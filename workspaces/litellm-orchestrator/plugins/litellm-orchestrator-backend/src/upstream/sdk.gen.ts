// This file is auto-generated by @hey-api/openapi-ts

import {
  type Client,
  formDataBodySerializer,
  type Options as Options2,
  type TDataShape,
  urlSearchParamsBodySerializer,
} from './client';
import { client } from './client.gen';
import type {
  ActiveCallbacksActiveCallbacksGetData,
  ActiveCallbacksActiveCallbacksGetResponses,
  ActiveCallbacksSettingsGetData,
  ActiveCallbacksSettingsGetResponses,
  AddAllowedIpAddAllowedIpPostData,
  AddAllowedIpAddAllowedIpPostErrors,
  AddAllowedIpAddAllowedIpPostResponses,
  AddMcpServerV1McpServerPostData,
  AddMcpServerV1McpServerPostErrors,
  AddMcpServerV1McpServerPostResponses,
  AddMessagesThreadsThreadIdMessagesPostData,
  AddMessagesThreadsThreadIdMessagesPostErrors,
  AddMessagesThreadsThreadIdMessagesPostResponses,
  AddMessagesV1ThreadsThreadIdMessagesPostData,
  AddMessagesV1ThreadsThreadIdMessagesPostErrors,
  AddMessagesV1ThreadsThreadIdMessagesPostResponses,
  AddNewModelModelNewPostData,
  AddNewModelModelNewPostErrors,
  AddNewModelModelNewPostResponses,
  AddSessionMcpServerV1McpServerOauthSessionPostData,
  AddSessionMcpServerV1McpServerOauthSessionPostErrors,
  AddSessionMcpServerV1McpServerOauthSessionPostResponses,
  AddTeamCallbacksTeamTeamIdCallbackPostData,
  AddTeamCallbacksTeamTeamIdCallbackPostErrors,
  AddTeamCallbacksTeamTeamIdCallbackPostResponses,
  AnthropicProxyRouteAnthropicEndpointPost2Data,
  AnthropicProxyRouteAnthropicEndpointPost2Errors,
  AnthropicProxyRouteAnthropicEndpointPost2Responses,
  AnthropicProxyRouteAnthropicEndpointPost3Data,
  AnthropicProxyRouteAnthropicEndpointPost3Errors,
  AnthropicProxyRouteAnthropicEndpointPost3Responses,
  AnthropicProxyRouteAnthropicEndpointPost4Data,
  AnthropicProxyRouteAnthropicEndpointPost4Errors,
  AnthropicProxyRouteAnthropicEndpointPost4Responses,
  AnthropicProxyRouteAnthropicEndpointPost5Data,
  AnthropicProxyRouteAnthropicEndpointPost5Errors,
  AnthropicProxyRouteAnthropicEndpointPost5Responses,
  AnthropicProxyRouteAnthropicEndpointPostData,
  AnthropicProxyRouteAnthropicEndpointPostErrors,
  AnthropicProxyRouteAnthropicEndpointPostResponses,
  AnthropicResponseV1MessagesPostData,
  AnthropicResponseV1MessagesPostResponses,
  ApplyGuardrailApplyGuardrailPostData,
  ApplyGuardrailApplyGuardrailPostErrors,
  ApplyGuardrailApplyGuardrailPostResponses,
  ApplyGuardrailGuardrailsApplyGuardrailPostData,
  ApplyGuardrailGuardrailsApplyGuardrailPostErrors,
  ApplyGuardrailGuardrailsApplyGuardrailPostResponses,
  AssemblyaiProxyRouteAssemblyaiEndpointPost2Data,
  AssemblyaiProxyRouteAssemblyaiEndpointPost2Errors,
  AssemblyaiProxyRouteAssemblyaiEndpointPost2Responses,
  AssemblyaiProxyRouteAssemblyaiEndpointPost3Data,
  AssemblyaiProxyRouteAssemblyaiEndpointPost3Errors,
  AssemblyaiProxyRouteAssemblyaiEndpointPost3Responses,
  AssemblyaiProxyRouteAssemblyaiEndpointPost4Data,
  AssemblyaiProxyRouteAssemblyaiEndpointPost4Errors,
  AssemblyaiProxyRouteAssemblyaiEndpointPost4Responses,
  AssemblyaiProxyRouteAssemblyaiEndpointPost5Data,
  AssemblyaiProxyRouteAssemblyaiEndpointPost5Errors,
  AssemblyaiProxyRouteAssemblyaiEndpointPost5Responses,
  AssemblyaiProxyRouteAssemblyaiEndpointPostData,
  AssemblyaiProxyRouteAssemblyaiEndpointPostErrors,
  AssemblyaiProxyRouteAssemblyaiEndpointPostResponses,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPost2Data,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPost2Errors,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPost2Responses,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPost3Data,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPost3Errors,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPost3Responses,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPost4Data,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPost4Errors,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPost4Responses,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPost5Data,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPost5Errors,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPost5Responses,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPostData,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPostErrors,
  AssemblyaiProxyRouteEuAssemblyaiEndpointPostResponses,
  AudioSpeechAudioSpeechPostData,
  AudioSpeechAudioSpeechPostResponses,
  AudioSpeechV1AudioSpeechPostData,
  AudioSpeechV1AudioSpeechPostResponses,
  AudioTranscriptionsAudioTranscriptionsPostData,
  AudioTranscriptionsAudioTranscriptionsPostErrors,
  AudioTranscriptionsAudioTranscriptionsPostResponses,
  AudioTranscriptionsV1AudioTranscriptionsPostData,
  AudioTranscriptionsV1AudioTranscriptionsPostErrors,
  AudioTranscriptionsV1AudioTranscriptionsPostResponses,
  AuthorizeAuthorizeGetData,
  AuthorizeAuthorizeGetErrors,
  AuthorizeAuthorizeGetResponses,
  AuthorizeMcpServerNameAuthorizeGetData,
  AuthorizeMcpServerNameAuthorizeGetErrors,
  AuthorizeMcpServerNameAuthorizeGetResponses,
  AzureProxyRouteAzureAiEndpointPost2Data,
  AzureProxyRouteAzureAiEndpointPost2Errors,
  AzureProxyRouteAzureAiEndpointPost2Responses,
  AzureProxyRouteAzureAiEndpointPost3Data,
  AzureProxyRouteAzureAiEndpointPost3Errors,
  AzureProxyRouteAzureAiEndpointPost3Responses,
  AzureProxyRouteAzureAiEndpointPost4Data,
  AzureProxyRouteAzureAiEndpointPost4Errors,
  AzureProxyRouteAzureAiEndpointPost4Responses,
  AzureProxyRouteAzureAiEndpointPost5Data,
  AzureProxyRouteAzureAiEndpointPost5Errors,
  AzureProxyRouteAzureAiEndpointPost5Responses,
  AzureProxyRouteAzureAiEndpointPostData,
  AzureProxyRouteAzureAiEndpointPostErrors,
  AzureProxyRouteAzureAiEndpointPostResponses,
  AzureProxyRouteAzureEndpointPost2Data,
  AzureProxyRouteAzureEndpointPost2Errors,
  AzureProxyRouteAzureEndpointPost2Responses,
  AzureProxyRouteAzureEndpointPost3Data,
  AzureProxyRouteAzureEndpointPost3Errors,
  AzureProxyRouteAzureEndpointPost3Responses,
  AzureProxyRouteAzureEndpointPost4Data,
  AzureProxyRouteAzureEndpointPost4Errors,
  AzureProxyRouteAzureEndpointPost4Responses,
  AzureProxyRouteAzureEndpointPost5Data,
  AzureProxyRouteAzureEndpointPost5Errors,
  AzureProxyRouteAzureEndpointPost5Responses,
  AzureProxyRouteAzureEndpointPostData,
  AzureProxyRouteAzureEndpointPostErrors,
  AzureProxyRouteAzureEndpointPostResponses,
  BedrockProxyRouteBedrockEndpointPost2Data,
  BedrockProxyRouteBedrockEndpointPost2Errors,
  BedrockProxyRouteBedrockEndpointPost2Responses,
  BedrockProxyRouteBedrockEndpointPost3Data,
  BedrockProxyRouteBedrockEndpointPost3Errors,
  BedrockProxyRouteBedrockEndpointPost3Responses,
  BedrockProxyRouteBedrockEndpointPost4Data,
  BedrockProxyRouteBedrockEndpointPost4Errors,
  BedrockProxyRouteBedrockEndpointPost4Responses,
  BedrockProxyRouteBedrockEndpointPost5Data,
  BedrockProxyRouteBedrockEndpointPost5Errors,
  BedrockProxyRouteBedrockEndpointPost5Responses,
  BedrockProxyRouteBedrockEndpointPostData,
  BedrockProxyRouteBedrockEndpointPostErrors,
  BedrockProxyRouteBedrockEndpointPostResponses,
  BlockKeyKeyBlockPostData,
  BlockKeyKeyBlockPostErrors,
  BlockKeyKeyBlockPostResponses,
  BlockTeamTeamBlockPostData,
  BlockTeamTeamBlockPostErrors,
  BlockTeamTeamBlockPostResponses,
  BlockUserCustomerBlockPostData,
  BlockUserCustomerBlockPostErrors,
  BlockUserCustomerBlockPostResponses,
  BudgetSettingsBudgetSettingsGetData,
  BudgetSettingsBudgetSettingsGetErrors,
  BudgetSettingsBudgetSettingsGetResponses,
  BulkTeamMemberAddTeamBulkMemberAddPostData,
  BulkTeamMemberAddTeamBulkMemberAddPostErrors,
  BulkTeamMemberAddTeamBulkMemberAddPostResponses,
  BulkUserUpdateUserBulkUpdatePostData,
  BulkUserUpdateUserBulkUpdatePostErrors,
  BulkUserUpdateUserBulkUpdatePostResponses,
  CacheDeleteCacheDeletePostData,
  CacheDeleteCacheDeletePostResponses,
  CacheFlushallCacheFlushallPostData,
  CacheFlushallCacheFlushallPostResponses,
  CachePingCachePingGetData,
  CachePingCachePingGetResponses,
  CacheRedisInfoCacheRedisInfoGetData,
  CacheRedisInfoCacheRedisInfoGetResponses,
  CalculateSpendSpendCalculatePostData,
  CalculateSpendSpendCalculatePostErrors,
  CalculateSpendSpendCalculatePostResponses,
  CallbackCallbackGetData,
  CallbackCallbackGetErrors,
  CallbackCallbackGetResponses,
  CallToolRestApiMcpRestToolsCallPostData,
  CallToolRestApiMcpRestToolsCallPostResponses,
  CancelBatchBatchesBatchIdCancelPostData,
  CancelBatchBatchesBatchIdCancelPostErrors,
  CancelBatchBatchesBatchIdCancelPostResponses,
  CancelBatchProviderV1BatchesBatchIdCancelPostData,
  CancelBatchProviderV1BatchesBatchIdCancelPostErrors,
  CancelBatchProviderV1BatchesBatchIdCancelPostResponses,
  CancelBatchV1BatchesBatchIdCancelPostData,
  CancelBatchV1BatchesBatchIdCancelPostErrors,
  CancelBatchV1BatchesBatchIdCancelPostResponses,
  CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostData,
  CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostErrors,
  CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostResponses,
  CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostData,
  CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostErrors,
  CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostResponses,
  CancelResponseOpenaiV1ResponsesResponseIdCancelPostData,
  CancelResponseOpenaiV1ResponsesResponseIdCancelPostErrors,
  CancelResponseOpenaiV1ResponsesResponseIdCancelPostResponses,
  CancelResponseResponsesResponseIdCancelPostData,
  CancelResponseResponsesResponseIdCancelPostErrors,
  CancelResponseResponsesResponseIdCancelPostResponses,
  CancelResponseV1ResponsesResponseIdCancelPostData,
  CancelResponseV1ResponsesResponseIdCancelPostErrors,
  CancelResponseV1ResponsesResponseIdCancelPostResponses,
  ChatCompletionChatCompletionsPostData,
  ChatCompletionChatCompletionsPostErrors,
  ChatCompletionChatCompletionsPostResponses,
  ChatCompletionEnginesModelChatCompletionsPostData,
  ChatCompletionEnginesModelChatCompletionsPostErrors,
  ChatCompletionEnginesModelChatCompletionsPostResponses,
  ChatCompletionOpenaiDeploymentsModelChatCompletionsPostData,
  ChatCompletionOpenaiDeploymentsModelChatCompletionsPostErrors,
  ChatCompletionOpenaiDeploymentsModelChatCompletionsPostResponses,
  ChatCompletionV1ChatCompletionsPostData,
  ChatCompletionV1ChatCompletionsPostErrors,
  ChatCompletionV1ChatCompletionsPostResponses,
  CloudzeroDryRunExportCloudzeroDryRunPostData,
  CloudzeroDryRunExportCloudzeroDryRunPostErrors,
  CloudzeroDryRunExportCloudzeroDryRunPostResponses,
  CloudzeroExportCloudzeroExportPostData,
  CloudzeroExportCloudzeroExportPostErrors,
  CloudzeroExportCloudzeroExportPostResponses,
  CohereProxyRouteCohereEndpointPost2Data,
  CohereProxyRouteCohereEndpointPost2Errors,
  CohereProxyRouteCohereEndpointPost2Responses,
  CohereProxyRouteCohereEndpointPost3Data,
  CohereProxyRouteCohereEndpointPost3Errors,
  CohereProxyRouteCohereEndpointPost3Responses,
  CohereProxyRouteCohereEndpointPost4Data,
  CohereProxyRouteCohereEndpointPost4Errors,
  CohereProxyRouteCohereEndpointPost4Responses,
  CohereProxyRouteCohereEndpointPost5Data,
  CohereProxyRouteCohereEndpointPost5Errors,
  CohereProxyRouteCohereEndpointPost5Responses,
  CohereProxyRouteCohereEndpointPostData,
  CohereProxyRouteCohereEndpointPostErrors,
  CohereProxyRouteCohereEndpointPostResponses,
  CompletionCompletionsPostData,
  CompletionCompletionsPostErrors,
  CompletionCompletionsPostResponses,
  CompletionEnginesModelCompletionsPostData,
  CompletionEnginesModelCompletionsPostErrors,
  CompletionEnginesModelCompletionsPostResponses,
  CompletionOpenaiDeploymentsModelCompletionsPostData,
  CompletionOpenaiDeploymentsModelCompletionsPostErrors,
  CompletionOpenaiDeploymentsModelCompletionsPostResponses,
  CompletionV1CompletionsPostData,
  CompletionV1CompletionsPostErrors,
  CompletionV1CompletionsPostResponses,
  ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostData,
  ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostErrors,
  ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostResponses,
  CountTokensV1MessagesCountTokensPostData,
  CountTokensV1MessagesCountTokensPostResponses,
  CreateAgentV1AgentsPostData,
  CreateAgentV1AgentsPostErrors,
  CreateAgentV1AgentsPostResponses,
  CreateAssistantAssistantsPostData,
  CreateAssistantAssistantsPostResponses,
  CreateAssistantV1AssistantsPostData,
  CreateAssistantV1AssistantsPostResponses,
  CreateBatchBatchesPostData,
  CreateBatchBatchesPostErrors,
  CreateBatchBatchesPostResponses,
  CreateBatchProviderV1BatchesPostData,
  CreateBatchProviderV1BatchesPostErrors,
  CreateBatchProviderV1BatchesPostResponses,
  CreateBatchV1BatchesPostData,
  CreateBatchV1BatchesPostErrors,
  CreateBatchV1BatchesPostResponses,
  CreateContainerContainersPostData,
  CreateContainerContainersPostResponses,
  CreateContainerV1ContainersPostData,
  CreateContainerV1ContainersPostResponses,
  CreateCredentialCredentialsPostData,
  CreateCredentialCredentialsPostErrors,
  CreateCredentialCredentialsPostResponses,
  CreateFileFilesPostData,
  CreateFileFilesPostErrors,
  CreateFileFilesPostResponses,
  CreateFileProviderV1FilesPostData,
  CreateFileProviderV1FilesPostErrors,
  CreateFileProviderV1FilesPostResponses,
  CreateFileV1FilesPostData,
  CreateFileV1FilesPostErrors,
  CreateFileV1FilesPostResponses,
  CreateFineTuningJobFineTuningJobsPostData,
  CreateFineTuningJobFineTuningJobsPostErrors,
  CreateFineTuningJobFineTuningJobsPostResponses,
  CreateFineTuningJobV1FineTuningJobsPostData,
  CreateFineTuningJobV1FineTuningJobsPostErrors,
  CreateFineTuningJobV1FineTuningJobsPostResponses,
  CreateGroupScimV2GroupsPostData,
  CreateGroupScimV2GroupsPostErrors,
  CreateGroupScimV2GroupsPostResponses,
  CreateGuardrailGuardrailsPostData,
  CreateGuardrailGuardrailsPostErrors,
  CreateGuardrailGuardrailsPostResponses,
  CreateModelGroupAccessGroupNewPostData,
  CreateModelGroupAccessGroupNewPostErrors,
  CreateModelGroupAccessGroupNewPostResponses,
  CreatePassThroughEndpointsConfigPassThroughEndpointPostData,
  CreatePassThroughEndpointsConfigPassThroughEndpointPostErrors,
  CreatePassThroughEndpointsConfigPassThroughEndpointPostResponses,
  CreatePromptPromptsPostData,
  CreatePromptPromptsPostErrors,
  CreatePromptPromptsPostResponses,
  CreateSearchToolSearchToolsPostData,
  CreateSearchToolSearchToolsPostErrors,
  CreateSearchToolSearchToolsPostResponses,
  CreateSkillV1SkillsPostData,
  CreateSkillV1SkillsPostErrors,
  CreateSkillV1SkillsPostResponses,
  CreateThreadsThreadsPostData,
  CreateThreadsThreadsPostResponses,
  CreateThreadsV1ThreadsPostData,
  CreateThreadsV1ThreadsPostResponses,
  CreateUserScimV2UsersPostData,
  CreateUserScimV2UsersPostErrors,
  CreateUserScimV2UsersPostResponses,
  DeleteAccessGroupAccessGroupAccessGroupDeleteDeleteData,
  DeleteAccessGroupAccessGroupAccessGroupDeleteDeleteErrors,
  DeleteAccessGroupAccessGroupAccessGroupDeleteDeleteResponses,
  DeleteAgentV1AgentsAgentIdDeleteData,
  DeleteAgentV1AgentsAgentIdDeleteErrors,
  DeleteAgentV1AgentsAgentIdDeleteResponses,
  DeleteAllowedIpDeleteAllowedIpPostData,
  DeleteAllowedIpDeleteAllowedIpPostErrors,
  DeleteAllowedIpDeleteAllowedIpPostResponses,
  DeleteAssistantAssistantsAssistantIdDeleteData,
  DeleteAssistantAssistantsAssistantIdDeleteErrors,
  DeleteAssistantAssistantsAssistantIdDeleteResponses,
  DeleteAssistantV1AssistantsAssistantIdDeleteData,
  DeleteAssistantV1AssistantsAssistantIdDeleteErrors,
  DeleteAssistantV1AssistantsAssistantIdDeleteResponses,
  DeleteBudgetBudgetDeletePostData,
  DeleteBudgetBudgetDeletePostErrors,
  DeleteBudgetBudgetDeletePostResponses,
  DeleteContainerContainersContainerIdDeleteData,
  DeleteContainerContainersContainerIdDeleteErrors,
  DeleteContainerContainersContainerIdDeleteResponses,
  DeleteContainerV1ContainersContainerIdDeleteData,
  DeleteContainerV1ContainersContainerIdDeleteErrors,
  DeleteContainerV1ContainersContainerIdDeleteResponses,
  DeleteCredentialCredentialsCredentialNameDeleteData,
  DeleteCredentialCredentialsCredentialNameDeleteErrors,
  DeleteCredentialCredentialsCredentialNameDeleteResponses,
  DeleteEndUserCustomerDeletePostData,
  DeleteEndUserCustomerDeletePostErrors,
  DeleteEndUserCustomerDeletePostResponses,
  DeleteFileFilesFileIdDeleteData,
  DeleteFileFilesFileIdDeleteErrors,
  DeleteFileFilesFileIdDeleteResponses,
  DeleteFileProviderV1FilesFileIdDeleteData,
  DeleteFileProviderV1FilesFileIdDeleteErrors,
  DeleteFileProviderV1FilesFileIdDeleteResponses,
  DeleteFileV1FilesFileIdDeleteData,
  DeleteFileV1FilesFileIdDeleteErrors,
  DeleteFileV1FilesFileIdDeleteResponses,
  DeleteGroupScimV2GroupsGroupIdDeleteData,
  DeleteGroupScimV2GroupsGroupIdDeleteErrors,
  DeleteGroupScimV2GroupsGroupIdDeleteResponses,
  DeleteGuardrailGuardrailsGuardrailIdDeleteData,
  DeleteGuardrailGuardrailsGuardrailIdDeleteErrors,
  DeleteGuardrailGuardrailsGuardrailIdDeleteResponses,
  DeleteKeyFnKeyDeletePostData,
  DeleteKeyFnKeyDeletePostErrors,
  DeleteKeyFnKeyDeletePostResponses,
  DeleteModelModelDeletePostData,
  DeleteModelModelDeletePostErrors,
  DeleteModelModelDeletePostResponses,
  DeleteOrganizationOrganizationDeleteDeleteData,
  DeleteOrganizationOrganizationDeleteDeleteErrors,
  DeleteOrganizationOrganizationDeleteDeleteResponses,
  DeletePassThroughEndpointsConfigPassThroughEndpointDeleteData,
  DeletePassThroughEndpointsConfigPassThroughEndpointDeleteErrors,
  DeletePassThroughEndpointsConfigPassThroughEndpointDeleteResponses,
  DeletePromptPromptsPromptIdDeleteData,
  DeletePromptPromptsPromptIdDeleteErrors,
  DeletePromptPromptsPromptIdDeleteResponses,
  DeleteResponseOpenaiV1ResponsesResponseIdDeleteData,
  DeleteResponseOpenaiV1ResponsesResponseIdDeleteErrors,
  DeleteResponseOpenaiV1ResponsesResponseIdDeleteResponses,
  DeleteResponseResponsesResponseIdDeleteData,
  DeleteResponseResponsesResponseIdDeleteErrors,
  DeleteResponseResponsesResponseIdDeleteResponses,
  DeleteResponseV1ResponsesResponseIdDeleteData,
  DeleteResponseV1ResponsesResponseIdDeleteErrors,
  DeleteResponseV1ResponsesResponseIdDeleteResponses,
  DeleteSearchToolSearchToolsSearchToolIdDeleteData,
  DeleteSearchToolSearchToolsSearchToolIdDeleteErrors,
  DeleteSearchToolSearchToolsSearchToolIdDeleteResponses,
  DeleteSkillV1SkillsSkillIdDeleteData,
  DeleteSkillV1SkillsSkillIdDeleteErrors,
  DeleteSkillV1SkillsSkillIdDeleteResponses,
  DeleteTagTagDeletePostData,
  DeleteTagTagDeletePostErrors,
  DeleteTagTagDeletePostResponses,
  DeleteTeamTeamDeletePostData,
  DeleteTeamTeamDeletePostErrors,
  DeleteTeamTeamDeletePostResponses,
  DeleteUserScimV2UsersUserIdDeleteData,
  DeleteUserScimV2UsersUserIdDeleteErrors,
  DeleteUserScimV2UsersUserIdDeleteResponses,
  DeleteUserUserDeletePostData,
  DeleteUserUserDeletePostErrors,
  DeleteUserUserDeletePostResponses,
  DeleteVectorStoreVectorStoreDeletePostData,
  DeleteVectorStoreVectorStoreDeletePostErrors,
  DeleteVectorStoreVectorStoreDeletePostResponses,
  DeprecatedInfoOrganizationOrganizationInfoPostData,
  DeprecatedInfoOrganizationOrganizationInfoPostErrors,
  DeprecatedInfoOrganizationOrganizationInfoPostResponses,
  DisableTeamLoggingTeamTeamIdDisableLoggingPostData,
  DisableTeamLoggingTeamTeamIdDisableLoggingPostErrors,
  DisableTeamLoggingTeamTeamIdDisableLoggingPostResponses,
  DynamicMcpRouteMcpServerNameMcpOptions2Data,
  DynamicMcpRouteMcpServerNameMcpOptions2Errors,
  DynamicMcpRouteMcpServerNameMcpOptions2Responses,
  DynamicMcpRouteMcpServerNameMcpOptions3Data,
  DynamicMcpRouteMcpServerNameMcpOptions3Errors,
  DynamicMcpRouteMcpServerNameMcpOptions3Responses,
  DynamicMcpRouteMcpServerNameMcpOptions4Data,
  DynamicMcpRouteMcpServerNameMcpOptions4Errors,
  DynamicMcpRouteMcpServerNameMcpOptions4Responses,
  DynamicMcpRouteMcpServerNameMcpOptions5Data,
  DynamicMcpRouteMcpServerNameMcpOptions5Errors,
  DynamicMcpRouteMcpServerNameMcpOptions5Responses,
  DynamicMcpRouteMcpServerNameMcpOptions6Data,
  DynamicMcpRouteMcpServerNameMcpOptions6Errors,
  DynamicMcpRouteMcpServerNameMcpOptions6Responses,
  DynamicMcpRouteMcpServerNameMcpOptions7Data,
  DynamicMcpRouteMcpServerNameMcpOptions7Errors,
  DynamicMcpRouteMcpServerNameMcpOptions7Responses,
  DynamicMcpRouteMcpServerNameMcpOptionsData,
  DynamicMcpRouteMcpServerNameMcpOptionsErrors,
  DynamicMcpRouteMcpServerNameMcpOptionsResponses,
  EditMcpServerV1McpServerPutData,
  EditMcpServerV1McpServerPutErrors,
  EditMcpServerV1McpServerPutResponses,
  EmbeddingsEmbeddingsPostData,
  EmbeddingsEmbeddingsPostErrors,
  EmbeddingsEmbeddingsPostResponses,
  EmbeddingsEnginesModelEmbeddingsPostData,
  EmbeddingsEnginesModelEmbeddingsPostErrors,
  EmbeddingsEnginesModelEmbeddingsPostResponses,
  EmbeddingsOpenaiDeploymentsModelEmbeddingsPostData,
  EmbeddingsOpenaiDeploymentsModelEmbeddingsPostErrors,
  EmbeddingsOpenaiDeploymentsModelEmbeddingsPostResponses,
  EmbeddingsV1EmbeddingsPostData,
  EmbeddingsV1EmbeddingsPostErrors,
  EmbeddingsV1EmbeddingsPostResponses,
  EndUserInfoCustomerInfoGetData,
  EndUserInfoCustomerInfoGetErrors,
  EndUserInfoCustomerInfoGetResponses,
  FetchAllMcpServersV1McpServerGetData,
  FetchAllMcpServersV1McpServerGetResponses,
  FetchMcpServerV1McpServerServerIdGetData,
  FetchMcpServerV1McpServerServerIdGetErrors,
  FetchMcpServerV1McpServerServerIdGetResponses,
  GeminiProxyRouteGeminiEndpointPost2Data,
  GeminiProxyRouteGeminiEndpointPost2Errors,
  GeminiProxyRouteGeminiEndpointPost2Responses,
  GeminiProxyRouteGeminiEndpointPost3Data,
  GeminiProxyRouteGeminiEndpointPost3Errors,
  GeminiProxyRouteGeminiEndpointPost3Responses,
  GeminiProxyRouteGeminiEndpointPost4Data,
  GeminiProxyRouteGeminiEndpointPost4Errors,
  GeminiProxyRouteGeminiEndpointPost4Responses,
  GeminiProxyRouteGeminiEndpointPost5Data,
  GeminiProxyRouteGeminiEndpointPost5Errors,
  GeminiProxyRouteGeminiEndpointPost5Responses,
  GeminiProxyRouteGeminiEndpointPostData,
  GeminiProxyRouteGeminiEndpointPostErrors,
  GeminiProxyRouteGeminiEndpointPostResponses,
  GenerateKeyFnKeyGeneratePostData,
  GenerateKeyFnKeyGeneratePostErrors,
  GenerateKeyFnKeyGeneratePostResponses,
  GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostData,
  GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostErrors,
  GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostResponses,
  GetAccessGroupInfoAccessGroupAccessGroupInfoGetData,
  GetAccessGroupInfoAccessGroupAccessGroupInfoGetErrors,
  GetAccessGroupInfoAccessGroupAccessGroupInfoGetResponses,
  GetActiveTasksStatsDebugAsyncioTasksGetData,
  GetActiveTasksStatsDebugAsyncioTasksGetResponses,
  GetAgentByIdV1AgentsAgentIdGetData,
  GetAgentByIdV1AgentsAgentIdGetErrors,
  GetAgentByIdV1AgentsAgentIdGetResponses,
  GetAgentsPublicAgentHubGetData,
  GetAgentsPublicAgentHubGetResponses,
  GetAgentsV1AgentsGetData,
  GetAgentsV1AgentsGetResponses,
  GetAssistantsAssistantsGetData,
  GetAssistantsAssistantsGetResponses,
  GetAssistantsV1AssistantsGetData,
  GetAssistantsV1AssistantsGetResponses,
  GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetData,
  GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetResponses,
  GetCacheSettingsCacheSettingsGetData,
  GetCacheSettingsCacheSettingsGetResponses,
  GetCallbackConfigsCallbacksConfigsGetData,
  GetCallbackConfigsCallbacksConfigsGetResponses,
  GetCloudzeroSettingsCloudzeroSettingsGetData,
  GetCloudzeroSettingsCloudzeroSettingsGetResponses,
  GetCostDiscountConfigConfigCostDiscountConfigGetData,
  GetCostDiscountConfigConfigCostDiscountConfigGetResponses,
  GetCredentialCredentialsByModelModelIdGetData,
  GetCredentialCredentialsByModelModelIdGetErrors,
  GetCredentialCredentialsByModelModelIdGetResponses,
  GetCredentialCredentialsByNameCredentialNameGetData,
  GetCredentialCredentialsByNameCredentialNameGetErrors,
  GetCredentialCredentialsByNameCredentialNameGetResponses,
  GetCredentialsCredentialsGetData,
  GetCredentialsCredentialsGetResponses,
  GetDailyActiveUsersTagDauGetData,
  GetDailyActiveUsersTagDauGetErrors,
  GetDailyActiveUsersTagDauGetResponses,
  GetDefaultTeamSettingsGetDefaultTeamSettingsGetData,
  GetDefaultTeamSettingsGetDefaultTeamSettingsGetResponses,
  GetDistinctUserAgentTagsTagDistinctGetData,
  GetDistinctUserAgentTagsTagDistinctGetResponses,
  GetFileContentFilesFileIdContentGetData,
  GetFileContentFilesFileIdContentGetErrors,
  GetFileContentFilesFileIdContentGetResponses,
  GetFileContentProviderV1FilesFileIdContentGetData,
  GetFileContentProviderV1FilesFileIdContentGetErrors,
  GetFileContentProviderV1FilesFileIdContentGetResponses,
  GetFileContentV1FilesFileIdContentGetData,
  GetFileContentV1FilesFileIdContentGetErrors,
  GetFileContentV1FilesFileIdContentGetResponses,
  GetFileFilesFileIdGetData,
  GetFileFilesFileIdGetErrors,
  GetFileFilesFileIdGetResponses,
  GetFileProviderV1FilesFileIdGetData,
  GetFileProviderV1FilesFileIdGetErrors,
  GetFileProviderV1FilesFileIdGetResponses,
  GetFileV1FilesFileIdGetData,
  GetFileV1FilesFileIdGetErrors,
  GetFileV1FilesFileIdGetResponses,
  GetGlobalSpendReportGlobalSpendReportGetData,
  GetGlobalSpendReportGlobalSpendReportGetErrors,
  GetGlobalSpendReportGlobalSpendReportGetResponses,
  GetGroupScimV2GroupsGroupIdGetData,
  GetGroupScimV2GroupsGroupIdGetErrors,
  GetGroupScimV2GroupsGroupIdGetResponses,
  GetGroupsScimV2GroupsGetData,
  GetGroupsScimV2GroupsGetErrors,
  GetGroupsScimV2GroupsGetResponses,
  GetGuardrailInfoGuardrailsGuardrailIdGetData,
  GetGuardrailInfoGuardrailsGuardrailIdGetErrors,
  GetGuardrailInfoGuardrailsGuardrailIdGetResponses,
  GetGuardrailInfoGuardrailsGuardrailIdInfoGetData,
  GetGuardrailInfoGuardrailsGuardrailIdInfoGetErrors,
  GetGuardrailInfoGuardrailsGuardrailIdInfoGetResponses,
  GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetData,
  GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetResponses,
  GetInternalUserSettingsGetInternalUserSettingsGetData,
  GetInternalUserSettingsGetInternalUserSettingsGetResponses,
  GetMcpAccessGroupsV1McpAccessGroupsGetData,
  GetMcpAccessGroupsV1McpAccessGroupsGetResponses,
  GetMcpServersPublicMcpHubGetData,
  GetMcpServersPublicMcpHubGetResponses,
  GetMcpToolsV1McpToolsGetData,
  GetMcpToolsV1McpToolsGetResponses,
  GetMessagesThreadsThreadIdMessagesGetData,
  GetMessagesThreadsThreadIdMessagesGetErrors,
  GetMessagesThreadsThreadIdMessagesGetResponses,
  GetMessagesV1ThreadsThreadIdMessagesGetData,
  GetMessagesV1ThreadsThreadIdMessagesGetErrors,
  GetMessagesV1ThreadsThreadIdMessagesGetResponses,
  GetMonthlyActiveUsersTagMauGetData,
  GetMonthlyActiveUsersTagMauGetErrors,
  GetMonthlyActiveUsersTagMauGetResponses,
  GetOrganizationDailyActivityOrganizationDailyActivityGetData,
  GetOrganizationDailyActivityOrganizationDailyActivityGetErrors,
  GetOrganizationDailyActivityOrganizationDailyActivityGetResponses,
  GetPassThroughEndpointsConfigPassThroughEndpointGetData,
  GetPassThroughEndpointsConfigPassThroughEndpointGetErrors,
  GetPassThroughEndpointsConfigPassThroughEndpointGetResponses,
  GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetData,
  GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetErrors,
  GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetResponses,
  GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetData,
  GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetErrors,
  GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetResponses,
  GetPromptInfoPromptsPromptIdGetData,
  GetPromptInfoPromptsPromptIdGetErrors,
  GetPromptInfoPromptsPromptIdGetResponses,
  GetPromptInfoPromptsPromptIdInfoGetData,
  GetPromptInfoPromptsPromptIdInfoGetErrors,
  GetPromptInfoPromptsPromptIdInfoGetResponses,
  GetPromptVersionsPromptsPromptIdVersionsGetData,
  GetPromptVersionsPromptsPromptIdVersionsGetErrors,
  GetPromptVersionsPromptsPromptIdVersionsGetResponses,
  GetProviderFieldsPublicProvidersFieldsGetData,
  GetProviderFieldsPublicProvidersFieldsGetResponses,
  GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetData,
  GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetResponses,
  GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetData,
  GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetErrors,
  GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetResponses,
  GetResponseInputItemsResponsesResponseIdInputItemsGetData,
  GetResponseInputItemsResponsesResponseIdInputItemsGetErrors,
  GetResponseInputItemsResponsesResponseIdInputItemsGetResponses,
  GetResponseInputItemsV1ResponsesResponseIdInputItemsGetData,
  GetResponseInputItemsV1ResponsesResponseIdInputItemsGetErrors,
  GetResponseInputItemsV1ResponsesResponseIdInputItemsGetResponses,
  GetResponseOpenaiV1ResponsesResponseIdGetData,
  GetResponseOpenaiV1ResponsesResponseIdGetErrors,
  GetResponseOpenaiV1ResponsesResponseIdGetResponses,
  GetResponseResponsesResponseIdGetData,
  GetResponseResponsesResponseIdGetErrors,
  GetResponseResponsesResponseIdGetResponses,
  GetResponseV1ResponsesResponseIdGetData,
  GetResponseV1ResponsesResponseIdGetErrors,
  GetResponseV1ResponsesResponseIdGetResponses,
  GetRouterSettingsRouterSettingsGetData,
  GetRouterSettingsRouterSettingsGetResponses,
  GetRoutesRoutesGetData,
  GetRoutesRoutesGetResponses,
  GetSearchToolInfoSearchToolsSearchToolIdGetData,
  GetSearchToolInfoSearchToolsSearchToolIdGetErrors,
  GetSearchToolInfoSearchToolsSearchToolIdGetResponses,
  GetServiceProviderConfigScimV2ServiceProviderConfigGetData,
  GetServiceProviderConfigScimV2ServiceProviderConfigGetErrors,
  GetServiceProviderConfigScimV2ServiceProviderConfigGetResponses,
  GetSkillV1SkillsSkillIdGetData,
  GetSkillV1SkillsSkillIdGetErrors,
  GetSkillV1SkillsSkillIdGetResponses,
  GetSsoSettingsGetSsoSettingsGetData,
  GetSsoSettingsGetSsoSettingsGetResponses,
  GetSupportedProvidersPublicProvidersGetData,
  GetSupportedProvidersPublicProvidersGetResponses,
  GetTagDailyActivityTagDailyActivityGetData,
  GetTagDailyActivityTagDailyActivityGetErrors,
  GetTagDailyActivityTagDailyActivityGetResponses,
  GetTagSummaryTagSummaryGetData,
  GetTagSummaryTagSummaryGetErrors,
  GetTagSummaryTagSummaryGetResponses,
  GetTeamCallbacksTeamTeamIdCallbackGetData,
  GetTeamCallbacksTeamTeamIdCallbackGetErrors,
  GetTeamCallbacksTeamTeamIdCallbackGetResponses,
  GetTeamDailyActivityTeamDailyActivityGetData,
  GetTeamDailyActivityTeamDailyActivityGetErrors,
  GetTeamDailyActivityTeamDailyActivityGetResponses,
  GetThreadThreadsThreadIdGetData,
  GetThreadThreadsThreadIdGetErrors,
  GetThreadThreadsThreadIdGetResponses,
  GetThreadV1ThreadsThreadIdGetData,
  GetThreadV1ThreadsThreadIdGetErrors,
  GetThreadV1ThreadsThreadIdGetResponses,
  GetUiConfigLitellmWellKnownLitellmUiConfigGetData,
  GetUiConfigLitellmWellKnownLitellmUiConfigGetResponses,
  GetUiConfigWellKnownLitellmUiConfigGetData,
  GetUiConfigWellKnownLitellmUiConfigGetResponses,
  GetUiThemeSettingsGetUiThemeSettingsGetData,
  GetUiThemeSettingsGetUiThemeSettingsGetResponses,
  GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetData,
  GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetErrors,
  GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetResponses,
  GetUserDailyActivityUserDailyActivityGetData,
  GetUserDailyActivityUserDailyActivityGetErrors,
  GetUserDailyActivityUserDailyActivityGetResponses,
  GetUserScimV2UsersUserIdGetData,
  GetUserScimV2UsersUserIdGetErrors,
  GetUserScimV2UsersUserIdGetResponses,
  GetUsersScimV2UsersGetData,
  GetUsersScimV2UsersGetErrors,
  GetUsersScimV2UsersGetResponses,
  GetUsersUserListGetData,
  GetUsersUserListGetErrors,
  GetUsersUserListGetResponses,
  GetVectorStoreInfoVectorStoreInfoPostData,
  GetVectorStoreInfoVectorStoreInfoPostErrors,
  GetVectorStoreInfoVectorStoreInfoPostResponses,
  GetWeeklyActiveUsersTagWauGetData,
  GetWeeklyActiveUsersTagWauGetErrors,
  GetWeeklyActiveUsersTagWauGetResponses,
  GlobalSpendResetGlobalSpendResetPostData,
  GlobalSpendResetGlobalSpendResetPostResponses,
  GlobalViewSpendTagsGlobalSpendTagsGetData,
  GlobalViewSpendTagsGlobalSpendTagsGetErrors,
  GlobalViewSpendTagsGlobalSpendTagsGetResponses,
  GoogleCountTokensModelsModelNameCountTokensPostData,
  GoogleCountTokensModelsModelNameCountTokensPostErrors,
  GoogleCountTokensModelsModelNameCountTokensPostResponses,
  GoogleCountTokensV1BetaModelsModelNameCountTokensPostData,
  GoogleCountTokensV1BetaModelsModelNameCountTokensPostErrors,
  GoogleCountTokensV1BetaModelsModelNameCountTokensPostResponses,
  GoogleGenerateContentModelsModelNameGenerateContentPostData,
  GoogleGenerateContentModelsModelNameGenerateContentPostErrors,
  GoogleGenerateContentModelsModelNameGenerateContentPostResponses,
  GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostData,
  GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostErrors,
  GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostResponses,
  GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostData,
  GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostErrors,
  GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostResponses,
  GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostData,
  GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostErrors,
  GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostResponses,
  HealthCheckAllMcpServersV1McpServerHealthGetData,
  HealthCheckAllMcpServersV1McpServerHealthGetResponses,
  HealthCheckHistoryEndpointHealthHistoryGetData,
  HealthCheckHistoryEndpointHealthHistoryGetErrors,
  HealthCheckHistoryEndpointHealthHistoryGetResponses,
  HealthCheckMcpServerV1McpServerServerIdHealthGetData,
  HealthCheckMcpServerV1McpServerServerIdHealthGetErrors,
  HealthCheckMcpServerV1McpServerServerIdHealthGetResponses,
  HealthEndpointHealthGetData,
  HealthEndpointHealthGetErrors,
  HealthEndpointHealthGetResponses,
  HealthLivelinessHealthLivelinessGetData,
  HealthLivelinessHealthLivelinessGetResponses,
  HealthLivelinessHealthLivenessGetData,
  HealthLivelinessHealthLivenessGetResponses,
  HealthLivelinessOptionsHealthLivelinessOptionsData,
  HealthLivelinessOptionsHealthLivelinessOptionsResponses,
  HealthLivelinessOptionsHealthLivenessOptionsData,
  HealthLivelinessOptionsHealthLivenessOptionsResponses,
  HealthReadinessHealthReadinessGetData,
  HealthReadinessHealthReadinessGetResponses,
  HealthReadinessOptionsHealthReadinessOptionsData,
  HealthReadinessOptionsHealthReadinessOptionsResponses,
  HealthServicesEndpointHealthServicesGetData,
  HealthServicesEndpointHealthServicesGetErrors,
  HealthServicesEndpointHealthServicesGetResponses,
  HomeGetData,
  HomeGetResponses,
  ImageEditApiImagesEditsPostData,
  ImageEditApiImagesEditsPostErrors,
  ImageEditApiImagesEditsPostResponses,
  ImageEditApiOpenaiDeploymentsModelImagesEditsPostData,
  ImageEditApiOpenaiDeploymentsModelImagesEditsPostErrors,
  ImageEditApiOpenaiDeploymentsModelImagesEditsPostResponses,
  ImageEditApiV1ImagesEditsPostData,
  ImageEditApiV1ImagesEditsPostErrors,
  ImageEditApiV1ImagesEditsPostResponses,
  ImageGenerationImagesGenerationsPostData,
  ImageGenerationImagesGenerationsPostErrors,
  ImageGenerationImagesGenerationsPostResponses,
  ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostData,
  ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostErrors,
  ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostResponses,
  ImageGenerationV1ImagesGenerationsPostData,
  ImageGenerationV1ImagesGenerationsPostErrors,
  ImageGenerationV1ImagesGenerationsPostResponses,
  IndexCreateV1IndexesPostData,
  IndexCreateV1IndexesPostErrors,
  IndexCreateV1IndexesPostResponses,
  InfoBudgetBudgetInfoPostData,
  InfoBudgetBudgetInfoPostErrors,
  InfoBudgetBudgetInfoPostResponses,
  InfoKeyFnKeyInfoGetData,
  InfoKeyFnKeyInfoGetErrors,
  InfoKeyFnKeyInfoGetResponses,
  InfoOrganizationOrganizationInfoGetData,
  InfoOrganizationOrganizationInfoGetErrors,
  InfoOrganizationOrganizationInfoGetResponses,
  InfoTagTagInfoPostData,
  InfoTagTagInfoPostErrors,
  InfoTagTagInfoPostResponses,
  InitCloudzeroSettingsCloudzeroInitPostData,
  InitCloudzeroSettingsCloudzeroInitPostErrors,
  InitCloudzeroSettingsCloudzeroInitPostResponses,
  KeyAliasesKeyAliasesGetData,
  KeyAliasesKeyAliasesGetResponses,
  KeyHealthKeyHealthPostData,
  KeyHealthKeyHealthPostResponses,
  LangfuseProxyRouteLangfuseEndpointPost2Data,
  LangfuseProxyRouteLangfuseEndpointPost2Errors,
  LangfuseProxyRouteLangfuseEndpointPost2Responses,
  LangfuseProxyRouteLangfuseEndpointPost3Data,
  LangfuseProxyRouteLangfuseEndpointPost3Errors,
  LangfuseProxyRouteLangfuseEndpointPost3Responses,
  LangfuseProxyRouteLangfuseEndpointPost4Data,
  LangfuseProxyRouteLangfuseEndpointPost4Errors,
  LangfuseProxyRouteLangfuseEndpointPost4Responses,
  LangfuseProxyRouteLangfuseEndpointPost5Data,
  LangfuseProxyRouteLangfuseEndpointPost5Errors,
  LangfuseProxyRouteLangfuseEndpointPost5Responses,
  LangfuseProxyRouteLangfuseEndpointPostData,
  LangfuseProxyRouteLangfuseEndpointPostErrors,
  LangfuseProxyRouteLangfuseEndpointPostResponses,
  LatestHealthChecksEndpointHealthLatestGetData,
  LatestHealthChecksEndpointHealthLatestGetResponses,
  ListAccessGroupsAccessGroupListGetData,
  ListAccessGroupsAccessGroupListGetResponses,
  ListAvailableTeamsTeamAvailableGetData,
  ListAvailableTeamsTeamAvailableGetErrors,
  ListAvailableTeamsTeamAvailableGetResponses,
  ListBatchesBatchesGetData,
  ListBatchesBatchesGetErrors,
  ListBatchesBatchesGetResponses,
  ListBatchesProviderV1BatchesGetData,
  ListBatchesProviderV1BatchesGetErrors,
  ListBatchesProviderV1BatchesGetResponses,
  ListBatchesV1BatchesGetData,
  ListBatchesV1BatchesGetErrors,
  ListBatchesV1BatchesGetResponses,
  ListBudgetBudgetListGetData,
  ListBudgetBudgetListGetResponses,
  ListCallbacksCallbacksListGetData,
  ListCallbacksCallbacksListGetResponses,
  ListContainersContainersGetData,
  ListContainersContainersGetResponses,
  ListContainersV1ContainersGetData,
  ListContainersV1ContainersGetResponses,
  ListEndUserCustomerListGetData,
  ListEndUserCustomerListGetResponses,
  ListFilesFilesGetData,
  ListFilesFilesGetErrors,
  ListFilesFilesGetResponses,
  ListFilesProviderV1FilesGetData,
  ListFilesProviderV1FilesGetErrors,
  ListFilesProviderV1FilesGetResponses,
  ListFilesV1FilesGetData,
  ListFilesV1FilesGetErrors,
  ListFilesV1FilesGetResponses,
  ListFineTuningJobsFineTuningJobsGetData,
  ListFineTuningJobsFineTuningJobsGetErrors,
  ListFineTuningJobsFineTuningJobsGetResponses,
  ListFineTuningJobsV1FineTuningJobsGetData,
  ListFineTuningJobsV1FineTuningJobsGetErrors,
  ListFineTuningJobsV1FineTuningJobsGetResponses,
  ListGuardrailsGuardrailsListGetData,
  ListGuardrailsGuardrailsListGetResponses,
  ListGuardrailsV2V2GuardrailsListGetData,
  ListGuardrailsV2V2GuardrailsListGetResponses,
  ListKeysKeyListGetData,
  ListKeysKeyListGetErrors,
  ListKeysKeyListGetResponses,
  ListOrganizationOrganizationListGetData,
  ListOrganizationOrganizationListGetResponses,
  ListPromptsPromptsListGetData,
  ListPromptsPromptsListGetResponses,
  ListSearchToolsSearchToolsListGetData,
  ListSearchToolsSearchToolsListGetResponses,
  ListSkillsV1SkillsGetData,
  ListSkillsV1SkillsGetErrors,
  ListSkillsV1SkillsGetResponses,
  ListTagsTagListGetData,
  ListTagsTagListGetResponses,
  ListTeamTeamListGetData,
  ListTeamTeamListGetErrors,
  ListTeamTeamListGetResponses,
  ListTeamV2V2TeamListGetData,
  ListTeamV2V2TeamListGetErrors,
  ListTeamV2V2TeamListGetResponses,
  ListToolRestApiMcpRestToolsListGetData,
  ListToolRestApiMcpRestToolsListGetErrors,
  ListToolRestApiMcpRestToolsListGetResponses,
  ListVectorStoresVectorStoreListGetData,
  ListVectorStoresVectorStoreListGetErrors,
  ListVectorStoresVectorStoreListGetResponses,
  MakeAgentPublicV1AgentsAgentIdMakePublicPostData,
  MakeAgentPublicV1AgentsAgentIdMakePublicPostErrors,
  MakeAgentPublicV1AgentsAgentIdMakePublicPostResponses,
  MakeAgentsPublicV1AgentsMakePublicPostData,
  MakeAgentsPublicV1AgentsMakePublicPostErrors,
  MakeAgentsPublicV1AgentsMakePublicPostResponses,
  MakeMcpServersPublicV1McpMakePublicPostData,
  MakeMcpServersPublicV1McpMakePublicPostErrors,
  MakeMcpServersPublicV1McpMakePublicPostResponses,
  MilvusProxyRouteMilvusEndpointPost2Data,
  MilvusProxyRouteMilvusEndpointPost2Errors,
  MilvusProxyRouteMilvusEndpointPost2Responses,
  MilvusProxyRouteMilvusEndpointPost3Data,
  MilvusProxyRouteMilvusEndpointPost3Errors,
  MilvusProxyRouteMilvusEndpointPost3Responses,
  MilvusProxyRouteMilvusEndpointPost4Data,
  MilvusProxyRouteMilvusEndpointPost4Errors,
  MilvusProxyRouteMilvusEndpointPost4Responses,
  MilvusProxyRouteMilvusEndpointPost5Data,
  MilvusProxyRouteMilvusEndpointPost5Errors,
  MilvusProxyRouteMilvusEndpointPost5Responses,
  MilvusProxyRouteMilvusEndpointPostData,
  MilvusProxyRouteMilvusEndpointPostErrors,
  MilvusProxyRouteMilvusEndpointPostResponses,
  MistralProxyRouteMistralEndpointPost2Data,
  MistralProxyRouteMistralEndpointPost2Errors,
  MistralProxyRouteMistralEndpointPost2Responses,
  MistralProxyRouteMistralEndpointPost3Data,
  MistralProxyRouteMistralEndpointPost3Errors,
  MistralProxyRouteMistralEndpointPost3Responses,
  MistralProxyRouteMistralEndpointPost4Data,
  MistralProxyRouteMistralEndpointPost4Errors,
  MistralProxyRouteMistralEndpointPost4Responses,
  MistralProxyRouteMistralEndpointPost5Data,
  MistralProxyRouteMistralEndpointPost5Errors,
  MistralProxyRouteMistralEndpointPost5Responses,
  MistralProxyRouteMistralEndpointPostData,
  MistralProxyRouteMistralEndpointPostErrors,
  MistralProxyRouteMistralEndpointPostResponses,
  ModelGroupInfoModelGroupInfoGetData,
  ModelGroupInfoModelGroupInfoGetErrors,
  ModelGroupInfoModelGroupInfoGetResponses,
  ModelInfoModelsModelIdGetData,
  ModelInfoModelsModelIdGetErrors,
  ModelInfoModelsModelIdGetResponses,
  ModelInfoV1ModelInfoGetData,
  ModelInfoV1ModelInfoGetErrors,
  ModelInfoV1ModelInfoGetResponses,
  ModelInfoV1ModelsModelIdGetData,
  ModelInfoV1ModelsModelIdGetErrors,
  ModelInfoV1ModelsModelIdGetResponses,
  ModelInfoV1V1ModelInfoGetData,
  ModelInfoV1V1ModelInfoGetErrors,
  ModelInfoV1V1ModelInfoGetResponses,
  ModelListModelsGetData,
  ModelListModelsGetErrors,
  ModelListModelsGetResponses,
  ModelListV1ModelsGetData,
  ModelListV1ModelsGetErrors,
  ModelListV1ModelsGetResponses,
  ModerationsModerationsPostData,
  ModerationsModerationsPostResponses,
  ModerationsV1ModerationsPostData,
  ModerationsV1ModerationsPostResponses,
  NewBudgetBudgetNewPostData,
  NewBudgetBudgetNewPostErrors,
  NewBudgetBudgetNewPostResponses,
  NewEndUserCustomerNewPostData,
  NewEndUserCustomerNewPostErrors,
  NewEndUserCustomerNewPostResponses,
  NewOrganizationOrganizationNewPostData,
  NewOrganizationOrganizationNewPostErrors,
  NewOrganizationOrganizationNewPostResponses,
  NewTagTagNewPostData,
  NewTagTagNewPostErrors,
  NewTagTagNewPostResponses,
  NewTeamTeamNewPostData,
  NewTeamTeamNewPostErrors,
  NewTeamTeamNewPostResponses,
  NewUserUserNewPostData,
  NewUserUserNewPostErrors,
  NewUserUserNewPostResponses,
  NewVectorStoreVectorStoreNewPostData,
  NewVectorStoreVectorStoreNewPostErrors,
  NewVectorStoreVectorStoreNewPostResponses,
  OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetData,
  OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetErrors,
  OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetResponses,
  OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetData,
  OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetErrors,
  OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetResponses,
  OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetData,
  OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetErrors,
  OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetResponses,
  OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetData,
  OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetErrors,
  OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetResponses,
  OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetData,
  OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetErrors,
  OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetResponses,
  OcrOcrPostData,
  OcrOcrPostResponses,
  OcrV1OcrPostData,
  OcrV1OcrPostResponses,
  OpenaiProxyRouteOpenaiEndpointPost2Data,
  OpenaiProxyRouteOpenaiEndpointPost2Errors,
  OpenaiProxyRouteOpenaiEndpointPost2Responses,
  OpenaiProxyRouteOpenaiEndpointPost3Data,
  OpenaiProxyRouteOpenaiEndpointPost3Errors,
  OpenaiProxyRouteOpenaiEndpointPost3Responses,
  OpenaiProxyRouteOpenaiEndpointPost4Data,
  OpenaiProxyRouteOpenaiEndpointPost4Errors,
  OpenaiProxyRouteOpenaiEndpointPost4Responses,
  OpenaiProxyRouteOpenaiEndpointPost5Data,
  OpenaiProxyRouteOpenaiEndpointPost5Errors,
  OpenaiProxyRouteOpenaiEndpointPost5Responses,
  OpenaiProxyRouteOpenaiEndpointPostData,
  OpenaiProxyRouteOpenaiEndpointPostErrors,
  OpenaiProxyRouteOpenaiEndpointPostResponses,
  OpenidConfigurationWellKnownOpenidConfigurationGetData,
  OpenidConfigurationWellKnownOpenidConfigurationGetResponses,
  OrganizationMemberAddOrganizationMemberAddPostData,
  OrganizationMemberAddOrganizationMemberAddPostErrors,
  OrganizationMemberAddOrganizationMemberAddPostResponses,
  OrganizationMemberDeleteOrganizationMemberDeleteDeleteData,
  OrganizationMemberDeleteOrganizationMemberDeleteDeleteErrors,
  OrganizationMemberDeleteOrganizationMemberDeleteDeleteResponses,
  OrganizationMemberUpdateOrganizationMemberUpdatePatchData,
  OrganizationMemberUpdateOrganizationMemberUpdatePatchErrors,
  OrganizationMemberUpdateOrganizationMemberUpdatePatchResponses,
  PatchAgentV1AgentsAgentIdPatchData,
  PatchAgentV1AgentsAgentIdPatchErrors,
  PatchAgentV1AgentsAgentIdPatchResponses,
  PatchGroupScimV2GroupsGroupIdPatchData,
  PatchGroupScimV2GroupsGroupIdPatchErrors,
  PatchGroupScimV2GroupsGroupIdPatchResponses,
  PatchGuardrailGuardrailsGuardrailIdPatchData,
  PatchGuardrailGuardrailsGuardrailIdPatchErrors,
  PatchGuardrailGuardrailsGuardrailIdPatchResponses,
  PatchModelModelModelIdUpdatePatchData,
  PatchModelModelModelIdUpdatePatchErrors,
  PatchModelModelModelIdUpdatePatchResponses,
  PatchPromptPromptsPromptIdPatchData,
  PatchPromptPromptsPromptIdPatchErrors,
  PatchPromptPromptsPromptIdPatchResponses,
  PatchUserScimV2UsersUserIdPatchData,
  PatchUserScimV2UsersUserIdPatchErrors,
  PatchUserScimV2UsersUserIdPatchResponses,
  ProviderBudgetsProviderBudgetsGetData,
  ProviderBudgetsProviderBudgetsGetResponses,
  PublicModelHubInfoPublicModelHubInfoGetData,
  PublicModelHubInfoPublicModelHubInfoGetResponses,
  PublicModelHubPublicModelHubGetData,
  PublicModelHubPublicModelHubGetResponses,
  RagIngestRagIngestPostData,
  RagIngestRagIngestPostResponses,
  RagIngestV1RagIngestPostData,
  RagIngestV1RagIngestPostResponses,
  RegenerateKeyFnKeyKeyRegeneratePostData,
  RegenerateKeyFnKeyKeyRegeneratePostErrors,
  RegenerateKeyFnKeyKeyRegeneratePostResponses,
  RegenerateKeyFnKeyRegeneratePostData,
  RegenerateKeyFnKeyRegeneratePostErrors,
  RegenerateKeyFnKeyRegeneratePostResponses,
  RegisterClientMcpServerNameRegisterPostData,
  RegisterClientMcpServerNameRegisterPostErrors,
  RegisterClientMcpServerNameRegisterPostResponses,
  RegisterClientRegisterPostData,
  RegisterClientRegisterPostErrors,
  RegisterClientRegisterPostResponses,
  RemoveMcpServerV1McpServerServerIdDeleteData,
  RemoveMcpServerV1McpServerServerIdDeleteErrors,
  RemoveMcpServerV1McpServerServerIdDeleteResponses,
  RerankRerankPostData,
  RerankRerankPostResponses,
  RerankV1RerankPostData,
  RerankV1RerankPostResponses,
  RerankV2RerankPostData,
  RerankV2RerankPostResponses,
  ResponsesApiOpenaiV1ResponsesPostData,
  ResponsesApiOpenaiV1ResponsesPostResponses,
  ResponsesApiResponsesPostData,
  ResponsesApiResponsesPostResponses,
  ResponsesApiV1ResponsesPostData,
  ResponsesApiV1ResponsesPostResponses,
  RetrieveBatchBatchesBatchIdGetData,
  RetrieveBatchBatchesBatchIdGetErrors,
  RetrieveBatchBatchesBatchIdGetResponses,
  RetrieveBatchProviderV1BatchesBatchIdGetData,
  RetrieveBatchProviderV1BatchesBatchIdGetErrors,
  RetrieveBatchProviderV1BatchesBatchIdGetResponses,
  RetrieveBatchV1BatchesBatchIdGetData,
  RetrieveBatchV1BatchesBatchIdGetErrors,
  RetrieveBatchV1BatchesBatchIdGetResponses,
  RetrieveContainerContainersContainerIdGetData,
  RetrieveContainerContainersContainerIdGetErrors,
  RetrieveContainerContainersContainerIdGetResponses,
  RetrieveContainerV1ContainersContainerIdGetData,
  RetrieveContainerV1ContainersContainerIdGetErrors,
  RetrieveContainerV1ContainersContainerIdGetResponses,
  RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetData,
  RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetErrors,
  RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetResponses,
  RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetData,
  RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetErrors,
  RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetResponses,
  RunThreadThreadsThreadIdRunsPostData,
  RunThreadThreadsThreadIdRunsPostErrors,
  RunThreadThreadsThreadIdRunsPostResponses,
  RunThreadV1ThreadsThreadIdRunsPostData,
  RunThreadV1ThreadsThreadIdRunsPostErrors,
  RunThreadV1ThreadsThreadIdRunsPostResponses,
  SearchSearchPostData,
  SearchSearchPostErrors,
  SearchSearchPostResponses,
  SearchSearchSearchToolNamePostData,
  SearchSearchSearchToolNamePostErrors,
  SearchSearchSearchToolNamePostResponses,
  SearchV1SearchPostData,
  SearchV1SearchPostErrors,
  SearchV1SearchPostResponses,
  SearchV1SearchSearchToolNamePostData,
  SearchV1SearchSearchToolNamePostErrors,
  SearchV1SearchSearchToolNamePostResponses,
  SharedHealthCheckStatusEndpointHealthSharedStatusGetData,
  SharedHealthCheckStatusEndpointHealthSharedStatusGetResponses,
  SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetData,
  SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetErrors,
  SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetResponses,
  TeamInfoTeamInfoGetData,
  TeamInfoTeamInfoGetErrors,
  TeamInfoTeamInfoGetResponses,
  TeamMemberAddTeamMemberAddPostData,
  TeamMemberAddTeamMemberAddPostErrors,
  TeamMemberAddTeamMemberAddPostResponses,
  TeamMemberDeleteTeamMemberDeletePostData,
  TeamMemberDeleteTeamMemberDeletePostErrors,
  TeamMemberDeleteTeamMemberDeletePostResponses,
  TeamMemberPermissionsTeamPermissionsListGetData,
  TeamMemberPermissionsTeamPermissionsListGetErrors,
  TeamMemberPermissionsTeamPermissionsListGetResponses,
  TeamMemberUpdateTeamMemberUpdatePostData,
  TeamMemberUpdateTeamMemberUpdatePostErrors,
  TeamMemberUpdateTeamMemberUpdatePostResponses,
  TeamModelAddTeamModelAddPostData,
  TeamModelAddTeamModelAddPostErrors,
  TeamModelAddTeamModelAddPostResponses,
  TeamModelDeleteTeamModelDeletePostData,
  TeamModelDeleteTeamModelDeletePostErrors,
  TeamModelDeleteTeamModelDeletePostResponses,
  TestCacheConnectionCacheSettingsTestPostData,
  TestCacheConnectionCacheSettingsTestPostErrors,
  TestCacheConnectionCacheSettingsTestPostResponses,
  TestConnectionMcpRestTestConnectionPostData,
  TestConnectionMcpRestTestConnectionPostErrors,
  TestConnectionMcpRestTestConnectionPostResponses,
  TestEndpointTestGetData,
  TestEndpointTestGetResponses,
  TestModelConnectionHealthTestConnectionPostData,
  TestModelConnectionHealthTestConnectionPostErrors,
  TestModelConnectionHealthTestConnectionPostResponses,
  TestPromptPromptsTestPostData,
  TestPromptPromptsTestPostErrors,
  TestPromptPromptsTestPostResponses,
  TestSearchToolConnectionSearchToolsTestConnectionPostData,
  TestSearchToolConnectionSearchToolsTestConnectionPostErrors,
  TestSearchToolConnectionSearchToolsTestConnectionPostResponses,
  TestToolsListMcpRestTestToolsListPostData,
  TestToolsListMcpRestTestToolsListPostErrors,
  TestToolsListMcpRestTestToolsListPostResponses,
  TokenCounterUtilsTokenCounterPostData,
  TokenCounterUtilsTokenCounterPostErrors,
  TokenCounterUtilsTokenCounterPostResponses,
  TokenEndpointMcpServerNameTokenPostData,
  TokenEndpointMcpServerNameTokenPostErrors,
  TokenEndpointMcpServerNameTokenPostResponses,
  TokenEndpointTokenPostData,
  TokenEndpointTokenPostErrors,
  TokenEndpointTokenPostResponses,
  TransformRequestUtilsTransformRequestPostData,
  TransformRequestUtilsTransformRequestPostErrors,
  TransformRequestUtilsTransformRequestPostResponses,
  UiViewSpendLogsSpendLogsV2GetData,
  UiViewSpendLogsSpendLogsV2GetErrors,
  UiViewSpendLogsSpendLogsV2GetResponses,
  UnblockKeyKeyUnblockPostData,
  UnblockKeyKeyUnblockPostErrors,
  UnblockKeyKeyUnblockPostResponses,
  UnblockTeamTeamUnblockPostData,
  UnblockTeamTeamUnblockPostErrors,
  UnblockTeamTeamUnblockPostResponses,
  UnblockUserCustomerUnblockPostData,
  UnblockUserCustomerUnblockPostErrors,
  UnblockUserCustomerUnblockPostResponses,
  UpdateAccessGroupAccessGroupAccessGroupUpdatePutData,
  UpdateAccessGroupAccessGroupAccessGroupUpdatePutErrors,
  UpdateAccessGroupAccessGroupAccessGroupUpdatePutResponses,
  UpdateAgentV1AgentsAgentIdPutData,
  UpdateAgentV1AgentsAgentIdPutErrors,
  UpdateAgentV1AgentsAgentIdPutResponses,
  UpdateBudgetBudgetUpdatePostData,
  UpdateBudgetBudgetUpdatePostErrors,
  UpdateBudgetBudgetUpdatePostResponses,
  UpdateCacheSettingsCacheSettingsPostData,
  UpdateCacheSettingsCacheSettingsPostErrors,
  UpdateCacheSettingsCacheSettingsPostResponses,
  UpdateCloudzeroSettingsCloudzeroSettingsPutData,
  UpdateCloudzeroSettingsCloudzeroSettingsPutErrors,
  UpdateCloudzeroSettingsCloudzeroSettingsPutResponses,
  UpdateCostDiscountConfigConfigCostDiscountConfigPatchData,
  UpdateCostDiscountConfigConfigCostDiscountConfigPatchErrors,
  UpdateCostDiscountConfigConfigCostDiscountConfigPatchResponses,
  UpdateCredentialCredentialsCredentialNamePatchData,
  UpdateCredentialCredentialsCredentialNamePatchErrors,
  UpdateCredentialCredentialsCredentialNamePatchResponses,
  UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchData,
  UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchErrors,
  UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchResponses,
  UpdateEndUserCustomerUpdatePostData,
  UpdateEndUserCustomerUpdatePostErrors,
  UpdateEndUserCustomerUpdatePostResponses,
  UpdateGroupScimV2GroupsGroupIdPutData,
  UpdateGroupScimV2GroupsGroupIdPutErrors,
  UpdateGroupScimV2GroupsGroupIdPutResponses,
  UpdateGuardrailGuardrailsGuardrailIdPutData,
  UpdateGuardrailGuardrailsGuardrailIdPutErrors,
  UpdateGuardrailGuardrailsGuardrailIdPutResponses,
  UpdateInternalUserSettingsUpdateInternalUserSettingsPatchData,
  UpdateInternalUserSettingsUpdateInternalUserSettingsPatchErrors,
  UpdateInternalUserSettingsUpdateInternalUserSettingsPatchResponses,
  UpdateKeyFnKeyUpdatePostData,
  UpdateKeyFnKeyUpdatePostErrors,
  UpdateKeyFnKeyUpdatePostResponses,
  UpdateModelModelUpdatePostData,
  UpdateModelModelUpdatePostErrors,
  UpdateModelModelUpdatePostResponses,
  UpdateOrganizationOrganizationUpdatePatchData,
  UpdateOrganizationOrganizationUpdatePatchResponses,
  UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostData,
  UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostErrors,
  UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostResponses,
  UpdatePromptPromptsPromptIdPutData,
  UpdatePromptPromptsPromptIdPutErrors,
  UpdatePromptPromptsPromptIdPutResponses,
  UpdatePublicModelGroupsModelGroupMakePublicPostData,
  UpdatePublicModelGroupsModelGroupMakePublicPostErrors,
  UpdatePublicModelGroupsModelGroupMakePublicPostResponses,
  UpdateSearchToolSearchToolsSearchToolIdPutData,
  UpdateSearchToolSearchToolsSearchToolIdPutErrors,
  UpdateSearchToolSearchToolsSearchToolIdPutResponses,
  UpdateSsoSettingsUpdateSsoSettingsPatchData,
  UpdateSsoSettingsUpdateSsoSettingsPatchErrors,
  UpdateSsoSettingsUpdateSsoSettingsPatchResponses,
  UpdateTagTagUpdatePostData,
  UpdateTagTagUpdatePostErrors,
  UpdateTagTagUpdatePostResponses,
  UpdateTeamMemberPermissionsTeamPermissionsUpdatePostData,
  UpdateTeamMemberPermissionsTeamPermissionsUpdatePostErrors,
  UpdateTeamMemberPermissionsTeamPermissionsUpdatePostResponses,
  UpdateTeamTeamUpdatePostData,
  UpdateTeamTeamUpdatePostErrors,
  UpdateTeamTeamUpdatePostResponses,
  UpdateUiThemeSettingsUpdateUiThemeSettingsPatchData,
  UpdateUiThemeSettingsUpdateUiThemeSettingsPatchErrors,
  UpdateUiThemeSettingsUpdateUiThemeSettingsPatchResponses,
  UpdateUsefulLinksModelHubUpdateUsefulLinksPostData,
  UpdateUsefulLinksModelHubUpdateUsefulLinksPostErrors,
  UpdateUsefulLinksModelHubUpdateUsefulLinksPostResponses,
  UpdateUserScimV2UsersUserIdPutData,
  UpdateUserScimV2UsersUserIdPutErrors,
  UpdateUserScimV2UsersUserIdPutResponses,
  UpdateVectorStoreVectorStoreUpdatePostData,
  UpdateVectorStoreVectorStoreUpdatePostErrors,
  UpdateVectorStoreVectorStoreUpdatePostResponses,
  UploadLogoUploadLogoPostData,
  UploadLogoUploadLogoPostErrors,
  UploadLogoUploadLogoPostResponses,
  UserInfoUserInfoGetData,
  UserInfoUserInfoGetErrors,
  UserInfoUserInfoGetResponses,
  UserUpdateUserUpdatePostData,
  UserUpdateUserUpdatePostErrors,
  UserUpdateUserUpdatePostResponses,
  ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostData,
  ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostErrors,
  ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostResponses,
  VectorStoreCreateV1VectorStoresPostData,
  VectorStoreCreateV1VectorStoresPostResponses,
  VectorStoreCreateVectorStoresPostData,
  VectorStoreCreateVectorStoresPostResponses,
  VectorStoreFileContentV1VectorStoresVectorStoreIdFilesFileIdContentGetData,
  VectorStoreFileContentV1VectorStoresVectorStoreIdFilesFileIdContentGetErrors,
  VectorStoreFileContentV1VectorStoresVectorStoreIdFilesFileIdContentGetResponses,
  VectorStoreFileContentVectorStoresVectorStoreIdFilesFileIdContentGetData,
  VectorStoreFileContentVectorStoresVectorStoreIdFilesFileIdContentGetErrors,
  VectorStoreFileContentVectorStoresVectorStoreIdFilesFileIdContentGetResponses,
  VectorStoreFileCreateV1VectorStoresVectorStoreIdFilesPostData,
  VectorStoreFileCreateV1VectorStoresVectorStoreIdFilesPostErrors,
  VectorStoreFileCreateV1VectorStoresVectorStoreIdFilesPostResponses,
  VectorStoreFileCreateVectorStoresVectorStoreIdFilesPostData,
  VectorStoreFileCreateVectorStoresVectorStoreIdFilesPostErrors,
  VectorStoreFileCreateVectorStoresVectorStoreIdFilesPostResponses,
  VectorStoreFileDeleteV1VectorStoresVectorStoreIdFilesFileIdDeleteData,
  VectorStoreFileDeleteV1VectorStoresVectorStoreIdFilesFileIdDeleteErrors,
  VectorStoreFileDeleteV1VectorStoresVectorStoreIdFilesFileIdDeleteResponses,
  VectorStoreFileDeleteVectorStoresVectorStoreIdFilesFileIdDeleteData,
  VectorStoreFileDeleteVectorStoresVectorStoreIdFilesFileIdDeleteErrors,
  VectorStoreFileDeleteVectorStoresVectorStoreIdFilesFileIdDeleteResponses,
  VectorStoreFileListV1VectorStoresVectorStoreIdFilesGetData,
  VectorStoreFileListV1VectorStoresVectorStoreIdFilesGetErrors,
  VectorStoreFileListV1VectorStoresVectorStoreIdFilesGetResponses,
  VectorStoreFileListVectorStoresVectorStoreIdFilesGetData,
  VectorStoreFileListVectorStoresVectorStoreIdFilesGetErrors,
  VectorStoreFileListVectorStoresVectorStoreIdFilesGetResponses,
  VectorStoreFileRetrieveV1VectorStoresVectorStoreIdFilesFileIdGetData,
  VectorStoreFileRetrieveV1VectorStoresVectorStoreIdFilesFileIdGetErrors,
  VectorStoreFileRetrieveV1VectorStoresVectorStoreIdFilesFileIdGetResponses,
  VectorStoreFileRetrieveVectorStoresVectorStoreIdFilesFileIdGetData,
  VectorStoreFileRetrieveVectorStoresVectorStoreIdFilesFileIdGetErrors,
  VectorStoreFileRetrieveVectorStoresVectorStoreIdFilesFileIdGetResponses,
  VectorStoreFileUpdateV1VectorStoresVectorStoreIdFilesFileIdPostData,
  VectorStoreFileUpdateV1VectorStoresVectorStoreIdFilesFileIdPostErrors,
  VectorStoreFileUpdateV1VectorStoresVectorStoreIdFilesFileIdPostResponses,
  VectorStoreFileUpdateVectorStoresVectorStoreIdFilesFileIdPostData,
  VectorStoreFileUpdateVectorStoresVectorStoreIdFilesFileIdPostErrors,
  VectorStoreFileUpdateVectorStoresVectorStoreIdFilesFileIdPostResponses,
  VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostData,
  VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostErrors,
  VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostResponses,
  VectorStoreSearchVectorStoresVectorStoreIdSearchPostData,
  VectorStoreSearchVectorStoresVectorStoreIdSearchPostErrors,
  VectorStoreSearchVectorStoresVectorStoreIdSearchPostResponses,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost2Data,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost2Errors,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost2Responses,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost3Data,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost3Errors,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost3Responses,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost4Data,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost4Errors,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost4Responses,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost5Data,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost5Errors,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost5Responses,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPostData,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPostErrors,
  VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPostResponses,
  VertexProxyRouteVertexAiEndpointPost2Data,
  VertexProxyRouteVertexAiEndpointPost2Errors,
  VertexProxyRouteVertexAiEndpointPost2Responses,
  VertexProxyRouteVertexAiEndpointPost3Data,
  VertexProxyRouteVertexAiEndpointPost3Errors,
  VertexProxyRouteVertexAiEndpointPost3Responses,
  VertexProxyRouteVertexAiEndpointPost4Data,
  VertexProxyRouteVertexAiEndpointPost4Errors,
  VertexProxyRouteVertexAiEndpointPost4Responses,
  VertexProxyRouteVertexAiEndpointPost5Data,
  VertexProxyRouteVertexAiEndpointPost5Errors,
  VertexProxyRouteVertexAiEndpointPost5Responses,
  VertexProxyRouteVertexAiEndpointPostData,
  VertexProxyRouteVertexAiEndpointPostErrors,
  VertexProxyRouteVertexAiEndpointPostResponses,
  VideoContentV1VideosVideoIdContentGetData,
  VideoContentV1VideosVideoIdContentGetErrors,
  VideoContentV1VideosVideoIdContentGetResponses,
  VideoContentVideosVideoIdContentGetData,
  VideoContentVideosVideoIdContentGetErrors,
  VideoContentVideosVideoIdContentGetResponses,
  VideoGenerationV1VideosPostData,
  VideoGenerationV1VideosPostErrors,
  VideoGenerationV1VideosPostResponses,
  VideoGenerationVideosPostData,
  VideoGenerationVideosPostErrors,
  VideoGenerationVideosPostResponses,
  VideoListV1VideosGetData,
  VideoListV1VideosGetResponses,
  VideoListVideosGetData,
  VideoListVideosGetResponses,
  VideoRemixV1VideosVideoIdRemixPostData,
  VideoRemixV1VideosVideoIdRemixPostErrors,
  VideoRemixV1VideosVideoIdRemixPostResponses,
  VideoRemixVideosVideoIdRemixPostData,
  VideoRemixVideosVideoIdRemixPostErrors,
  VideoRemixVideosVideoIdRemixPostResponses,
  VideoStatusV1VideosVideoIdGetData,
  VideoStatusV1VideosVideoIdGetErrors,
  VideoStatusV1VideosVideoIdGetResponses,
  VideoStatusVideosVideoIdGetData,
  VideoStatusVideosVideoIdGetErrors,
  VideoStatusVideosVideoIdGetResponses,
  ViewSpendLogsSpendLogsGetData,
  ViewSpendLogsSpendLogsGetErrors,
  ViewSpendLogsSpendLogsGetResponses,
  ViewSpendTagsSpendTagsGetData,
  ViewSpendTagsSpendTagsGetErrors,
  ViewSpendTagsSpendTagsGetResponses,
  VllmProxyRouteVllmEndpointPost2Data,
  VllmProxyRouteVllmEndpointPost2Errors,
  VllmProxyRouteVllmEndpointPost2Responses,
  VllmProxyRouteVllmEndpointPost3Data,
  VllmProxyRouteVllmEndpointPost3Errors,
  VllmProxyRouteVllmEndpointPost3Responses,
  VllmProxyRouteVllmEndpointPost4Data,
  VllmProxyRouteVllmEndpointPost4Errors,
  VllmProxyRouteVllmEndpointPost4Responses,
  VllmProxyRouteVllmEndpointPost5Data,
  VllmProxyRouteVllmEndpointPost5Errors,
  VllmProxyRouteVllmEndpointPost5Responses,
  VllmProxyRouteVllmEndpointPostData,
  VllmProxyRouteVllmEndpointPostErrors,
  VllmProxyRouteVllmEndpointPostResponses,
  WebsocketRealtimeWebsocketEndpoint2Data,
  WebsocketRealtimeWebsocketEndpointData,
  WebsocketVertexAiLivePassthroughEndpointData,
} from './types.gen';

export type Options<
  TData extends TDataShape = TDataShape,
  ThrowOnError extends boolean = boolean,
> = Options2<TData, ThrowOnError> & {
  /**
   * You can provide a client instance returned by `createClient()` instead of
   * individual options. This might be also useful if you want to implement a
   * custom client.
   */
  client?: Client;
  /**
   * You can pass arbitrary values through the `meta` object. This can be
   * used to access values that aren't defined as part of the SDK function.
   */
  meta?: Record<string, unknown>;
};

/**
 * Model List
 *
 * Use `/model/info` - to get detailed model information, example - pricing, mode, etc.
 *
 * This is just for compatibility with openai projects like aider.
 *
 * Query Parameters:
 * - include_metadata: Include additional metadata in the response with fallback information
 * - fallback_type: Type of fallbacks to include ("general", "context_window", "content_policy")
 * Defaults to "general" when include_metadata=true
 */
export const modelListModelsGet = <ThrowOnError extends boolean = false>(
  options?: Options<ModelListModelsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ModelListModelsGetResponses,
    ModelListModelsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/models',
    ...options,
  });

/**
 * Model List
 *
 * Use `/model/info` - to get detailed model information, example - pricing, mode, etc.
 *
 * This is just for compatibility with openai projects like aider.
 *
 * Query Parameters:
 * - include_metadata: Include additional metadata in the response with fallback information
 * - fallback_type: Type of fallbacks to include ("general", "context_window", "content_policy")
 * Defaults to "general" when include_metadata=true
 */
export const modelListV1ModelsGet = <ThrowOnError extends boolean = false>(
  options?: Options<ModelListV1ModelsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ModelListV1ModelsGetResponses,
    ModelListV1ModelsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/models',
    ...options,
  });

/**
 * Model Info
 *
 * Retrieve information about a specific model accessible to your API key.
 *
 * Returns model details only if the model is available to your API key/team.
 * Returns 404 if the model doesn't exist or is not accessible.
 *
 * Follows OpenAI API specification for individual model retrieval.
 * https://platform.openai.com/docs/api-reference/models/retrieve
 */
export const modelInfoModelsModelIdGet = <ThrowOnError extends boolean = false>(
  options: Options<ModelInfoModelsModelIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    ModelInfoModelsModelIdGetResponses,
    ModelInfoModelsModelIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/models/{model_id}',
    ...options,
  });

/**
 * Model Info
 *
 * Retrieve information about a specific model accessible to your API key.
 *
 * Returns model details only if the model is available to your API key/team.
 * Returns 404 if the model doesn't exist or is not accessible.
 *
 * Follows OpenAI API specification for individual model retrieval.
 * https://platform.openai.com/docs/api-reference/models/retrieve
 */
export const modelInfoV1ModelsModelIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<ModelInfoV1ModelsModelIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    ModelInfoV1ModelsModelIdGetResponses,
    ModelInfoV1ModelsModelIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/models/{model_id}',
    ...options,
  });

/**
 * Chat Completion
 *
 * Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/chat/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "model": "gpt-4o",
 * "messages": [
 * {
 * "role": "user",
 * "content": "Hello!"
 * }
 * ]
 * }'
 * ```
 */
export const chatCompletionOpenaiDeploymentsModelChatCompletionsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    ChatCompletionOpenaiDeploymentsModelChatCompletionsPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    ChatCompletionOpenaiDeploymentsModelChatCompletionsPostResponses,
    ChatCompletionOpenaiDeploymentsModelChatCompletionsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/deployments/{model}/chat/completions',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Chat Completion
 *
 * Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/chat/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "model": "gpt-4o",
 * "messages": [
 * {
 * "role": "user",
 * "content": "Hello!"
 * }
 * ]
 * }'
 * ```
 */
export const chatCompletionEnginesModelChatCompletionsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    ChatCompletionEnginesModelChatCompletionsPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    ChatCompletionEnginesModelChatCompletionsPostResponses,
    ChatCompletionEnginesModelChatCompletionsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/engines/{model}/chat/completions',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Chat Completion
 *
 * Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/chat/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "model": "gpt-4o",
 * "messages": [
 * {
 * "role": "user",
 * "content": "Hello!"
 * }
 * ]
 * }'
 * ```
 */
export const chatCompletionChatCompletionsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<ChatCompletionChatCompletionsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    ChatCompletionChatCompletionsPostResponses,
    ChatCompletionChatCompletionsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/chat/completions',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Chat Completion
 *
 * Follows the exact same API spec as `OpenAI's Chat API https://platform.openai.com/docs/api-reference/chat`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/chat/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "model": "gpt-4o",
 * "messages": [
 * {
 * "role": "user",
 * "content": "Hello!"
 * }
 * ]
 * }'
 * ```
 */
export const chatCompletionV1ChatCompletionsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<ChatCompletionV1ChatCompletionsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    ChatCompletionV1ChatCompletionsPostResponses,
    ChatCompletionV1ChatCompletionsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/chat/completions',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Completion
 *
 * Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "model": "gpt-3.5-turbo-instruct",
 * "prompt": "Once upon a time",
 * "max_tokens": 50,
 * "temperature": 0.7
 * }'
 * ```
 */
export const completionOpenaiDeploymentsModelCompletionsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    CompletionOpenaiDeploymentsModelCompletionsPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    CompletionOpenaiDeploymentsModelCompletionsPostResponses,
    CompletionOpenaiDeploymentsModelCompletionsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/deployments/{model}/completions',
    ...options,
  });

/**
 * Completion
 *
 * Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "model": "gpt-3.5-turbo-instruct",
 * "prompt": "Once upon a time",
 * "max_tokens": 50,
 * "temperature": 0.7
 * }'
 * ```
 */
export const completionEnginesModelCompletionsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CompletionEnginesModelCompletionsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CompletionEnginesModelCompletionsPostResponses,
    CompletionEnginesModelCompletionsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/engines/{model}/completions',
    ...options,
  });

/**
 * Completion
 *
 * Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "model": "gpt-3.5-turbo-instruct",
 * "prompt": "Once upon a time",
 * "max_tokens": 50,
 * "temperature": 0.7
 * }'
 * ```
 */
export const completionCompletionsPost = <ThrowOnError extends boolean = false>(
  options?: Options<CompletionCompletionsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CompletionCompletionsPostResponses,
    CompletionCompletionsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/completions',
    ...options,
  });

/**
 * Completion
 *
 * Follows the exact same API spec as `OpenAI's Completions API https://platform.openai.com/docs/api-reference/completions`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/completions
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "model": "gpt-3.5-turbo-instruct",
 * "prompt": "Once upon a time",
 * "max_tokens": 50,
 * "temperature": 0.7
 * }'
 * ```
 */
export const completionV1CompletionsPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<CompletionV1CompletionsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CompletionV1CompletionsPostResponses,
    CompletionV1CompletionsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/completions',
    ...options,
  });

/**
 * Embeddings
 *
 * Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/embeddings
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "model": "text-embedding-ada-002",
 * "input": "The quick brown fox jumps over the lazy dog"
 * }'
 * ```
 */
export const embeddingsOpenaiDeploymentsModelEmbeddingsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    EmbeddingsOpenaiDeploymentsModelEmbeddingsPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    EmbeddingsOpenaiDeploymentsModelEmbeddingsPostResponses,
    EmbeddingsOpenaiDeploymentsModelEmbeddingsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/deployments/{model}/embeddings',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Embeddings
 *
 * Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/embeddings
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "model": "text-embedding-ada-002",
 * "input": "The quick brown fox jumps over the lazy dog"
 * }'
 * ```
 */
export const embeddingsEnginesModelEmbeddingsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<EmbeddingsEnginesModelEmbeddingsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    EmbeddingsEnginesModelEmbeddingsPostResponses,
    EmbeddingsEnginesModelEmbeddingsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/engines/{model}/embeddings',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Embeddings
 *
 * Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/embeddings
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "model": "text-embedding-ada-002",
 * "input": "The quick brown fox jumps over the lazy dog"
 * }'
 * ```
 */
export const embeddingsEmbeddingsPost = <ThrowOnError extends boolean = false>(
  options: Options<EmbeddingsEmbeddingsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    EmbeddingsEmbeddingsPostResponses,
    EmbeddingsEmbeddingsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/embeddings',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Embeddings
 *
 * Follows the exact same API spec as `OpenAI's Embeddings API https://platform.openai.com/docs/api-reference/embeddings`
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/embeddings
 * -H "Content-Type: application/json"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "model": "text-embedding-ada-002",
 * "input": "The quick brown fox jumps over the lazy dog"
 * }'
 * ```
 */
export const embeddingsV1EmbeddingsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<EmbeddingsV1EmbeddingsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    EmbeddingsV1EmbeddingsPostResponses,
    EmbeddingsV1EmbeddingsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/embeddings',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Moderations
 *
 * The moderations endpoint is a tool you can use to check whether content complies with an LLM Providers policies.
 * Quick Start
 * ```
 * curl --location 'http://0.0.0.0:4000/moderations'     --header 'Content-Type: application/json'     --header 'Authorization: Bearer sk-1234'     --data '{"input": "Sample text goes here", "model": "text-moderation-stable"}'
 * ```
 */
export const moderationsModerationsPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ModerationsModerationsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    ModerationsModerationsPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/moderations',
    ...options,
  });

/**
 * Moderations
 *
 * The moderations endpoint is a tool you can use to check whether content complies with an LLM Providers policies.
 * Quick Start
 * ```
 * curl --location 'http://0.0.0.0:4000/moderations'     --header 'Content-Type: application/json'     --header 'Authorization: Bearer sk-1234'     --data '{"input": "Sample text goes here", "model": "text-moderation-stable"}'
 * ```
 */
export const moderationsV1ModerationsPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ModerationsV1ModerationsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    ModerationsV1ModerationsPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/moderations',
    ...options,
  });

/**
 * Audio Speech
 *
 * Same params as:
 *
 * https://platform.openai.com/docs/api-reference/audio/createSpeech
 */
export const audioSpeechAudioSpeechPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<AudioSpeechAudioSpeechPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    AudioSpeechAudioSpeechPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/audio/speech',
    ...options,
  });

/**
 * Audio Speech
 *
 * Same params as:
 *
 * https://platform.openai.com/docs/api-reference/audio/createSpeech
 */
export const audioSpeechV1AudioSpeechPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<AudioSpeechV1AudioSpeechPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    AudioSpeechV1AudioSpeechPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/audio/speech',
    ...options,
  });

/**
 * Audio Transcriptions
 *
 * Same params as:
 *
 * https://platform.openai.com/docs/api-reference/audio/createTranscription?lang=curl
 */
export const audioTranscriptionsAudioTranscriptionsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AudioTranscriptionsAudioTranscriptionsPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    AudioTranscriptionsAudioTranscriptionsPostResponses,
    AudioTranscriptionsAudioTranscriptionsPostErrors,
    ThrowOnError
  >({
    ...formDataBodySerializer,
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/audio/transcriptions',
    ...options,
    headers: {
      'Content-Type': null,
      ...options.headers,
    },
  });

/**
 * Audio Transcriptions
 *
 * Same params as:
 *
 * https://platform.openai.com/docs/api-reference/audio/createTranscription?lang=curl
 */
export const audioTranscriptionsV1AudioTranscriptionsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AudioTranscriptionsV1AudioTranscriptionsPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    AudioTranscriptionsV1AudioTranscriptionsPostResponses,
    AudioTranscriptionsV1AudioTranscriptionsPostErrors,
    ThrowOnError
  >({
    ...formDataBodySerializer,
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/audio/transcriptions',
    ...options,
    headers: {
      'Content-Type': null,
      ...options.headers,
    },
  });

/**
 * Get Assistants
 *
 * Returns a list of assistants.
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/listAssistants
 */
export const getAssistantsAssistantsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetAssistantsAssistantsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetAssistantsAssistantsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/assistants',
    ...options,
  });

/**
 * Create Assistant
 *
 * Create assistant
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 */
export const createAssistantAssistantsPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<CreateAssistantAssistantsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CreateAssistantAssistantsPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/assistants',
    ...options,
  });

/**
 * Get Assistants
 *
 * Returns a list of assistants.
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/listAssistants
 */
export const getAssistantsV1AssistantsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetAssistantsV1AssistantsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetAssistantsV1AssistantsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/assistants',
    ...options,
  });

/**
 * Create Assistant
 *
 * Create assistant
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 */
export const createAssistantV1AssistantsPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<CreateAssistantV1AssistantsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CreateAssistantV1AssistantsPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/assistants',
    ...options,
  });

/**
 * Delete Assistant
 *
 * Delete assistant
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 */
export const deleteAssistantAssistantsAssistantIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DeleteAssistantAssistantsAssistantIdDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    DeleteAssistantAssistantsAssistantIdDeleteResponses,
    DeleteAssistantAssistantsAssistantIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/assistants/{assistant_id}',
    ...options,
  });

/**
 * Delete Assistant
 *
 * Delete assistant
 *
 * API Reference docs - https://platform.openai.com/docs/api-reference/assistants/createAssistant
 */
export const deleteAssistantV1AssistantsAssistantIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DeleteAssistantV1AssistantsAssistantIdDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    DeleteAssistantV1AssistantsAssistantIdDeleteResponses,
    DeleteAssistantV1AssistantsAssistantIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/assistants/{assistant_id}',
    ...options,
  });

/**
 * Create Threads
 *
 * Create a thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/threads/createThread
 */
export const createThreadsThreadsPost = <ThrowOnError extends boolean = false>(
  options?: Options<CreateThreadsThreadsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CreateThreadsThreadsPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/threads',
    ...options,
  });

/**
 * Create Threads
 *
 * Create a thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/threads/createThread
 */
export const createThreadsV1ThreadsPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<CreateThreadsV1ThreadsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CreateThreadsV1ThreadsPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/threads',
    ...options,
  });

/**
 * Get Thread
 *
 * Retrieves a thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/threads/getThread
 */
export const getThreadThreadsThreadIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetThreadThreadsThreadIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetThreadThreadsThreadIdGetResponses,
    GetThreadThreadsThreadIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/threads/{thread_id}',
    ...options,
  });

/**
 * Get Thread
 *
 * Retrieves a thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/threads/getThread
 */
export const getThreadV1ThreadsThreadIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetThreadV1ThreadsThreadIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetThreadV1ThreadsThreadIdGetResponses,
    GetThreadV1ThreadsThreadIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/threads/{thread_id}',
    ...options,
  });

/**
 * Get Messages
 *
 * Returns a list of messages for a given thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/messages/listMessages
 */
export const getMessagesThreadsThreadIdMessagesGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetMessagesThreadsThreadIdMessagesGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetMessagesThreadsThreadIdMessagesGetResponses,
    GetMessagesThreadsThreadIdMessagesGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/threads/{thread_id}/messages',
    ...options,
  });

/**
 * Add Messages
 *
 * Create a message.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/messages/createMessage
 */
export const addMessagesThreadsThreadIdMessagesPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AddMessagesThreadsThreadIdMessagesPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    AddMessagesThreadsThreadIdMessagesPostResponses,
    AddMessagesThreadsThreadIdMessagesPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/threads/{thread_id}/messages',
    ...options,
  });

/**
 * Get Messages
 *
 * Returns a list of messages for a given thread.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/messages/listMessages
 */
export const getMessagesV1ThreadsThreadIdMessagesGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetMessagesV1ThreadsThreadIdMessagesGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetMessagesV1ThreadsThreadIdMessagesGetResponses,
    GetMessagesV1ThreadsThreadIdMessagesGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/threads/{thread_id}/messages',
    ...options,
  });

/**
 * Add Messages
 *
 * Create a message.
 *
 * API Reference - https://platform.openai.com/docs/api-reference/messages/createMessage
 */
export const addMessagesV1ThreadsThreadIdMessagesPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AddMessagesV1ThreadsThreadIdMessagesPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    AddMessagesV1ThreadsThreadIdMessagesPostResponses,
    AddMessagesV1ThreadsThreadIdMessagesPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/threads/{thread_id}/messages',
    ...options,
  });

/**
 * Run Thread
 *
 * Create a run.
 *
 * API Reference: https://platform.openai.com/docs/api-reference/runs/createRun
 */
export const runThreadThreadsThreadIdRunsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<RunThreadThreadsThreadIdRunsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    RunThreadThreadsThreadIdRunsPostResponses,
    RunThreadThreadsThreadIdRunsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/threads/{thread_id}/runs',
    ...options,
  });

/**
 * Run Thread
 *
 * Create a run.
 *
 * API Reference: https://platform.openai.com/docs/api-reference/runs/createRun
 */
export const runThreadV1ThreadsThreadIdRunsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<RunThreadV1ThreadsThreadIdRunsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    RunThreadV1ThreadsThreadIdRunsPostResponses,
    RunThreadV1ThreadsThreadIdRunsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/threads/{thread_id}/runs',
    ...options,
  });

/**
 * Token Counter
 *
 * Args:
 * request: TokenCountRequest
 * call_endpoint: bool - When set to "True" it will call the token counting endpoint - e.g Anthropic or Google AI Studio Token Counting APIs.
 *
 * Returns:
 * TokenCountResponse
 */
export const tokenCounterUtilsTokenCounterPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<TokenCounterUtilsTokenCounterPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TokenCounterUtilsTokenCounterPostResponses,
    TokenCounterUtilsTokenCounterPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/utils/token_counter',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Supported Openai Params
 *
 * Returns supported openai params for a given litellm model name
 *
 * e.g. `gpt-4` vs `gpt-3.5-turbo`
 *
 * Example curl:
 * ```
 * curl -X GET --location 'http://localhost:4000/utils/supported_openai_params?model=gpt-3.5-turbo-16k'         --header 'Authorization: Bearer sk-1234'
 * ```
 */
export const supportedOpenaiParamsUtilsSupportedOpenaiParamsGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetResponses,
    SupportedOpenaiParamsUtilsSupportedOpenaiParamsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/utils/supported_openai_params',
    ...options,
  });

/**
 * Transform Request
 */
export const transformRequestUtilsTransformRequestPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<TransformRequestUtilsTransformRequestPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TransformRequestUtilsTransformRequestPostResponses,
    TransformRequestUtilsTransformRequestPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/utils/transform_request',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Model Info V1
 *
 * Provides more info about each model in /models, including config.yaml descriptions (except api key and api base)
 *
 * Parameters:
 * litellm_model_id: Optional[str] = None (this is the value of `x-litellm-model-id` returned in response headers)
 *
 * - When litellm_model_id is passed, it will return the info for that specific model
 * - When litellm_model_id is not passed, it will return the info for all models
 *
 * Returns:
 * Returns a dictionary containing information about each model.
 *
 * Example Response:
 * ```json
 * {
 * "data": [
 * {
 * "model_name": "fake-openai-endpoint",
 * "litellm_params": {
 * "api_base": "https://exampleopenaiendpoint-production.up.railway.app/",
 * "model": "openai/fake"
 * },
 * "model_info": {
 * "id": "112f74fab24a7a5245d2ced3536dd8f5f9192c57ee6e332af0f0512e08bed5af",
 * "db_model": false
 * }
 * }
 * ]
 * }
 *
 * ```
 */
export const modelInfoV1V1ModelInfoGet = <ThrowOnError extends boolean = false>(
  options?: Options<ModelInfoV1V1ModelInfoGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ModelInfoV1V1ModelInfoGetResponses,
    ModelInfoV1V1ModelInfoGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/model/info',
    ...options,
  });

/**
 * Model Info V1
 *
 * Provides more info about each model in /models, including config.yaml descriptions (except api key and api base)
 *
 * Parameters:
 * litellm_model_id: Optional[str] = None (this is the value of `x-litellm-model-id` returned in response headers)
 *
 * - When litellm_model_id is passed, it will return the info for that specific model
 * - When litellm_model_id is not passed, it will return the info for all models
 *
 * Returns:
 * Returns a dictionary containing information about each model.
 *
 * Example Response:
 * ```json
 * {
 * "data": [
 * {
 * "model_name": "fake-openai-endpoint",
 * "litellm_params": {
 * "api_base": "https://exampleopenaiendpoint-production.up.railway.app/",
 * "model": "openai/fake"
 * },
 * "model_info": {
 * "id": "112f74fab24a7a5245d2ced3536dd8f5f9192c57ee6e332af0f0512e08bed5af",
 * "db_model": false
 * }
 * }
 * ]
 * }
 *
 * ```
 */
export const modelInfoV1ModelInfoGet = <ThrowOnError extends boolean = false>(
  options?: Options<ModelInfoV1ModelInfoGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ModelInfoV1ModelInfoGetResponses,
    ModelInfoV1ModelInfoGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/model/info',
    ...options,
  });

/**
 * Model Group Info
 *
 * Get information about all the deployments on litellm proxy, including config.yaml descriptions (except api key and api base)
 *
 * - /model_group/info returns all model groups. End users of proxy should use /model_group/info since those models will be used for /chat/completions, /embeddings, etc.
 * - /model_group/info?model_group=rerank-english-v3.0 returns all model groups for a specific model group (`model_name` in config.yaml)
 *
 *
 *
 * Example Request (All Models):
 * ```shell
 * curl -X 'GET'     'http://localhost:4000/model_group/info'     -H 'accept: application/json'     -H 'x-api-key: sk-1234'
 * ```
 *
 * Example Request (Specific Model Group):
 * ```shell
 * curl -X 'GET'     'http://localhost:4000/model_group/info?model_group=rerank-english-v3.0'     -H 'accept: application/json'     -H 'Authorization: Bearer sk-1234'
 * ```
 *
 * Example Request (Specific Wildcard Model Group): (e.g. `model_name: openai*` on config.yaml)
 * ```shell
 * curl -X 'GET'     'http://localhost:4000/model_group/info?model_group=openai/tts-1'
 * -H 'accept: application/json'     -H 'Authorization: Bearersk-1234'
 * ```
 *
 * Learn how to use and set wildcard models [here](https://docs.litellm.ai/docs/wildcard_routing)
 *
 * Example Response:
 * ```json
 * {
 * "data": [
 * {
 * "model_group": "rerank-english-v3.0",
 * "providers": [
 * "cohere"
 * ],
 * "max_input_tokens": null,
 * "max_output_tokens": null,
 * "input_cost_per_token": 0.0,
 * "output_cost_per_token": 0.0,
 * "mode": null,
 * "tpm": null,
 * "rpm": null,
 * "supports_parallel_function_calling": false,
 * "supports_vision": false,
 * "supports_function_calling": false,
 * "supported_openai_params": [
 * "stream",
 * "temperature",
 * "max_tokens",
 * "logit_bias",
 * "top_p",
 * "frequency_penalty",
 * "presence_penalty",
 * "stop",
 * "n",
 * "extra_headers"
 * ]
 * },
 * {
 * "model_group": "gpt-3.5-turbo",
 * "providers": [
 * "openai"
 * ],
 * "max_input_tokens": 16385.0,
 * "max_output_tokens": 4096.0,
 * "input_cost_per_token": 1.5e-06,
 * "output_cost_per_token": 2e-06,
 * "mode": "chat",
 * "tpm": null,
 * "rpm": null,
 * "supports_parallel_function_calling": false,
 * "supports_vision": false,
 * "supports_function_calling": true,
 * "supported_openai_params": [
 * "frequency_penalty",
 * "logit_bias",
 * "logprobs",
 * "top_logprobs",
 * "max_tokens",
 * "max_completion_tokens",
 * "n",
 * "presence_penalty",
 * "seed",
 * "stop",
 * "stream",
 * "stream_options",
 * "temperature",
 * "top_p",
 * "tools",
 * "tool_choice",
 * "function_call",
 * "functions",
 * "max_retries",
 * "extra_headers",
 * "parallel_tool_calls",
 * "response_format"
 * ]
 * },
 * {
 * "model_group": "llava-hf",
 * "providers": [
 * "openai"
 * ],
 * "max_input_tokens": null,
 * "max_output_tokens": null,
 * "input_cost_per_token": 0.0,
 * "output_cost_per_token": 0.0,
 * "mode": null,
 * "tpm": null,
 * "rpm": null,
 * "supports_parallel_function_calling": false,
 * "supports_vision": true,
 * "supports_function_calling": false,
 * "supported_openai_params": [
 * "frequency_penalty",
 * "logit_bias",
 * "logprobs",
 * "top_logprobs",
 * "max_tokens",
 * "max_completion_tokens",
 * "n",
 * "presence_penalty",
 * "seed",
 * "stop",
 * "stream",
 * "stream_options",
 * "temperature",
 * "top_p",
 * "tools",
 * "tool_choice",
 * "function_call",
 * "functions",
 * "max_retries",
 * "extra_headers",
 * "parallel_tool_calls",
 * "response_format"
 * ]
 * }
 * ]
 * }
 * ```
 */
export const modelGroupInfoModelGroupInfoGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ModelGroupInfoModelGroupInfoGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ModelGroupInfoModelGroupInfoGetResponses,
    ModelGroupInfoModelGroupInfoGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/model_group/info',
    ...options,
  });

/**
 * Home
 */
export const homeGet = <ThrowOnError extends boolean = false>(
  options?: Options<HomeGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<HomeGetResponses, unknown, ThrowOnError>({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/',
    ...options,
  });

/**
 * Get Routes
 *
 * Get a list of available routes in the FastAPI application.
 */
export const getRoutesRoutesGet = <ThrowOnError extends boolean = false>(
  options?: Options<GetRoutesRoutesGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetRoutesRoutesGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/routes',
    ...options,
  });

/**
 * Responses Api
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{
 * "model": "gpt-4o",
 * "input": "Tell me about AI"
 * }'
 * ```
 */
export const responsesApiOpenaiV1ResponsesPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ResponsesApiOpenaiV1ResponsesPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    ResponsesApiOpenaiV1ResponsesPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/v1/responses',
    ...options,
  });

/**
 * Responses Api
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{
 * "model": "gpt-4o",
 * "input": "Tell me about AI"
 * }'
 * ```
 */
export const responsesApiResponsesPost = <ThrowOnError extends boolean = false>(
  options?: Options<ResponsesApiResponsesPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    ResponsesApiResponsesPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/responses',
    ...options,
  });

/**
 * Responses Api
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"     -d '{
 * "model": "gpt-4o",
 * "input": "Tell me about AI"
 * }'
 * ```
 */
export const responsesApiV1ResponsesPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ResponsesApiV1ResponsesPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    ResponsesApiV1ResponsesPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/responses',
    ...options,
  });

/**
 * Delete Response
 *
 * Delete a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete
 *
 * ```bash
 * curl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const deleteResponseOpenaiV1ResponsesResponseIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DeleteResponseOpenaiV1ResponsesResponseIdDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    DeleteResponseOpenaiV1ResponsesResponseIdDeleteResponses,
    DeleteResponseOpenaiV1ResponsesResponseIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/v1/responses/{response_id}',
    ...options,
  });

/**
 * Get Response
 *
 * Get a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get
 *
 * ```bash
 * curl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const getResponseOpenaiV1ResponsesResponseIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetResponseOpenaiV1ResponsesResponseIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetResponseOpenaiV1ResponsesResponseIdGetResponses,
    GetResponseOpenaiV1ResponsesResponseIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/v1/responses/{response_id}',
    ...options,
  });

/**
 * Delete Response
 *
 * Delete a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete
 *
 * ```bash
 * curl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const deleteResponseResponsesResponseIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteResponseResponsesResponseIdDeleteData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    DeleteResponseResponsesResponseIdDeleteResponses,
    DeleteResponseResponsesResponseIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/responses/{response_id}',
    ...options,
  });

/**
 * Get Response
 *
 * Get a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get
 *
 * ```bash
 * curl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const getResponseResponsesResponseIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetResponseResponsesResponseIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetResponseResponsesResponseIdGetResponses,
    GetResponseResponsesResponseIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/responses/{response_id}',
    ...options,
  });

/**
 * Delete Response
 *
 * Delete a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/delete
 *
 * ```bash
 * curl -X DELETE http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const deleteResponseV1ResponsesResponseIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteResponseV1ResponsesResponseIdDeleteData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    DeleteResponseV1ResponsesResponseIdDeleteResponses,
    DeleteResponseV1ResponsesResponseIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/responses/{response_id}',
    ...options,
  });

/**
 * Get Response
 *
 * Get a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/get
 *
 * ```bash
 * curl -X GET http://localhost:4000/v1/responses/resp_abc123     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const getResponseV1ResponsesResponseIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetResponseV1ResponsesResponseIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetResponseV1ResponsesResponseIdGetResponses,
    GetResponseV1ResponsesResponseIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/responses/{response_id}',
    ...options,
  });

/**
 * Get Response Input Items
 *
 * List input items for a response.
 */
export const getResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetResponses,
    GetResponseInputItemsOpenaiV1ResponsesResponseIdInputItemsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/v1/responses/{response_id}/input_items',
    ...options,
  });

/**
 * Get Response Input Items
 *
 * List input items for a response.
 */
export const getResponseInputItemsResponsesResponseIdInputItemsGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GetResponseInputItemsResponsesResponseIdInputItemsGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    GetResponseInputItemsResponsesResponseIdInputItemsGetResponses,
    GetResponseInputItemsResponsesResponseIdInputItemsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/responses/{response_id}/input_items',
    ...options,
  });

/**
 * Get Response Input Items
 *
 * List input items for a response.
 */
export const getResponseInputItemsV1ResponsesResponseIdInputItemsGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GetResponseInputItemsV1ResponsesResponseIdInputItemsGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    GetResponseInputItemsV1ResponsesResponseIdInputItemsGetResponses,
    GetResponseInputItemsV1ResponsesResponseIdInputItemsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/responses/{response_id}/input_items',
    ...options,
  });

/**
 * Cancel Response
 *
 * Cancel a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const cancelResponseOpenaiV1ResponsesResponseIdCancelPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    CancelResponseOpenaiV1ResponsesResponseIdCancelPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    CancelResponseOpenaiV1ResponsesResponseIdCancelPostResponses,
    CancelResponseOpenaiV1ResponsesResponseIdCancelPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/v1/responses/{response_id}/cancel',
    ...options,
  });

/**
 * Cancel Response
 *
 * Cancel a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const cancelResponseResponsesResponseIdCancelPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    CancelResponseResponsesResponseIdCancelPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    CancelResponseResponsesResponseIdCancelPostResponses,
    CancelResponseResponsesResponseIdCancelPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/responses/{response_id}/cancel',
    ...options,
  });

/**
 * Cancel Response
 *
 * Cancel a response by ID.
 *
 * Follows the OpenAI Responses API spec: https://platform.openai.com/docs/api-reference/responses/cancel
 *
 * ```bash
 * curl -X POST http://localhost:4000/v1/responses/resp_abc123/cancel     -H "Authorization: Bearer sk-1234"
 * ```
 */
export const cancelResponseV1ResponsesResponseIdCancelPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    CancelResponseV1ResponsesResponseIdCancelPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    CancelResponseV1ResponsesResponseIdCancelPostResponses,
    CancelResponseV1ResponsesResponseIdCancelPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/responses/{response_id}/cancel',
    ...options,
  });

/**
 * List Batches
 *
 * Lists
 * This is the equivalent of GET https://api.openai.com/v1/batches/
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const listBatchesBatchesGet = <ThrowOnError extends boolean = false>(
  options?: Options<ListBatchesBatchesGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListBatchesBatchesGetResponses,
    ListBatchesBatchesGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/batches',
    ...options,
  });

/**
 * Create Batch
 *
 * Create large batches of API requests for asynchronous processing.
 * This is the equivalent of POST https://api.openai.com/v1/batch
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "input_file_id": "file-abc123",
 * "endpoint": "/v1/chat/completions",
 * "completion_window": "24h"
 * }'
 * ```
 */
export const createBatchBatchesPost = <ThrowOnError extends boolean = false>(
  options?: Options<CreateBatchBatchesPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CreateBatchBatchesPostResponses,
    CreateBatchBatchesPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/batches',
    ...options,
  });

/**
 * List Batches
 *
 * Lists
 * This is the equivalent of GET https://api.openai.com/v1/batches/
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const listBatchesV1BatchesGet = <ThrowOnError extends boolean = false>(
  options?: Options<ListBatchesV1BatchesGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListBatchesV1BatchesGetResponses,
    ListBatchesV1BatchesGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/batches',
    ...options,
  });

/**
 * Create Batch
 *
 * Create large batches of API requests for asynchronous processing.
 * This is the equivalent of POST https://api.openai.com/v1/batch
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "input_file_id": "file-abc123",
 * "endpoint": "/v1/chat/completions",
 * "completion_window": "24h"
 * }'
 * ```
 */
export const createBatchV1BatchesPost = <ThrowOnError extends boolean = false>(
  options?: Options<CreateBatchV1BatchesPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CreateBatchV1BatchesPostResponses,
    CreateBatchV1BatchesPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/batches',
    ...options,
  });

/**
 * List Batches
 *
 * Lists
 * This is the equivalent of GET https://api.openai.com/v1/batches/
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches?limit=2     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const listBatchesProviderV1BatchesGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<ListBatchesProviderV1BatchesGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    ListBatchesProviderV1BatchesGetResponses,
    ListBatchesProviderV1BatchesGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/{provider}/v1/batches',
    ...options,
  });

/**
 * Create Batch
 *
 * Create large batches of API requests for asynchronous processing.
 * This is the equivalent of POST https://api.openai.com/v1/batch
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "input_file_id": "file-abc123",
 * "endpoint": "/v1/chat/completions",
 * "completion_window": "24h"
 * }'
 * ```
 */
export const createBatchProviderV1BatchesPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CreateBatchProviderV1BatchesPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateBatchProviderV1BatchesPostResponses,
    CreateBatchProviderV1BatchesPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/{provider}/v1/batches',
    ...options,
  });

/**
 * Retrieve Batch
 *
 * Retrieves a batch.
 * This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const retrieveBatchBatchesBatchIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<RetrieveBatchBatchesBatchIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    RetrieveBatchBatchesBatchIdGetResponses,
    RetrieveBatchBatchesBatchIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/batches/{batch_id}',
    ...options,
  });

/**
 * Retrieve Batch
 *
 * Retrieves a batch.
 * This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const retrieveBatchV1BatchesBatchIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<RetrieveBatchV1BatchesBatchIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    RetrieveBatchV1BatchesBatchIdGetResponses,
    RetrieveBatchV1BatchesBatchIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/batches/{batch_id}',
    ...options,
  });

/**
 * Retrieve Batch
 *
 * Retrieves a batch.
 * This is the equivalent of GET https://api.openai.com/v1/batches/{batch_id}
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123     -H "Authorization: Bearer sk-1234"     -H "Content-Type: application/json"
 * ```
 */
export const retrieveBatchProviderV1BatchesBatchIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<RetrieveBatchProviderV1BatchesBatchIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    RetrieveBatchProviderV1BatchesBatchIdGetResponses,
    RetrieveBatchProviderV1BatchesBatchIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/{provider}/v1/batches/{batch_id}',
    ...options,
  });

/**
 * Cancel Batch
 *
 * Cancel a batch.
 * This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancel
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancel
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST
 *
 * ```
 */
export const cancelBatchBatchesBatchIdCancelPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CancelBatchBatchesBatchIdCancelPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CancelBatchBatchesBatchIdCancelPostResponses,
    CancelBatchBatchesBatchIdCancelPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/batches/{batch_id}/cancel',
    ...options,
  });

/**
 * Cancel Batch
 *
 * Cancel a batch.
 * This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancel
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancel
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST
 *
 * ```
 */
export const cancelBatchV1BatchesBatchIdCancelPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CancelBatchV1BatchesBatchIdCancelPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CancelBatchV1BatchesBatchIdCancelPostResponses,
    CancelBatchV1BatchesBatchIdCancelPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/batches/{batch_id}/cancel',
    ...options,
  });

/**
 * Cancel Batch
 *
 * Cancel a batch.
 * This is the equivalent of POST https://api.openai.com/v1/batches/{batch_id}/cancel
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/batch/cancel
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/batches/batch_abc123/cancel         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -X POST
 *
 * ```
 */
export const cancelBatchProviderV1BatchesBatchIdCancelPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    CancelBatchProviderV1BatchesBatchIdCancelPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    CancelBatchProviderV1BatchesBatchIdCancelPostResponses,
    CancelBatchProviderV1BatchesBatchIdCancelPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/{provider}/v1/batches/{batch_id}/cancel',
    ...options,
  });

/**
 * Public Model Hub
 */
export const publicModelHubPublicModelHubGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<PublicModelHubPublicModelHubGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    PublicModelHubPublicModelHubGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/public/model_hub',
    ...options,
  });

/**
 * Get Agents
 */
export const getAgentsPublicAgentHubGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetAgentsPublicAgentHubGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetAgentsPublicAgentHubGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/public/agent_hub',
    ...options,
  });

/**
 * Get Mcp Servers
 */
export const getMcpServersPublicMcpHubGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetMcpServersPublicMcpHubGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetMcpServersPublicMcpHubGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/public/mcp_hub',
    ...options,
  });

/**
 * Public Model Hub Info
 */
export const publicModelHubInfoPublicModelHubInfoGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<PublicModelHubInfoPublicModelHubInfoGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    PublicModelHubInfoPublicModelHubInfoGetResponses,
    unknown,
    ThrowOnError
  >({ url: '/public/model_hub/info', ...options });

/**
 * Get Supported Providers
 *
 * Return a sorted list of all providers supported by LiteLLM.
 */
export const getSupportedProvidersPublicProvidersGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetSupportedProvidersPublicProvidersGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetSupportedProvidersPublicProvidersGetResponses,
    unknown,
    ThrowOnError
  >({ url: '/public/providers', ...options });

/**
 * Get Provider Fields
 *
 * Return provider metadata required by the dashboard create-model flow.
 */
export const getProviderFieldsPublicProvidersFieldsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetProviderFieldsPublicProvidersFieldsGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetProviderFieldsPublicProvidersFieldsGetResponses,
    unknown,
    ThrowOnError
  >({ url: '/public/providers/fields', ...options });

/**
 * Rerank
 */
export const rerankRerankPost = <ThrowOnError extends boolean = false>(
  options?: Options<RerankRerankPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    RerankRerankPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/rerank',
    ...options,
  });

/**
 * Rerank
 */
export const rerankV1RerankPost = <ThrowOnError extends boolean = false>(
  options?: Options<RerankV1RerankPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    RerankV1RerankPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/rerank',
    ...options,
  });

/**
 * Rerank
 */
export const rerankV2RerankPost = <ThrowOnError extends boolean = false>(
  options?: Options<RerankV2RerankPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    RerankV2RerankPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v2/rerank',
    ...options,
  });

/**
 * Ocr
 *
 * OCR endpoint for extracting text from documents and images.
 *
 * Follows the Mistral OCR API spec:
 * https://docs.mistral.ai/capabilities/vision/#optical-character-recognition-ocr
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/ocr"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "model": "mistral/mistral-ocr-latest",
 * "document": {
 * "type": "document_url",
 * "document_url": "https://arxiv.org/pdf/2201.04234"
 * }
 * }'
 * ```
 */
export const ocrOcrPost = <ThrowOnError extends boolean = false>(
  options?: Options<OcrOcrPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<OcrOcrPostResponses, unknown, ThrowOnError>({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/ocr',
    ...options,
  });

/**
 * Ocr
 *
 * OCR endpoint for extracting text from documents and images.
 *
 * Follows the Mistral OCR API spec:
 * https://docs.mistral.ai/capabilities/vision/#optical-character-recognition-ocr
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/ocr"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "model": "mistral/mistral-ocr-latest",
 * "document": {
 * "type": "document_url",
 * "document_url": "https://arxiv.org/pdf/2201.04234"
 * }
 * }'
 * ```
 */
export const ocrV1OcrPost = <ThrowOnError extends boolean = false>(
  options?: Options<OcrV1OcrPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    OcrV1OcrPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/ocr',
    ...options,
  });

/**
 * Rag Ingest
 *
 * RAG Ingest endpoint - all-in-one document ingestion pipeline.
 *
 * Supports form upload (for files) or JSON body (for URLs).
 *
 * ## Form upload (for files):
 * ```bash
 * curl -X POST "http://localhost:4000/v1/rag/ingest" \
 * -H "Authorization: Bearer sk-1234" \
 * -F file="@document.pdf" \
 * -F 'ingest_options={"vector_store": {"custom_llm_provider": "openai"}}'
 * ```
 *
 * ## JSON body (for URLs):
 * ```bash
 * curl -X POST "http://localhost:4000/v1/rag/ingest" \
 * -H "Authorization: Bearer sk-1234" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "file_url": "https://example.com/document.pdf",
 * "ingest_options": {"vector_store": {"custom_llm_provider": "openai"}}
 * }'
 * ```
 *
 * ## Bedrock:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/rag/ingest" \
 * -H "Authorization: Bearer sk-1234" \
 * -F file="@document.pdf" \
 * -F 'ingest_options={"vector_store": {"custom_llm_provider": "bedrock"}}'
 * ```
 */
export const ragIngestRagIngestPost = <ThrowOnError extends boolean = false>(
  options?: Options<RagIngestRagIngestPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    RagIngestRagIngestPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/rag/ingest',
    ...options,
  });

/**
 * Rag Ingest
 *
 * RAG Ingest endpoint - all-in-one document ingestion pipeline.
 *
 * Supports form upload (for files) or JSON body (for URLs).
 *
 * ## Form upload (for files):
 * ```bash
 * curl -X POST "http://localhost:4000/v1/rag/ingest" \
 * -H "Authorization: Bearer sk-1234" \
 * -F file="@document.pdf" \
 * -F 'ingest_options={"vector_store": {"custom_llm_provider": "openai"}}'
 * ```
 *
 * ## JSON body (for URLs):
 * ```bash
 * curl -X POST "http://localhost:4000/v1/rag/ingest" \
 * -H "Authorization: Bearer sk-1234" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "file_url": "https://example.com/document.pdf",
 * "ingest_options": {"vector_store": {"custom_llm_provider": "openai"}}
 * }'
 * ```
 *
 * ## Bedrock:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/rag/ingest" \
 * -H "Authorization: Bearer sk-1234" \
 * -F file="@document.pdf" \
 * -F 'ingest_options={"vector_store": {"custom_llm_provider": "bedrock"}}'
 * ```
 */
export const ragIngestV1RagIngestPost = <ThrowOnError extends boolean = false>(
  options?: Options<RagIngestV1RagIngestPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    RagIngestV1RagIngestPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/rag/ingest',
    ...options,
  });

/**
 * Video List
 *
 * Video list endpoint for retrieving a list of videos.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"
 * ```
 */
export const videoListVideosGet = <ThrowOnError extends boolean = false>(
  options?: Options<VideoListVideosGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    VideoListVideosGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/videos',
    ...options,
  });

/**
 * Video Generation
 *
 * Video generation endpoint for creating videos from text prompts.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "model": "sora-2",
 * "prompt": "A beautiful sunset over the ocean"
 * }'
 * ```
 */
export const videoGenerationVideosPost = <ThrowOnError extends boolean = false>(
  options?: Options<VideoGenerationVideosPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    VideoGenerationVideosPostResponses,
    VideoGenerationVideosPostErrors,
    ThrowOnError
  >({
    ...formDataBodySerializer,
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/videos',
    ...options,
    headers: {
      'Content-Type': null,
      ...options?.headers,
    },
  });

/**
 * Video List
 *
 * Video list endpoint for retrieving a list of videos.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"
 * ```
 */
export const videoListV1VideosGet = <ThrowOnError extends boolean = false>(
  options?: Options<VideoListV1VideosGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    VideoListV1VideosGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/videos',
    ...options,
  });

/**
 * Video Generation
 *
 * Video generation endpoint for creating videos from text prompts.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/videos"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "model": "sora-2",
 * "prompt": "A beautiful sunset over the ocean"
 * }'
 * ```
 */
export const videoGenerationV1VideosPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<VideoGenerationV1VideosPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    VideoGenerationV1VideosPostResponses,
    VideoGenerationV1VideosPostErrors,
    ThrowOnError
  >({
    ...formDataBodySerializer,
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/videos',
    ...options,
    headers: {
      'Content-Type': null,
      ...options?.headers,
    },
  });

/**
 * Video Status
 *
 * Video status endpoint for retrieving video status and metadata.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/videos/video_123"         -H "Authorization: Bearer sk-1234"
 * ```
 */
export const videoStatusVideosVideoIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VideoStatusVideosVideoIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    VideoStatusVideosVideoIdGetResponses,
    VideoStatusVideosVideoIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/videos/{video_id}',
    ...options,
  });

/**
 * Video Status
 *
 * Video status endpoint for retrieving video status and metadata.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/videos/video_123"         -H "Authorization: Bearer sk-1234"
 * ```
 */
export const videoStatusV1VideosVideoIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VideoStatusV1VideosVideoIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    VideoStatusV1VideosVideoIdGetResponses,
    VideoStatusV1VideosVideoIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/videos/{video_id}',
    ...options,
  });

/**
 * Video Content
 *
 * Video content endpoint for downloading video content.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/videos/{video_id}/content"         -H "Authorization: Bearer sk-1234"         --output video.mp4
 * ```
 */
export const videoContentVideosVideoIdContentGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VideoContentVideosVideoIdContentGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    VideoContentVideosVideoIdContentGetResponses,
    VideoContentVideosVideoIdContentGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/videos/{video_id}/content',
    ...options,
  });

/**
 * Video Content
 *
 * Video content endpoint for downloading video content.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/videos/{video_id}/content"         -H "Authorization: Bearer sk-1234"         --output video.mp4
 * ```
 */
export const videoContentV1VideosVideoIdContentGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VideoContentV1VideosVideoIdContentGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    VideoContentV1VideosVideoIdContentGetResponses,
    VideoContentV1VideosVideoIdContentGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/videos/{video_id}/content',
    ...options,
  });

/**
 * Video Remix
 *
 * Video remix endpoint for remixing existing videos with new prompts.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/videos/video_123/remix"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "prompt": "A new version with different colors"
 * }'
 * ```
 */
export const videoRemixVideosVideoIdRemixPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VideoRemixVideosVideoIdRemixPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    VideoRemixVideosVideoIdRemixPostResponses,
    VideoRemixVideosVideoIdRemixPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/videos/{video_id}/remix',
    ...options,
  });

/**
 * Video Remix
 *
 * Video remix endpoint for remixing existing videos with new prompts.
 *
 * Follows the OpenAI Videos API spec:
 * https://platform.openai.com/docs/api-reference/videos
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/videos/video_123/remix"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "prompt": "A new version with different colors"
 * }'
 * ```
 */
export const videoRemixV1VideosVideoIdRemixPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VideoRemixV1VideosVideoIdRemixPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    VideoRemixV1VideosVideoIdRemixPostResponses,
    VideoRemixV1VideosVideoIdRemixPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/videos/{video_id}/remix',
    ...options,
  });

/**
 * List Containers
 *
 * Container list endpoint for retrieving a list of containers.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers?limit=20&order=desc"         -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Or specify provider via header or query param:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers?custom_llm_provider=azure"         -H "Authorization: Bearer sk-1234"
 * ```
 */
export const listContainersContainersGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListContainersContainersGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListContainersContainersGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/containers',
    ...options,
  });

/**
 * Create Container
 *
 * Container creation endpoint for creating new containers.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "name": "My Container",
 * "expires_after": {
 * "anchor": "last_active_at",
 * "minutes": 20
 * }
 * }'
 * ```
 *
 * Or specify provider via header:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"         -H "Content-Type: application/json"         -d '{
 * "name": "My Container"
 * }'
 * ```
 */
export const createContainerContainersPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<CreateContainerContainersPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CreateContainerContainersPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/containers',
    ...options,
  });

/**
 * List Containers
 *
 * Container list endpoint for retrieving a list of containers.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers?limit=20&order=desc"         -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Or specify provider via header or query param:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers?custom_llm_provider=azure"         -H "Authorization: Bearer sk-1234"
 * ```
 */
export const listContainersV1ContainersGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListContainersV1ContainersGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListContainersV1ContainersGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/containers',
    ...options,
  });

/**
 * Create Container
 *
 * Container creation endpoint for creating new containers.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "name": "My Container",
 * "expires_after": {
 * "anchor": "last_active_at",
 * "minutes": 20
 * }
 * }'
 * ```
 *
 * Or specify provider via header:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/containers"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"         -H "Content-Type: application/json"         -d '{
 * "name": "My Container"
 * }'
 * ```
 */
export const createContainerV1ContainersPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<CreateContainerV1ContainersPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CreateContainerV1ContainersPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/containers',
    ...options,
  });

/**
 * Delete Container
 *
 * Container delete endpoint for deleting a specific container.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Or specify provider via header:
 * ```bash
 * curl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"
 * ```
 */
export const deleteContainerContainersContainerIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DeleteContainerContainersContainerIdDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    DeleteContainerContainersContainerIdDeleteResponses,
    DeleteContainerContainersContainerIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/containers/{container_id}',
    ...options,
  });

/**
 * Retrieve Container
 *
 * Container retrieve endpoint for getting details of a specific container.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Or specify provider via header:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"
 * ```
 */
export const retrieveContainerContainersContainerIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<RetrieveContainerContainersContainerIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    RetrieveContainerContainersContainerIdGetResponses,
    RetrieveContainerContainersContainerIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/containers/{container_id}',
    ...options,
  });

/**
 * Delete Container
 *
 * Container delete endpoint for deleting a specific container.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Or specify provider via header:
 * ```bash
 * curl -X DELETE "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"
 * ```
 */
export const deleteContainerV1ContainersContainerIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DeleteContainerV1ContainersContainerIdDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    DeleteContainerV1ContainersContainerIdDeleteResponses,
    DeleteContainerV1ContainersContainerIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/containers/{container_id}',
    ...options,
  });

/**
 * Retrieve Container
 *
 * Container retrieve endpoint for getting details of a specific container.
 *
 * Follows the OpenAI Containers API spec:
 * https://platform.openai.com/docs/api-reference/containers
 *
 * Example:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Or specify provider via header:
 * ```bash
 * curl -X GET "http://localhost:4000/v1/containers/cntr_123"         -H "Authorization: Bearer sk-1234"         -H "custom-llm-provider: azure"
 * ```
 */
export const retrieveContainerV1ContainersContainerIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    RetrieveContainerV1ContainersContainerIdGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    RetrieveContainerV1ContainersContainerIdGetResponses,
    RetrieveContainerV1ContainersContainerIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/containers/{container_id}',
    ...options,
  });

/**
 * Search
 *
 * Search endpoint for performing web searches.
 *
 * Follows the Perplexity Search API spec:
 * https://docs.perplexity.ai/api-reference/search-post
 *
 * The search_tool_name can be passed either:
 * 1. In the URL path: /v1/search/{search_tool_name}
 * 2. In the request body: {"search_tool_name": "..."}
 *
 * Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "query": "latest AI developments 2024",
 * "max_results": 5,
 * "search_domain_filter": ["arxiv.org", "nature.com"],
 * "country": "US"
 * }'
 * ```
 *
 * Example with search_tool_name in body:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "search_tool_name": "litellm-search",
 * "query": "latest AI developments 2024",
 * "max_results": 5,
 * "search_domain_filter": ["arxiv.org", "nature.com"],
 * "country": "US"
 * }'
 * ```
 *
 * Request Body Parameters (when search_tool_name not in URL):
 * - search_tool_name (str, required if not in URL): Name of the search tool configured in router
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * When using URL path parameter, only Perplexity-compatible parameters are needed in body:
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * Response follows Perplexity Search API format:
 * ```json
 * {
 * "object": "search",
 * "results": [
 * {
 * "title": "Result title",
 * "url": "https://example.com",
 * "snippet": "Result snippet...",
 * "date": "2024-01-01",
 * "last_updated": "2024-01-01"
 * }
 * ]
 * }
 * ```
 */
export const searchSearchPost = <ThrowOnError extends boolean = false>(
  options?: Options<SearchSearchPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    SearchSearchPostResponses,
    SearchSearchPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/search',
    ...options,
  });

/**
 * Search
 *
 * Search endpoint for performing web searches.
 *
 * Follows the Perplexity Search API spec:
 * https://docs.perplexity.ai/api-reference/search-post
 *
 * The search_tool_name can be passed either:
 * 1. In the URL path: /v1/search/{search_tool_name}
 * 2. In the request body: {"search_tool_name": "..."}
 *
 * Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "query": "latest AI developments 2024",
 * "max_results": 5,
 * "search_domain_filter": ["arxiv.org", "nature.com"],
 * "country": "US"
 * }'
 * ```
 *
 * Example with search_tool_name in body:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "search_tool_name": "litellm-search",
 * "query": "latest AI developments 2024",
 * "max_results": 5,
 * "search_domain_filter": ["arxiv.org", "nature.com"],
 * "country": "US"
 * }'
 * ```
 *
 * Request Body Parameters (when search_tool_name not in URL):
 * - search_tool_name (str, required if not in URL): Name of the search tool configured in router
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * When using URL path parameter, only Perplexity-compatible parameters are needed in body:
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * Response follows Perplexity Search API format:
 * ```json
 * {
 * "object": "search",
 * "results": [
 * {
 * "title": "Result title",
 * "url": "https://example.com",
 * "snippet": "Result snippet...",
 * "date": "2024-01-01",
 * "last_updated": "2024-01-01"
 * }
 * ]
 * }
 * ```
 */
export const searchV1SearchPost = <ThrowOnError extends boolean = false>(
  options?: Options<SearchV1SearchPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    SearchV1SearchPostResponses,
    SearchV1SearchPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/search',
    ...options,
  });

/**
 * Search
 *
 * Search endpoint for performing web searches.
 *
 * Follows the Perplexity Search API spec:
 * https://docs.perplexity.ai/api-reference/search-post
 *
 * The search_tool_name can be passed either:
 * 1. In the URL path: /v1/search/{search_tool_name}
 * 2. In the request body: {"search_tool_name": "..."}
 *
 * Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "query": "latest AI developments 2024",
 * "max_results": 5,
 * "search_domain_filter": ["arxiv.org", "nature.com"],
 * "country": "US"
 * }'
 * ```
 *
 * Example with search_tool_name in body:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "search_tool_name": "litellm-search",
 * "query": "latest AI developments 2024",
 * "max_results": 5,
 * "search_domain_filter": ["arxiv.org", "nature.com"],
 * "country": "US"
 * }'
 * ```
 *
 * Request Body Parameters (when search_tool_name not in URL):
 * - search_tool_name (str, required if not in URL): Name of the search tool configured in router
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * When using URL path parameter, only Perplexity-compatible parameters are needed in body:
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * Response follows Perplexity Search API format:
 * ```json
 * {
 * "object": "search",
 * "results": [
 * {
 * "title": "Result title",
 * "url": "https://example.com",
 * "snippet": "Result snippet...",
 * "date": "2024-01-01",
 * "last_updated": "2024-01-01"
 * }
 * ]
 * }
 * ```
 */
export const searchSearchSearchToolNamePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<SearchSearchSearchToolNamePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    SearchSearchSearchToolNamePostResponses,
    SearchSearchSearchToolNamePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/search/{search_tool_name}',
    ...options,
  });

/**
 * Search
 *
 * Search endpoint for performing web searches.
 *
 * Follows the Perplexity Search API spec:
 * https://docs.perplexity.ai/api-reference/search-post
 *
 * The search_tool_name can be passed either:
 * 1. In the URL path: /v1/search/{search_tool_name}
 * 2. In the request body: {"search_tool_name": "..."}
 *
 * Example with search_tool_name in URL (recommended - keeps body Perplexity-compatible):
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search/litellm-search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "query": "latest AI developments 2024",
 * "max_results": 5,
 * "search_domain_filter": ["arxiv.org", "nature.com"],
 * "country": "US"
 * }'
 * ```
 *
 * Example with search_tool_name in body:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/search"         -H "Authorization: Bearer sk-1234"         -H "Content-Type: application/json"         -d '{
 * "search_tool_name": "litellm-search",
 * "query": "latest AI developments 2024",
 * "max_results": 5,
 * "search_domain_filter": ["arxiv.org", "nature.com"],
 * "country": "US"
 * }'
 * ```
 *
 * Request Body Parameters (when search_tool_name not in URL):
 * - search_tool_name (str, required if not in URL): Name of the search tool configured in router
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * When using URL path parameter, only Perplexity-compatible parameters are needed in body:
 * - query (str or list[str], required): Search query
 * - max_results (int, optional): Maximum number of results (1-20), default 10
 * - search_domain_filter (list[str], optional): List of domains to filter (max 20)
 * - max_tokens_per_page (int, optional): Max tokens per page, default 1024
 * - country (str, optional): Country code filter (e.g., 'US', 'GB', 'DE')
 *
 * Response follows Perplexity Search API format:
 * ```json
 * {
 * "object": "search",
 * "results": [
 * {
 * "title": "Result title",
 * "url": "https://example.com",
 * "snippet": "Result snippet...",
 * "date": "2024-01-01",
 * "last_updated": "2024-01-01"
 * }
 * ]
 * }
 * ```
 */
export const searchV1SearchSearchToolNamePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<SearchV1SearchSearchToolNamePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    SearchV1SearchSearchToolNamePostResponses,
    SearchV1SearchSearchToolNamePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/search/{search_tool_name}',
    ...options,
  });

/**
 * Image Generation
 */
export const imageGenerationOpenaiDeploymentsModelImagesGenerationsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostResponses,
    ImageGenerationOpenaiDeploymentsModelImagesGenerationsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/deployments/{model}/images/generations',
    ...options,
  });

/**
 * Image Generation
 */
export const imageGenerationImagesGenerationsPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ImageGenerationImagesGenerationsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    ImageGenerationImagesGenerationsPostResponses,
    ImageGenerationImagesGenerationsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/images/generations',
    ...options,
  });

/**
 * Image Generation
 */
export const imageGenerationV1ImagesGenerationsPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ImageGenerationV1ImagesGenerationsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    ImageGenerationV1ImagesGenerationsPostResponses,
    ImageGenerationV1ImagesGenerationsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/images/generations',
    ...options,
  });

/**
 * Image Edit Api
 *
 * Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create
 *
 * ```bash
 * curl -s -D >(grep -i x-request-id >&2)     -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F 'prompt=Create a studio ghibli image of this'
 * ```
 */
export const imageEditApiOpenaiDeploymentsModelImagesEditsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    ImageEditApiOpenaiDeploymentsModelImagesEditsPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    ImageEditApiOpenaiDeploymentsModelImagesEditsPostResponses,
    ImageEditApiOpenaiDeploymentsModelImagesEditsPostErrors,
    ThrowOnError
  >({
    ...formDataBodySerializer,
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/deployments/{model}/images/edits',
    ...options,
    headers: {
      'Content-Type': null,
      ...options.headers,
    },
  });

/**
 * Image Edit Api
 *
 * Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create
 *
 * ```bash
 * curl -s -D >(grep -i x-request-id >&2)     -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F 'prompt=Create a studio ghibli image of this'
 * ```
 */
export const imageEditApiImagesEditsPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ImageEditApiImagesEditsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    ImageEditApiImagesEditsPostResponses,
    ImageEditApiImagesEditsPostErrors,
    ThrowOnError
  >({
    ...formDataBodySerializer,
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/images/edits',
    ...options,
    headers: {
      'Content-Type': null,
      ...options?.headers,
    },
  });

/**
 * Image Edit Api
 *
 * Follows the OpenAI Images API spec: https://platform.openai.com/docs/api-reference/images/create
 *
 * ```bash
 * curl -s -D >(grep -i x-request-id >&2)     -o >(jq -r '.data[0].b64_json' | base64 --decode > gift-basket.png)     -X POST "http://localhost:4000/v1/images/edits"     -H "Authorization: Bearer sk-1234"         -F "model=gpt-image-1"         -F "image[]=@soap.png"         -F 'prompt=Create a studio ghibli image of this'
 * ```
 */
export const imageEditApiV1ImagesEditsPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ImageEditApiV1ImagesEditsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    ImageEditApiV1ImagesEditsPostResponses,
    ImageEditApiV1ImagesEditsPostErrors,
    ThrowOnError
  >({
    ...formDataBodySerializer,
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/images/edits',
    ...options,
    headers: {
      'Content-Type': null,
      ...options?.headers,
    },
  });

/**
 *  (Enterprise) List Fine-Tuning Jobs
 *
 * Lists fine-tuning jobs for the organization.
 * This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `after`: Identifier for the last job from the previous pagination request.
 * - `limit`: Number of fine-tuning jobs to retrieve (default is 20).
 */
export const listFineTuningJobsFineTuningJobsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListFineTuningJobsFineTuningJobsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListFineTuningJobsFineTuningJobsGetResponses,
    ListFineTuningJobsFineTuningJobsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/fine_tuning/jobs',
    ...options,
  });

/**
 *  (Enterprise) Create Fine-Tuning Job
 *
 * Creates a fine-tuning job which begins the process of creating a new model from a given dataset.
 * This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/fine-tuning/create
 *
 * Example Curl:
 * ```
 * curl http://localhost:4000/v1/fine_tuning/jobs       -H "Content-Type: application/json"       -H "Authorization: Bearer sk-1234"       -d '{
 * "model": "gpt-3.5-turbo",
 * "training_file": "file-abc123",
 * "hyperparameters": {
 * "n_epochs": 4
 * }
 * }'
 * ```
 */
export const createFineTuningJobFineTuningJobsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CreateFineTuningJobFineTuningJobsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateFineTuningJobFineTuningJobsPostResponses,
    CreateFineTuningJobFineTuningJobsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/fine_tuning/jobs',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 *  (Enterprise) List Fine-Tuning Jobs
 *
 * Lists fine-tuning jobs for the organization.
 * This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `after`: Identifier for the last job from the previous pagination request.
 * - `limit`: Number of fine-tuning jobs to retrieve (default is 20).
 */
export const listFineTuningJobsV1FineTuningJobsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListFineTuningJobsV1FineTuningJobsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListFineTuningJobsV1FineTuningJobsGetResponses,
    ListFineTuningJobsV1FineTuningJobsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/fine_tuning/jobs',
    ...options,
  });

/**
 *  (Enterprise) Create Fine-Tuning Job
 *
 * Creates a fine-tuning job which begins the process of creating a new model from a given dataset.
 * This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/fine-tuning/create
 *
 * Example Curl:
 * ```
 * curl http://localhost:4000/v1/fine_tuning/jobs       -H "Content-Type: application/json"       -H "Authorization: Bearer sk-1234"       -d '{
 * "model": "gpt-3.5-turbo",
 * "training_file": "file-abc123",
 * "hyperparameters": {
 * "n_epochs": 4
 * }
 * }'
 * ```
 */
export const createFineTuningJobV1FineTuningJobsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CreateFineTuningJobV1FineTuningJobsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateFineTuningJobV1FineTuningJobsPostResponses,
    CreateFineTuningJobV1FineTuningJobsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/fine_tuning/jobs',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 *  (Enterprise) Retrieve Fine-Tuning Job
 *
 * Retrieves a fine-tuning job.
 * This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `fine_tuning_job_id`: The ID of the fine-tuning job to retrieve.
 */
export const retrieveFineTuningJobFineTuningJobsFineTuningJobIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetResponses,
    RetrieveFineTuningJobFineTuningJobsFineTuningJobIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/fine_tuning/jobs/{fine_tuning_job_id}',
    ...options,
  });

/**
 *  (Enterprise) Retrieve Fine-Tuning Job
 *
 * Retrieves a fine-tuning job.
 * This is the equivalent of GET https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `fine_tuning_job_id`: The ID of the fine-tuning job to retrieve.
 */
export const retrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetResponses,
    RetrieveFineTuningJobV1FineTuningJobsFineTuningJobIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/fine_tuning/jobs/{fine_tuning_job_id}',
    ...options,
  });

/**
 *  (Enterprise) Cancel Fine-Tuning Jobs
 *
 * Cancel a fine-tuning job.
 *
 * This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `fine_tuning_job_id`: The ID of the fine-tuning job to cancel.
 */
export const cancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostResponses,
    CancelFineTuningJobFineTuningJobsFineTuningJobIdCancelPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/fine_tuning/jobs/{fine_tuning_job_id}/cancel',
    ...options,
  });

/**
 *  (Enterprise) Cancel Fine-Tuning Jobs
 *
 * Cancel a fine-tuning job.
 *
 * This is the equivalent of POST https://api.openai.com/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel
 *
 * Supported Query Params:
 * - `custom_llm_provider`: Name of the LiteLLM provider
 * - `fine_tuning_job_id`: The ID of the fine-tuning job to cancel.
 */
export const cancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostResponses,
    CancelFineTuningJobV1FineTuningJobsFineTuningJobIdCancelPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/fine_tuning/jobs/{fine_tuning_job_id}/cancel',
    ...options,
  });

/**
 * Vector Store Search
 *
 * Search a vector store.
 *
 * API Reference:
 * https://platform.openai.com/docs/api-reference/vector-stores/search
 */
export const vectorStoreSearchVectorStoresVectorStoreIdSearchPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VectorStoreSearchVectorStoresVectorStoreIdSearchPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    VectorStoreSearchVectorStoresVectorStoreIdSearchPostResponses,
    VectorStoreSearchVectorStoresVectorStoreIdSearchPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vector_stores/{vector_store_id}/search',
    ...options,
  });

/**
 * Vector Store Search
 *
 * Search a vector store.
 *
 * API Reference:
 * https://platform.openai.com/docs/api-reference/vector-stores/search
 */
export const vectorStoreSearchV1VectorStoresVectorStoreIdSearchPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostResponses,
    VectorStoreSearchV1VectorStoresVectorStoreIdSearchPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/vector_stores/{vector_store_id}/search',
    ...options,
  });

/**
 * Vector Store Create
 *
 * Create a vector store.
 *
 * API Reference:
 * https://platform.openai.com/docs/api-reference/vector-stores/create
 */
export const vectorStoreCreateVectorStoresPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<VectorStoreCreateVectorStoresPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    VectorStoreCreateVectorStoresPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vector_stores',
    ...options,
  });

/**
 * Vector Store Create
 *
 * Create a vector store.
 *
 * API Reference:
 * https://platform.openai.com/docs/api-reference/vector-stores/create
 */
export const vectorStoreCreateV1VectorStoresPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<VectorStoreCreateV1VectorStoresPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    VectorStoreCreateV1VectorStoresPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/vector_stores',
    ...options,
  });

/**
 * Index Create
 *
 * Create an index. Just writes the index to the database.
 *
 * ```bash
 * curl -L -X POST 'http://0.0.0.0:4000/indexes/create'         -H 'Content-Type: application/json'         -H 'Authorization: Bearer sk-1234'         -H 'LiteLLM-Beta: indexes_beta=v1'         -d '{
 * "index_name": "dall-e-3",
 * "vector_store_index": "real-index-name",
 * "vector_store_name": "azure-ai-search"
 * }'
 * ```
 */
export const indexCreateV1IndexesPost = <ThrowOnError extends boolean = false>(
  options: Options<IndexCreateV1IndexesPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    IndexCreateV1IndexesPostResponses,
    IndexCreateV1IndexesPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/indexes',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * New Vector Store
 *
 * Create a new vector store.
 *
 * Parameters:
 * - vector_store_id: str - Unique identifier for the vector store
 * - custom_llm_provider: str - Provider of the vector store
 * - vector_store_name: Optional[str] - Name of the vector store
 * - vector_store_description: Optional[str] - Description of the vector store
 * - vector_store_metadata: Optional[Dict] - Additional metadata for the vector store
 */
export const newVectorStoreVectorStoreNewPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<NewVectorStoreVectorStoreNewPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    NewVectorStoreVectorStoreNewPostResponses,
    NewVectorStoreVectorStoreNewPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vector_store/new',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * List Vector Stores
 *
 * List all available vector stores with optional filtering and pagination.
 * Combines both in-memory vector stores and those stored in the database.
 *
 * Parameters:
 * - page: int - Page number for pagination (default: 1)
 * - page_size: int - Number of items per page (default: 100)
 */
export const listVectorStoresVectorStoreListGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListVectorStoresVectorStoreListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListVectorStoresVectorStoreListGetResponses,
    ListVectorStoresVectorStoreListGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vector_store/list',
    ...options,
  });

/**
 * Delete Vector Store
 *
 * Delete a vector store.
 *
 * Parameters:
 * - vector_store_id: str - ID of the vector store to delete
 */
export const deleteVectorStoreVectorStoreDeletePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteVectorStoreVectorStoreDeletePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    DeleteVectorStoreVectorStoreDeletePostResponses,
    DeleteVectorStoreVectorStoreDeletePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vector_store/delete',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Vector Store Info
 *
 * Return a single vector store's details
 */
export const getVectorStoreInfoVectorStoreInfoPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetVectorStoreInfoVectorStoreInfoPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    GetVectorStoreInfoVectorStoreInfoPostResponses,
    GetVectorStoreInfoVectorStoreInfoPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vector_store/info',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Vector Store
 *
 * Update vector store details
 */
export const updateVectorStoreVectorStoreUpdatePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UpdateVectorStoreVectorStoreUpdatePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UpdateVectorStoreVectorStoreUpdatePostResponses,
    UpdateVectorStoreVectorStoreUpdatePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vector_store/update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Vector Store File List
 */
export const vectorStoreFileListVectorStoresVectorStoreIdFilesGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VectorStoreFileListVectorStoresVectorStoreIdFilesGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    VectorStoreFileListVectorStoresVectorStoreIdFilesGetResponses,
    VectorStoreFileListVectorStoresVectorStoreIdFilesGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vector_stores/{vector_store_id}/files',
    ...options,
  });

/**
 * Vector Store File Create
 */
export const vectorStoreFileCreateVectorStoresVectorStoreIdFilesPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VectorStoreFileCreateVectorStoresVectorStoreIdFilesPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    VectorStoreFileCreateVectorStoresVectorStoreIdFilesPostResponses,
    VectorStoreFileCreateVectorStoresVectorStoreIdFilesPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vector_stores/{vector_store_id}/files',
    ...options,
  });

/**
 * Vector Store File List
 */
export const vectorStoreFileListV1VectorStoresVectorStoreIdFilesGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VectorStoreFileListV1VectorStoresVectorStoreIdFilesGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    VectorStoreFileListV1VectorStoresVectorStoreIdFilesGetResponses,
    VectorStoreFileListV1VectorStoresVectorStoreIdFilesGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/vector_stores/{vector_store_id}/files',
    ...options,
  });

/**
 * Vector Store File Create
 */
export const vectorStoreFileCreateV1VectorStoresVectorStoreIdFilesPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VectorStoreFileCreateV1VectorStoresVectorStoreIdFilesPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    VectorStoreFileCreateV1VectorStoresVectorStoreIdFilesPostResponses,
    VectorStoreFileCreateV1VectorStoresVectorStoreIdFilesPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/vector_stores/{vector_store_id}/files',
    ...options,
  });

/**
 * Vector Store File Delete
 */
export const vectorStoreFileDeleteVectorStoresVectorStoreIdFilesFileIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VectorStoreFileDeleteVectorStoresVectorStoreIdFilesFileIdDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    VectorStoreFileDeleteVectorStoresVectorStoreIdFilesFileIdDeleteResponses,
    VectorStoreFileDeleteVectorStoresVectorStoreIdFilesFileIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vector_stores/{vector_store_id}/files/{file_id}',
    ...options,
  });

/**
 * Vector Store File Retrieve
 */
export const vectorStoreFileRetrieveVectorStoresVectorStoreIdFilesFileIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VectorStoreFileRetrieveVectorStoresVectorStoreIdFilesFileIdGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    VectorStoreFileRetrieveVectorStoresVectorStoreIdFilesFileIdGetResponses,
    VectorStoreFileRetrieveVectorStoresVectorStoreIdFilesFileIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vector_stores/{vector_store_id}/files/{file_id}',
    ...options,
  });

/**
 * Vector Store File Update
 */
export const vectorStoreFileUpdateVectorStoresVectorStoreIdFilesFileIdPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VectorStoreFileUpdateVectorStoresVectorStoreIdFilesFileIdPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    VectorStoreFileUpdateVectorStoresVectorStoreIdFilesFileIdPostResponses,
    VectorStoreFileUpdateVectorStoresVectorStoreIdFilesFileIdPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vector_stores/{vector_store_id}/files/{file_id}',
    ...options,
  });

/**
 * Vector Store File Delete
 */
export const vectorStoreFileDeleteV1VectorStoresVectorStoreIdFilesFileIdDelete =
  <ThrowOnError extends boolean = false>(
    options: Options<
      VectorStoreFileDeleteV1VectorStoresVectorStoreIdFilesFileIdDeleteData,
      ThrowOnError
    >,
  ) =>
    (options.client ?? client).delete<
      VectorStoreFileDeleteV1VectorStoresVectorStoreIdFilesFileIdDeleteResponses,
      VectorStoreFileDeleteV1VectorStoresVectorStoreIdFilesFileIdDeleteErrors,
      ThrowOnError
    >({
      security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
      url: '/v1/vector_stores/{vector_store_id}/files/{file_id}',
      ...options,
    });

/**
 * Vector Store File Retrieve
 */
export const vectorStoreFileRetrieveV1VectorStoresVectorStoreIdFilesFileIdGet =
  <ThrowOnError extends boolean = false>(
    options: Options<
      VectorStoreFileRetrieveV1VectorStoresVectorStoreIdFilesFileIdGetData,
      ThrowOnError
    >,
  ) =>
    (options.client ?? client).get<
      VectorStoreFileRetrieveV1VectorStoresVectorStoreIdFilesFileIdGetResponses,
      VectorStoreFileRetrieveV1VectorStoresVectorStoreIdFilesFileIdGetErrors,
      ThrowOnError
    >({
      security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
      url: '/v1/vector_stores/{vector_store_id}/files/{file_id}',
      ...options,
    });

/**
 * Vector Store File Update
 */
export const vectorStoreFileUpdateV1VectorStoresVectorStoreIdFilesFileIdPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VectorStoreFileUpdateV1VectorStoresVectorStoreIdFilesFileIdPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    VectorStoreFileUpdateV1VectorStoresVectorStoreIdFilesFileIdPostResponses,
    VectorStoreFileUpdateV1VectorStoresVectorStoreIdFilesFileIdPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/vector_stores/{vector_store_id}/files/{file_id}',
    ...options,
  });

/**
 * Vector Store File Content
 */
export const vectorStoreFileContentVectorStoresVectorStoreIdFilesFileIdContentGet =
  <ThrowOnError extends boolean = false>(
    options: Options<
      VectorStoreFileContentVectorStoresVectorStoreIdFilesFileIdContentGetData,
      ThrowOnError
    >,
  ) =>
    (options.client ?? client).get<
      VectorStoreFileContentVectorStoresVectorStoreIdFilesFileIdContentGetResponses,
      VectorStoreFileContentVectorStoresVectorStoreIdFilesFileIdContentGetErrors,
      ThrowOnError
    >({
      security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
      url: '/vector_stores/{vector_store_id}/files/{file_id}/content',
      ...options,
    });

/**
 * Vector Store File Content
 */
export const vectorStoreFileContentV1VectorStoresVectorStoreIdFilesFileIdContentGet =
  <ThrowOnError extends boolean = false>(
    options: Options<
      VectorStoreFileContentV1VectorStoresVectorStoreIdFilesFileIdContentGetData,
      ThrowOnError
    >,
  ) =>
    (options.client ?? client).get<
      VectorStoreFileContentV1VectorStoresVectorStoreIdFilesFileIdContentGetResponses,
      VectorStoreFileContentV1VectorStoresVectorStoreIdFilesFileIdContentGetErrors,
      ThrowOnError
    >({
      security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
      url: '/v1/vector_stores/{vector_store_id}/files/{file_id}/content',
      ...options,
    });

/**
 * Get Credentials
 *
 * [BETA] endpoint. This might change unexpectedly.
 */
export const getCredentialsCredentialsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetCredentialsCredentialsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetCredentialsCredentialsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/credentials',
    ...options,
  });

/**
 * Create Credential
 *
 * [BETA] endpoint. This might change unexpectedly.
 * Stores credential in DB.
 * Reloads credentials in memory.
 */
export const createCredentialCredentialsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CreateCredentialCredentialsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateCredentialCredentialsPostResponses,
    CreateCredentialCredentialsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/credentials',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Credential
 *
 * [BETA] endpoint. This might change unexpectedly.
 */
export const getCredentialCredentialsByModelModelIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetCredentialCredentialsByModelModelIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetCredentialCredentialsByModelModelIdGetResponses,
    GetCredentialCredentialsByModelModelIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/credentials/by_model/{model_id}',
    ...options,
  });

/**
 * Get Credential
 *
 * [BETA] endpoint. This might change unexpectedly.
 */
export const getCredentialCredentialsByNameCredentialNameGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GetCredentialCredentialsByNameCredentialNameGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    GetCredentialCredentialsByNameCredentialNameGetResponses,
    GetCredentialCredentialsByNameCredentialNameGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/credentials/by_name/{credential_name}',
    ...options,
  });

/**
 * Delete Credential
 *
 * [BETA] endpoint. This might change unexpectedly.
 */
export const deleteCredentialCredentialsCredentialNameDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DeleteCredentialCredentialsCredentialNameDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    DeleteCredentialCredentialsCredentialNameDeleteResponses,
    DeleteCredentialCredentialsCredentialNameDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/credentials/{credential_name}',
    ...options,
  });

/**
 * Update Credential
 *
 * [BETA] endpoint. This might change unexpectedly.
 */
export const updateCredentialCredentialsCredentialNamePatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    UpdateCredentialCredentialsCredentialNamePatchData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).patch<
    UpdateCredentialCredentialsCredentialNamePatchResponses,
    UpdateCredentialCredentialsCredentialNamePatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/credentials/{credential_name}',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Gemini Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/google_ai_studio)
 */
export const geminiProxyRouteGeminiEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GeminiProxyRouteGeminiEndpointPostData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    GeminiProxyRouteGeminiEndpointPostResponses,
    GeminiProxyRouteGeminiEndpointPostErrors,
    ThrowOnError
  >({ url: '/gemini/{endpoint}', ...options });

/**
 * Gemini Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/google_ai_studio)
 */
export const geminiProxyRouteGeminiEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GeminiProxyRouteGeminiEndpointPost2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GeminiProxyRouteGeminiEndpointPost2Responses,
    GeminiProxyRouteGeminiEndpointPost2Errors,
    ThrowOnError
  >({ url: '/gemini/{endpoint}', ...options });

/**
 * Gemini Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/google_ai_studio)
 */
export const geminiProxyRouteGeminiEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GeminiProxyRouteGeminiEndpointPost3Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    GeminiProxyRouteGeminiEndpointPost3Responses,
    GeminiProxyRouteGeminiEndpointPost3Errors,
    ThrowOnError
  >({ url: '/gemini/{endpoint}', ...options });

/**
 * Gemini Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/google_ai_studio)
 */
export const geminiProxyRouteGeminiEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GeminiProxyRouteGeminiEndpointPost4Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    GeminiProxyRouteGeminiEndpointPost4Responses,
    GeminiProxyRouteGeminiEndpointPost4Errors,
    ThrowOnError
  >({ url: '/gemini/{endpoint}', ...options });

/**
 * Gemini Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/google_ai_studio)
 */
export const geminiProxyRouteGeminiEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GeminiProxyRouteGeminiEndpointPost5Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    GeminiProxyRouteGeminiEndpointPost5Responses,
    GeminiProxyRouteGeminiEndpointPost5Errors,
    ThrowOnError
  >({ url: '/gemini/{endpoint}', ...options });

/**
 * Cohere Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/cohere)
 */
export const cohereProxyRouteCohereEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CohereProxyRouteCohereEndpointPostData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    CohereProxyRouteCohereEndpointPostResponses,
    CohereProxyRouteCohereEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cohere/{endpoint}',
    ...options,
  });

/**
 * Cohere Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/cohere)
 */
export const cohereProxyRouteCohereEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CohereProxyRouteCohereEndpointPost2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    CohereProxyRouteCohereEndpointPost2Responses,
    CohereProxyRouteCohereEndpointPost2Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cohere/{endpoint}',
    ...options,
  });

/**
 * Cohere Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/cohere)
 */
export const cohereProxyRouteCohereEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CohereProxyRouteCohereEndpointPost3Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    CohereProxyRouteCohereEndpointPost3Responses,
    CohereProxyRouteCohereEndpointPost3Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cohere/{endpoint}',
    ...options,
  });

/**
 * Cohere Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/cohere)
 */
export const cohereProxyRouteCohereEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CohereProxyRouteCohereEndpointPost4Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CohereProxyRouteCohereEndpointPost4Responses,
    CohereProxyRouteCohereEndpointPost4Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cohere/{endpoint}',
    ...options,
  });

/**
 * Cohere Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/cohere)
 */
export const cohereProxyRouteCohereEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CohereProxyRouteCohereEndpointPost5Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    CohereProxyRouteCohereEndpointPost5Responses,
    CohereProxyRouteCohereEndpointPost5Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cohere/{endpoint}',
    ...options,
  });

/**
 * Vllm Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/vllm)
 */
export const vllmProxyRouteVllmEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VllmProxyRouteVllmEndpointPostData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    VllmProxyRouteVllmEndpointPostResponses,
    VllmProxyRouteVllmEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vllm/{endpoint}',
    ...options,
  });

/**
 * Vllm Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/vllm)
 */
export const vllmProxyRouteVllmEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VllmProxyRouteVllmEndpointPost2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    VllmProxyRouteVllmEndpointPost2Responses,
    VllmProxyRouteVllmEndpointPost2Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vllm/{endpoint}',
    ...options,
  });

/**
 * Vllm Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/vllm)
 */
export const vllmProxyRouteVllmEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VllmProxyRouteVllmEndpointPost3Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    VllmProxyRouteVllmEndpointPost3Responses,
    VllmProxyRouteVllmEndpointPost3Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vllm/{endpoint}',
    ...options,
  });

/**
 * Vllm Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/vllm)
 */
export const vllmProxyRouteVllmEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VllmProxyRouteVllmEndpointPost4Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    VllmProxyRouteVllmEndpointPost4Responses,
    VllmProxyRouteVllmEndpointPost4Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vllm/{endpoint}',
    ...options,
  });

/**
 * Vllm Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/vllm)
 */
export const vllmProxyRouteVllmEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VllmProxyRouteVllmEndpointPost5Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    VllmProxyRouteVllmEndpointPost5Responses,
    VllmProxyRouteVllmEndpointPost5Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vllm/{endpoint}',
    ...options,
  });

/**
 * Mistral Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/anthropic_completion)
 */
export const mistralProxyRouteMistralEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<MistralProxyRouteMistralEndpointPostData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    MistralProxyRouteMistralEndpointPostResponses,
    MistralProxyRouteMistralEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/mistral/{endpoint}',
    ...options,
  });

/**
 * Mistral Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/anthropic_completion)
 */
export const mistralProxyRouteMistralEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<MistralProxyRouteMistralEndpointPost2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    MistralProxyRouteMistralEndpointPost2Responses,
    MistralProxyRouteMistralEndpointPost2Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/mistral/{endpoint}',
    ...options,
  });

/**
 * Mistral Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/anthropic_completion)
 */
export const mistralProxyRouteMistralEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<MistralProxyRouteMistralEndpointPost3Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    MistralProxyRouteMistralEndpointPost3Responses,
    MistralProxyRouteMistralEndpointPost3Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/mistral/{endpoint}',
    ...options,
  });

/**
 * Mistral Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/anthropic_completion)
 */
export const mistralProxyRouteMistralEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<MistralProxyRouteMistralEndpointPost4Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    MistralProxyRouteMistralEndpointPost4Responses,
    MistralProxyRouteMistralEndpointPost4Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/mistral/{endpoint}',
    ...options,
  });

/**
 * Mistral Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/anthropic_completion)
 */
export const mistralProxyRouteMistralEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<MistralProxyRouteMistralEndpointPost5Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    MistralProxyRouteMistralEndpointPost5Responses,
    MistralProxyRouteMistralEndpointPost5Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/mistral/{endpoint}',
    ...options,
  });

/**
 * Milvus Proxy Route
 *
 * Enable using Milvus `/vectors` endpoint as a pass-through endpoint.
 */
export const milvusProxyRouteMilvusEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<MilvusProxyRouteMilvusEndpointPostData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    MilvusProxyRouteMilvusEndpointPostResponses,
    MilvusProxyRouteMilvusEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/milvus/{endpoint}',
    ...options,
  });

/**
 * Milvus Proxy Route
 *
 * Enable using Milvus `/vectors` endpoint as a pass-through endpoint.
 */
export const milvusProxyRouteMilvusEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<MilvusProxyRouteMilvusEndpointPost2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    MilvusProxyRouteMilvusEndpointPost2Responses,
    MilvusProxyRouteMilvusEndpointPost2Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/milvus/{endpoint}',
    ...options,
  });

/**
 * Milvus Proxy Route
 *
 * Enable using Milvus `/vectors` endpoint as a pass-through endpoint.
 */
export const milvusProxyRouteMilvusEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<MilvusProxyRouteMilvusEndpointPost3Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    MilvusProxyRouteMilvusEndpointPost3Responses,
    MilvusProxyRouteMilvusEndpointPost3Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/milvus/{endpoint}',
    ...options,
  });

/**
 * Milvus Proxy Route
 *
 * Enable using Milvus `/vectors` endpoint as a pass-through endpoint.
 */
export const milvusProxyRouteMilvusEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<MilvusProxyRouteMilvusEndpointPost4Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    MilvusProxyRouteMilvusEndpointPost4Responses,
    MilvusProxyRouteMilvusEndpointPost4Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/milvus/{endpoint}',
    ...options,
  });

/**
 * Milvus Proxy Route
 *
 * Enable using Milvus `/vectors` endpoint as a pass-through endpoint.
 */
export const milvusProxyRouteMilvusEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<MilvusProxyRouteMilvusEndpointPost5Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    MilvusProxyRouteMilvusEndpointPost5Responses,
    MilvusProxyRouteMilvusEndpointPost5Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/milvus/{endpoint}',
    ...options,
  });

/**
 * Anthropic Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/anthropic_completion)
 */
export const anthropicProxyRouteAnthropicEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AnthropicProxyRouteAnthropicEndpointPostData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    AnthropicProxyRouteAnthropicEndpointPostResponses,
    AnthropicProxyRouteAnthropicEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/anthropic/{endpoint}',
    ...options,
  });

/**
 * Anthropic Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/anthropic_completion)
 */
export const anthropicProxyRouteAnthropicEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AnthropicProxyRouteAnthropicEndpointPost2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    AnthropicProxyRouteAnthropicEndpointPost2Responses,
    AnthropicProxyRouteAnthropicEndpointPost2Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/anthropic/{endpoint}',
    ...options,
  });

/**
 * Anthropic Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/anthropic_completion)
 */
export const anthropicProxyRouteAnthropicEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AnthropicProxyRouteAnthropicEndpointPost3Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    AnthropicProxyRouteAnthropicEndpointPost3Responses,
    AnthropicProxyRouteAnthropicEndpointPost3Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/anthropic/{endpoint}',
    ...options,
  });

/**
 * Anthropic Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/anthropic_completion)
 */
export const anthropicProxyRouteAnthropicEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AnthropicProxyRouteAnthropicEndpointPost4Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    AnthropicProxyRouteAnthropicEndpointPost4Responses,
    AnthropicProxyRouteAnthropicEndpointPost4Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/anthropic/{endpoint}',
    ...options,
  });

/**
 * Anthropic Proxy Route
 *
 * [Docs](https://docs.litellm.ai/docs/anthropic_completion)
 */
export const anthropicProxyRouteAnthropicEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AnthropicProxyRouteAnthropicEndpointPost5Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    AnthropicProxyRouteAnthropicEndpointPost5Responses,
    AnthropicProxyRouteAnthropicEndpointPost5Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/anthropic/{endpoint}',
    ...options,
  });

/**
 * Bedrock Proxy Route
 *
 * This is the v1 passthrough for Bedrock.
 * V2 is handled by the `/bedrock/v2` endpoint.
 * [Docs](https://docs.litellm.ai/docs/pass_through/bedrock)
 */
export const bedrockProxyRouteBedrockEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<BedrockProxyRouteBedrockEndpointPostData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    BedrockProxyRouteBedrockEndpointPostResponses,
    BedrockProxyRouteBedrockEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/bedrock/{endpoint}',
    ...options,
  });

/**
 * Bedrock Proxy Route
 *
 * This is the v1 passthrough for Bedrock.
 * V2 is handled by the `/bedrock/v2` endpoint.
 * [Docs](https://docs.litellm.ai/docs/pass_through/bedrock)
 */
export const bedrockProxyRouteBedrockEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<BedrockProxyRouteBedrockEndpointPost2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    BedrockProxyRouteBedrockEndpointPost2Responses,
    BedrockProxyRouteBedrockEndpointPost2Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/bedrock/{endpoint}',
    ...options,
  });

/**
 * Bedrock Proxy Route
 *
 * This is the v1 passthrough for Bedrock.
 * V2 is handled by the `/bedrock/v2` endpoint.
 * [Docs](https://docs.litellm.ai/docs/pass_through/bedrock)
 */
export const bedrockProxyRouteBedrockEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<BedrockProxyRouteBedrockEndpointPost3Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    BedrockProxyRouteBedrockEndpointPost3Responses,
    BedrockProxyRouteBedrockEndpointPost3Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/bedrock/{endpoint}',
    ...options,
  });

/**
 * Bedrock Proxy Route
 *
 * This is the v1 passthrough for Bedrock.
 * V2 is handled by the `/bedrock/v2` endpoint.
 * [Docs](https://docs.litellm.ai/docs/pass_through/bedrock)
 */
export const bedrockProxyRouteBedrockEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<BedrockProxyRouteBedrockEndpointPost4Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    BedrockProxyRouteBedrockEndpointPost4Responses,
    BedrockProxyRouteBedrockEndpointPost4Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/bedrock/{endpoint}',
    ...options,
  });

/**
 * Bedrock Proxy Route
 *
 * This is the v1 passthrough for Bedrock.
 * V2 is handled by the `/bedrock/v2` endpoint.
 * [Docs](https://docs.litellm.ai/docs/pass_through/bedrock)
 */
export const bedrockProxyRouteBedrockEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<BedrockProxyRouteBedrockEndpointPost5Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    BedrockProxyRouteBedrockEndpointPost5Responses,
    BedrockProxyRouteBedrockEndpointPost5Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/bedrock/{endpoint}',
    ...options,
  });

/**
 * Assemblyai Proxy Route
 */
export const assemblyaiProxyRouteEuAssemblyaiEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AssemblyaiProxyRouteEuAssemblyaiEndpointPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    AssemblyaiProxyRouteEuAssemblyaiEndpointPostResponses,
    AssemblyaiProxyRouteEuAssemblyaiEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/eu.assemblyai/{endpoint}',
    ...options,
  });

/**
 * Assemblyai Proxy Route
 */
export const assemblyaiProxyRouteEuAssemblyaiEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AssemblyaiProxyRouteEuAssemblyaiEndpointPost2Data,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    AssemblyaiProxyRouteEuAssemblyaiEndpointPost2Responses,
    AssemblyaiProxyRouteEuAssemblyaiEndpointPost2Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/eu.assemblyai/{endpoint}',
    ...options,
  });

/**
 * Assemblyai Proxy Route
 */
export const assemblyaiProxyRouteEuAssemblyaiEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AssemblyaiProxyRouteEuAssemblyaiEndpointPost3Data,
    ThrowOnError
  >,
) =>
  (options.client ?? client).patch<
    AssemblyaiProxyRouteEuAssemblyaiEndpointPost3Responses,
    AssemblyaiProxyRouteEuAssemblyaiEndpointPost3Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/eu.assemblyai/{endpoint}',
    ...options,
  });

/**
 * Assemblyai Proxy Route
 */
export const assemblyaiProxyRouteEuAssemblyaiEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AssemblyaiProxyRouteEuAssemblyaiEndpointPost4Data,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    AssemblyaiProxyRouteEuAssemblyaiEndpointPost4Responses,
    AssemblyaiProxyRouteEuAssemblyaiEndpointPost4Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/eu.assemblyai/{endpoint}',
    ...options,
  });

/**
 * Assemblyai Proxy Route
 */
export const assemblyaiProxyRouteEuAssemblyaiEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AssemblyaiProxyRouteEuAssemblyaiEndpointPost5Data,
    ThrowOnError
  >,
) =>
  (options.client ?? client).put<
    AssemblyaiProxyRouteEuAssemblyaiEndpointPost5Responses,
    AssemblyaiProxyRouteEuAssemblyaiEndpointPost5Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/eu.assemblyai/{endpoint}',
    ...options,
  });

/**
 * Assemblyai Proxy Route
 */
export const assemblyaiProxyRouteAssemblyaiEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AssemblyaiProxyRouteAssemblyaiEndpointPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    AssemblyaiProxyRouteAssemblyaiEndpointPostResponses,
    AssemblyaiProxyRouteAssemblyaiEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/assemblyai/{endpoint}',
    ...options,
  });

/**
 * Assemblyai Proxy Route
 */
export const assemblyaiProxyRouteAssemblyaiEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AssemblyaiProxyRouteAssemblyaiEndpointPost2Data,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    AssemblyaiProxyRouteAssemblyaiEndpointPost2Responses,
    AssemblyaiProxyRouteAssemblyaiEndpointPost2Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/assemblyai/{endpoint}',
    ...options,
  });

/**
 * Assemblyai Proxy Route
 */
export const assemblyaiProxyRouteAssemblyaiEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AssemblyaiProxyRouteAssemblyaiEndpointPost3Data,
    ThrowOnError
  >,
) =>
  (options.client ?? client).patch<
    AssemblyaiProxyRouteAssemblyaiEndpointPost3Responses,
    AssemblyaiProxyRouteAssemblyaiEndpointPost3Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/assemblyai/{endpoint}',
    ...options,
  });

/**
 * Assemblyai Proxy Route
 */
export const assemblyaiProxyRouteAssemblyaiEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AssemblyaiProxyRouteAssemblyaiEndpointPost4Data,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    AssemblyaiProxyRouteAssemblyaiEndpointPost4Responses,
    AssemblyaiProxyRouteAssemblyaiEndpointPost4Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/assemblyai/{endpoint}',
    ...options,
  });

/**
 * Assemblyai Proxy Route
 */
export const assemblyaiProxyRouteAssemblyaiEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AssemblyaiProxyRouteAssemblyaiEndpointPost5Data,
    ThrowOnError
  >,
) =>
  (options.client ?? client).put<
    AssemblyaiProxyRouteAssemblyaiEndpointPost5Responses,
    AssemblyaiProxyRouteAssemblyaiEndpointPost5Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/assemblyai/{endpoint}',
    ...options,
  });

/**
 * Azure Proxy Route
 *
 * Call any azure endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/azure/{endpoint:path}`
 *
 * Checks if the deployment id in the url is a litellm model name. If so, it will route using the llm_router.allm_passthrough_route.
 */
export const azureProxyRouteAzureEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AzureProxyRouteAzureEndpointPostData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    AzureProxyRouteAzureEndpointPostResponses,
    AzureProxyRouteAzureEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/azure/{endpoint}',
    ...options,
  });

/**
 * Azure Proxy Route
 *
 * Call any azure endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/azure/{endpoint:path}`
 *
 * Checks if the deployment id in the url is a litellm model name. If so, it will route using the llm_router.allm_passthrough_route.
 */
export const azureProxyRouteAzureEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AzureProxyRouteAzureEndpointPost2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    AzureProxyRouteAzureEndpointPost2Responses,
    AzureProxyRouteAzureEndpointPost2Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/azure/{endpoint}',
    ...options,
  });

/**
 * Azure Proxy Route
 *
 * Call any azure endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/azure/{endpoint:path}`
 *
 * Checks if the deployment id in the url is a litellm model name. If so, it will route using the llm_router.allm_passthrough_route.
 */
export const azureProxyRouteAzureEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AzureProxyRouteAzureEndpointPost3Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    AzureProxyRouteAzureEndpointPost3Responses,
    AzureProxyRouteAzureEndpointPost3Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/azure/{endpoint}',
    ...options,
  });

/**
 * Azure Proxy Route
 *
 * Call any azure endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/azure/{endpoint:path}`
 *
 * Checks if the deployment id in the url is a litellm model name. If so, it will route using the llm_router.allm_passthrough_route.
 */
export const azureProxyRouteAzureEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AzureProxyRouteAzureEndpointPost4Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    AzureProxyRouteAzureEndpointPost4Responses,
    AzureProxyRouteAzureEndpointPost4Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/azure/{endpoint}',
    ...options,
  });

/**
 * Azure Proxy Route
 *
 * Call any azure endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/azure/{endpoint:path}`
 *
 * Checks if the deployment id in the url is a litellm model name. If so, it will route using the llm_router.allm_passthrough_route.
 */
export const azureProxyRouteAzureEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AzureProxyRouteAzureEndpointPost5Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    AzureProxyRouteAzureEndpointPost5Responses,
    AzureProxyRouteAzureEndpointPost5Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/azure/{endpoint}',
    ...options,
  });

/**
 * Azure Proxy Route
 *
 * Call any azure endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/azure/{endpoint:path}`
 *
 * Checks if the deployment id in the url is a litellm model name. If so, it will route using the llm_router.allm_passthrough_route.
 */
export const azureProxyRouteAzureAiEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AzureProxyRouteAzureAiEndpointPostData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    AzureProxyRouteAzureAiEndpointPostResponses,
    AzureProxyRouteAzureAiEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/azure_ai/{endpoint}',
    ...options,
  });

/**
 * Azure Proxy Route
 *
 * Call any azure endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/azure/{endpoint:path}`
 *
 * Checks if the deployment id in the url is a litellm model name. If so, it will route using the llm_router.allm_passthrough_route.
 */
export const azureProxyRouteAzureAiEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AzureProxyRouteAzureAiEndpointPost2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    AzureProxyRouteAzureAiEndpointPost2Responses,
    AzureProxyRouteAzureAiEndpointPost2Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/azure_ai/{endpoint}',
    ...options,
  });

/**
 * Azure Proxy Route
 *
 * Call any azure endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/azure/{endpoint:path}`
 *
 * Checks if the deployment id in the url is a litellm model name. If so, it will route using the llm_router.allm_passthrough_route.
 */
export const azureProxyRouteAzureAiEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AzureProxyRouteAzureAiEndpointPost3Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    AzureProxyRouteAzureAiEndpointPost3Responses,
    AzureProxyRouteAzureAiEndpointPost3Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/azure_ai/{endpoint}',
    ...options,
  });

/**
 * Azure Proxy Route
 *
 * Call any azure endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/azure/{endpoint:path}`
 *
 * Checks if the deployment id in the url is a litellm model name. If so, it will route using the llm_router.allm_passthrough_route.
 */
export const azureProxyRouteAzureAiEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AzureProxyRouteAzureAiEndpointPost4Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    AzureProxyRouteAzureAiEndpointPost4Responses,
    AzureProxyRouteAzureAiEndpointPost4Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/azure_ai/{endpoint}',
    ...options,
  });

/**
 * Azure Proxy Route
 *
 * Call any azure endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/azure/{endpoint:path}`
 *
 * Checks if the deployment id in the url is a litellm model name. If so, it will route using the llm_router.allm_passthrough_route.
 */
export const azureProxyRouteAzureAiEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AzureProxyRouteAzureAiEndpointPost5Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    AzureProxyRouteAzureAiEndpointPost5Responses,
    AzureProxyRouteAzureAiEndpointPost5Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/azure_ai/{endpoint}',
    ...options,
  });

/**
 * Vertex Discovery Proxy Route
 *
 * Call any vertex discovery endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/vertex_ai/discovery/{endpoint:path}`
 *
 * Target url: `https://discoveryengine.googleapis.com`
 */
export const vertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPostResponses,
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPostErrors,
    ThrowOnError
  >({ url: '/vertex_ai/discovery/{endpoint}', ...options });

/**
 * Vertex Discovery Proxy Route
 *
 * Call any vertex discovery endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/vertex_ai/discovery/{endpoint:path}`
 *
 * Target url: `https://discoveryengine.googleapis.com`
 */
export const vertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost2Data,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost2Responses,
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost2Errors,
    ThrowOnError
  >({ url: '/vertex_ai/discovery/{endpoint}', ...options });

/**
 * Vertex Discovery Proxy Route
 *
 * Call any vertex discovery endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/vertex_ai/discovery/{endpoint:path}`
 *
 * Target url: `https://discoveryengine.googleapis.com`
 */
export const vertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost3Data,
    ThrowOnError
  >,
) =>
  (options.client ?? client).patch<
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost3Responses,
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost3Errors,
    ThrowOnError
  >({ url: '/vertex_ai/discovery/{endpoint}', ...options });

/**
 * Vertex Discovery Proxy Route
 *
 * Call any vertex discovery endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/vertex_ai/discovery/{endpoint:path}`
 *
 * Target url: `https://discoveryengine.googleapis.com`
 */
export const vertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost4Data,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost4Responses,
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost4Errors,
    ThrowOnError
  >({ url: '/vertex_ai/discovery/{endpoint}', ...options });

/**
 * Vertex Discovery Proxy Route
 *
 * Call any vertex discovery endpoint using the proxy.
 *
 * Just use `{PROXY_BASE_URL}/vertex_ai/discovery/{endpoint:path}`
 *
 * Target url: `https://discoveryengine.googleapis.com`
 */
export const vertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost5Data,
    ThrowOnError
  >,
) =>
  (options.client ?? client).put<
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost5Responses,
    VertexDiscoveryProxyRouteVertexAiDiscoveryEndpointPost5Errors,
    ThrowOnError
  >({ url: '/vertex_ai/discovery/{endpoint}', ...options });

/**
 * Vertex Proxy Route
 *
 * Call LiteLLM proxy via Vertex AI SDK.
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/vertex_ai)
 */
export const vertexProxyRouteVertexAiEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VertexProxyRouteVertexAiEndpointPostData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    VertexProxyRouteVertexAiEndpointPostResponses,
    VertexProxyRouteVertexAiEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vertex_ai/{endpoint}',
    ...options,
  });

/**
 * Vertex Proxy Route
 *
 * Call LiteLLM proxy via Vertex AI SDK.
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/vertex_ai)
 */
export const vertexProxyRouteVertexAiEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VertexProxyRouteVertexAiEndpointPost2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    VertexProxyRouteVertexAiEndpointPost2Responses,
    VertexProxyRouteVertexAiEndpointPost2Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vertex_ai/{endpoint}',
    ...options,
  });

/**
 * Vertex Proxy Route
 *
 * Call LiteLLM proxy via Vertex AI SDK.
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/vertex_ai)
 */
export const vertexProxyRouteVertexAiEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VertexProxyRouteVertexAiEndpointPost3Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    VertexProxyRouteVertexAiEndpointPost3Responses,
    VertexProxyRouteVertexAiEndpointPost3Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vertex_ai/{endpoint}',
    ...options,
  });

/**
 * Vertex Proxy Route
 *
 * Call LiteLLM proxy via Vertex AI SDK.
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/vertex_ai)
 */
export const vertexProxyRouteVertexAiEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VertexProxyRouteVertexAiEndpointPost4Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    VertexProxyRouteVertexAiEndpointPost4Responses,
    VertexProxyRouteVertexAiEndpointPost4Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vertex_ai/{endpoint}',
    ...options,
  });

/**
 * Vertex Proxy Route
 *
 * Call LiteLLM proxy via Vertex AI SDK.
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/vertex_ai)
 */
export const vertexProxyRouteVertexAiEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<VertexProxyRouteVertexAiEndpointPost5Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    VertexProxyRouteVertexAiEndpointPost5Responses,
    VertexProxyRouteVertexAiEndpointPost5Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/vertex_ai/{endpoint}',
    ...options,
  });

/**
 * Openai Proxy Route
 *
 * Simple pass-through for OpenAI. Use this if you want to directly send a request to OpenAI.
 */
export const openaiProxyRouteOpenaiEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<OpenaiProxyRouteOpenaiEndpointPostData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    OpenaiProxyRouteOpenaiEndpointPostResponses,
    OpenaiProxyRouteOpenaiEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/{endpoint}',
    ...options,
  });

/**
 * Openai Proxy Route
 *
 * Simple pass-through for OpenAI. Use this if you want to directly send a request to OpenAI.
 */
export const openaiProxyRouteOpenaiEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<OpenaiProxyRouteOpenaiEndpointPost2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    OpenaiProxyRouteOpenaiEndpointPost2Responses,
    OpenaiProxyRouteOpenaiEndpointPost2Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/{endpoint}',
    ...options,
  });

/**
 * Openai Proxy Route
 *
 * Simple pass-through for OpenAI. Use this if you want to directly send a request to OpenAI.
 */
export const openaiProxyRouteOpenaiEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<OpenaiProxyRouteOpenaiEndpointPost3Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    OpenaiProxyRouteOpenaiEndpointPost3Responses,
    OpenaiProxyRouteOpenaiEndpointPost3Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/{endpoint}',
    ...options,
  });

/**
 * Openai Proxy Route
 *
 * Simple pass-through for OpenAI. Use this if you want to directly send a request to OpenAI.
 */
export const openaiProxyRouteOpenaiEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<OpenaiProxyRouteOpenaiEndpointPost4Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    OpenaiProxyRouteOpenaiEndpointPost4Responses,
    OpenaiProxyRouteOpenaiEndpointPost4Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/{endpoint}',
    ...options,
  });

/**
 * Openai Proxy Route
 *
 * Simple pass-through for OpenAI. Use this if you want to directly send a request to OpenAI.
 */
export const openaiProxyRouteOpenaiEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<OpenaiProxyRouteOpenaiEndpointPost5Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    OpenaiProxyRouteOpenaiEndpointPost5Responses,
    OpenaiProxyRouteOpenaiEndpointPost5Errors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/openai/{endpoint}',
    ...options,
  });

/**
 * Get Mcp Tools
 *
 * Get all MCP tools available for the current key, including those from access groups
 */
export const getMcpToolsV1McpToolsGet = <ThrowOnError extends boolean = false>(
  options?: Options<GetMcpToolsV1McpToolsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetMcpToolsV1McpToolsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/mcp/tools',
    ...options,
  });

/**
 * Get Mcp Access Groups
 *
 * Get all available MCP access groups from the database AND config
 */
export const getMcpAccessGroupsV1McpAccessGroupsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetMcpAccessGroupsV1McpAccessGroupsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetMcpAccessGroupsV1McpAccessGroupsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/mcp/access_groups',
    ...options,
  });

/**
 * Health Check Mcp Server
 *
 * Perform health check on a specific MCP server
 */
export const healthCheckMcpServerV1McpServerServerIdHealthGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    HealthCheckMcpServerV1McpServerServerIdHealthGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    HealthCheckMcpServerV1McpServerServerIdHealthGetResponses,
    HealthCheckMcpServerV1McpServerServerIdHealthGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/mcp/server/{server_id}/health',
    ...options,
  });

/**
 * Health Check All Mcp Servers
 *
 * Perform health check on all accessible MCP servers
 */
export const healthCheckAllMcpServersV1McpServerHealthGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    HealthCheckAllMcpServersV1McpServerHealthGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    HealthCheckAllMcpServersV1McpServerHealthGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/mcp/server/health',
    ...options,
  });

/**
 * Fetch All Mcp Servers
 *
 * Returns the mcp server list with associated teams
 */
export const fetchAllMcpServersV1McpServerGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<FetchAllMcpServersV1McpServerGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    FetchAllMcpServersV1McpServerGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/mcp/server',
    ...options,
  });

/**
 * Add Mcp Server
 *
 * Allows creation of mcp servers
 */
export const addMcpServerV1McpServerPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AddMcpServerV1McpServerPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    AddMcpServerV1McpServerPostResponses,
    AddMcpServerV1McpServerPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/mcp/server',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Edit Mcp Server
 *
 * Allows deleting mcp serves in the db
 */
export const editMcpServerV1McpServerPut = <
  ThrowOnError extends boolean = false,
>(
  options: Options<EditMcpServerV1McpServerPutData, ThrowOnError>,
) =>
  (options.client ?? client).put<
    EditMcpServerV1McpServerPutResponses,
    EditMcpServerV1McpServerPutErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/mcp/server',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Remove Mcp Server
 *
 * Allows deleting mcp serves in the db
 */
export const removeMcpServerV1McpServerServerIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<RemoveMcpServerV1McpServerServerIdDeleteData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    RemoveMcpServerV1McpServerServerIdDeleteResponses,
    RemoveMcpServerV1McpServerServerIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/mcp/server/{server_id}',
    ...options,
  });

/**
 * Fetch Mcp Server
 *
 * Returns the mcp server info
 */
export const fetchMcpServerV1McpServerServerIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<FetchMcpServerV1McpServerServerIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    FetchMcpServerV1McpServerServerIdGetResponses,
    FetchMcpServerV1McpServerServerIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/mcp/server/{server_id}',
    ...options,
  });

/**
 * Add Session Mcp Server
 *
 * Temporarily cache an MCP server in memory without writing to the database
 */
export const addSessionMcpServerV1McpServerOauthSessionPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    AddSessionMcpServerV1McpServerOauthSessionPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    AddSessionMcpServerV1McpServerOauthSessionPostResponses,
    AddSessionMcpServerV1McpServerOauthSessionPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/mcp/server/oauth/session',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Make Mcp Servers Public
 *
 * Allows making MCP servers public for AI Hub
 */
export const makeMcpServersPublicV1McpMakePublicPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<MakeMcpServersPublicV1McpMakePublicPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    MakeMcpServersPublicV1McpMakePublicPostResponses,
    MakeMcpServersPublicV1McpMakePublicPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/mcp/make_public',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Anthropic Response
 *
 * Use `{PROXY_BASE_URL}/anthropic/v1/messages` instead - [Docs](https://docs.litellm.ai/docs/anthropic_completion).
 *
 * This was a BETA endpoint that calls 100+ LLMs in the anthropic format.
 */
export const anthropicResponseV1MessagesPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<AnthropicResponseV1MessagesPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    AnthropicResponseV1MessagesPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/messages',
    ...options,
  });

/**
 * Count Tokens
 *
 * Count tokens for Anthropic Messages API format.
 *
 * This endpoint follows the Anthropic Messages API token counting specification.
 * It accepts the same parameters as the /v1/messages endpoint but returns
 * token counts instead of generating a response.
 *
 * Example usage:
 * ```
 * curl -X POST "http://localhost:4000/v1/messages/count_tokens?beta=true"       -H "Content-Type: application/json"       -H "Authorization: Bearer your-key"       -d '{
 * "model": "claude-3-sonnet-20240229",
 * "messages": [{"role": "user", "content": "Hello Claude!"}]
 * }'
 * ```
 *
 * Returns: {"input_tokens": <number>}
 */
export const countTokensV1MessagesCountTokensPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<CountTokensV1MessagesCountTokensPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CountTokensV1MessagesCountTokensPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/messages/count_tokens',
    ...options,
  });

/**
 * List Skills
 *
 * List skills on Anthropic.
 *
 * Requires `?beta=true` query parameter.
 *
 * Model-based routing (for multi-account support):
 * - Pass model via header: `x-litellm-model: claude-account-1`
 * - Pass model via query: `?model=claude-account-1`
 * - Pass model via body: `{"model": "claude-account-1"}`
 *
 * Example usage:
 * ```bash
 * # Basic usage
 * curl "http://localhost:4000/v1/skills?beta=true&limit=10"       -H "Authorization: Bearer your-key"
 *
 * # With model-based routing
 * curl "http://localhost:4000/v1/skills?beta=true&limit=10"       -H "Authorization: Bearer your-key"       -H "x-litellm-model: claude-account-1"
 * ```
 *
 * Returns: ListSkillsResponse with list of skills
 */
export const listSkillsV1SkillsGet = <ThrowOnError extends boolean = false>(
  options?: Options<ListSkillsV1SkillsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListSkillsV1SkillsGetResponses,
    ListSkillsV1SkillsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/skills',
    ...options,
  });

/**
 * Create Skill
 *
 * Create a new skill on Anthropic.
 *
 * Requires `?beta=true` query parameter.
 *
 * Model-based routing (for multi-account support):
 * - Pass model via header: `x-litellm-model: claude-account-1`
 * - Pass model via query: `?model=claude-account-1`
 * - Pass model via form field: `model=claude-account-1`
 *
 * Example usage:
 * ```bash
 * # Basic usage
 * curl -X POST "http://localhost:4000/v1/skills?beta=true"       -H "Content-Type: multipart/form-data"       -H "Authorization: Bearer your-key"       -F "display_title=My Skill"       -F "files[]=@skill.zip"
 *
 * # With model-based routing
 * curl -X POST "http://localhost:4000/v1/skills?beta=true"       -H "Content-Type: multipart/form-data"       -H "Authorization: Bearer your-key"       -H "x-litellm-model: claude-account-1"       -F "display_title=My Skill"       -F "files[]=@skill.zip"
 * ```
 *
 * Returns: Skill object with id, display_title, etc.
 */
export const createSkillV1SkillsPost = <ThrowOnError extends boolean = false>(
  options?: Options<CreateSkillV1SkillsPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CreateSkillV1SkillsPostResponses,
    CreateSkillV1SkillsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/skills',
    ...options,
  });

/**
 * Delete Skill
 *
 * Delete a skill by ID from Anthropic.
 *
 * Requires `?beta=true` query parameter.
 *
 * Note: Anthropic does not allow deleting skills with existing versions.
 *
 * Model-based routing (for multi-account support):
 * - Pass model via header: `x-litellm-model: claude-account-1`
 * - Pass model via query: `?model=claude-account-1`
 * - Pass model via body: `{"model": "claude-account-1"}`
 *
 * Example usage:
 * ```bash
 * # Basic usage
 * curl -X DELETE "http://localhost:4000/v1/skills/skill_123?beta=true"       -H "Authorization: Bearer your-key"
 *
 * # With model-based routing
 * curl -X DELETE "http://localhost:4000/v1/skills/skill_123?beta=true"       -H "Authorization: Bearer your-key"       -H "x-litellm-model: claude-account-1"
 * ```
 *
 * Returns: DeleteSkillResponse with type="skill_deleted"
 */
export const deleteSkillV1SkillsSkillIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteSkillV1SkillsSkillIdDeleteData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    DeleteSkillV1SkillsSkillIdDeleteResponses,
    DeleteSkillV1SkillsSkillIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/skills/{skill_id}',
    ...options,
  });

/**
 * Get Skill
 *
 * Get a specific skill by ID from Anthropic.
 *
 * Requires `?beta=true` query parameter.
 *
 * Model-based routing (for multi-account support):
 * - Pass model via header: `x-litellm-model: claude-account-1`
 * - Pass model via query: `?model=claude-account-1`
 * - Pass model via body: `{"model": "claude-account-1"}`
 *
 * Example usage:
 * ```bash
 * # Basic usage
 * curl "http://localhost:4000/v1/skills/skill_123?beta=true"       -H "Authorization: Bearer your-key"
 *
 * # With model-based routing
 * curl "http://localhost:4000/v1/skills/skill_123?beta=true"       -H "Authorization: Bearer your-key"       -H "x-litellm-model: claude-account-1"
 * ```
 *
 * Returns: Skill object
 */
export const getSkillV1SkillsSkillIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetSkillV1SkillsSkillIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetSkillV1SkillsSkillIdGetResponses,
    GetSkillV1SkillsSkillIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/skills/{skill_id}',
    ...options,
  });

/**
 * Google Generate Content
 */
export const googleGenerateContentModelsModelNameGenerateContentPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GoogleGenerateContentModelsModelNameGenerateContentPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    GoogleGenerateContentModelsModelNameGenerateContentPostResponses,
    GoogleGenerateContentModelsModelNameGenerateContentPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/models/{model_name}:generateContent',
    ...options,
  });

/**
 * Google Generate Content
 */
export const googleGenerateContentV1BetaModelsModelNameGenerateContentPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostResponses,
    GoogleGenerateContentV1BetaModelsModelNameGenerateContentPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1beta/models/{model_name}:generateContent',
    ...options,
  });

/**
 * Google Stream Generate Content
 */
export const googleStreamGenerateContentModelsModelNameStreamGenerateContentPost =
  <ThrowOnError extends boolean = false>(
    options: Options<
      GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostData,
      ThrowOnError
    >,
  ) =>
    (options.client ?? client).post<
      GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostResponses,
      GoogleStreamGenerateContentModelsModelNameStreamGenerateContentPostErrors,
      ThrowOnError
    >({
      security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
      url: '/models/{model_name}:streamGenerateContent',
      ...options,
    });

/**
 * Google Stream Generate Content
 */
export const googleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPost =
  <ThrowOnError extends boolean = false>(
    options: Options<
      GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostData,
      ThrowOnError
    >,
  ) =>
    (options.client ?? client).post<
      GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostResponses,
      GoogleStreamGenerateContentV1BetaModelsModelNameStreamGenerateContentPostErrors,
      ThrowOnError
    >({
      security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
      url: '/v1beta/models/{model_name}:streamGenerateContent',
      ...options,
    });

/**
 * Google Count Tokens
 *
 * ```json
 * return {
 * "totalTokens": 31,
 * "totalBillableCharacters": 96,
 * "promptTokensDetails": [
 * {
 * "modality": "TEXT",
 * "tokenCount": 31
 * }
 * ]
 * }
 * ```
 */
export const googleCountTokensModelsModelNameCountTokensPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GoogleCountTokensModelsModelNameCountTokensPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    GoogleCountTokensModelsModelNameCountTokensPostResponses,
    GoogleCountTokensModelsModelNameCountTokensPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/models/{model_name}:countTokens',
    ...options,
  });

/**
 * Google Count Tokens
 *
 * ```json
 * return {
 * "totalTokens": 31,
 * "totalBillableCharacters": 96,
 * "promptTokensDetails": [
 * {
 * "modality": "TEXT",
 * "tokenCount": 31
 * }
 * ]
 * }
 * ```
 */
export const googleCountTokensV1BetaModelsModelNameCountTokensPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GoogleCountTokensV1BetaModelsModelNameCountTokensPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    GoogleCountTokensV1BetaModelsModelNameCountTokensPostResponses,
    GoogleCountTokensV1BetaModelsModelNameCountTokensPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1beta/models/{model_name}:countTokens',
    ...options,
  });

/**
 * Langfuse Proxy Route
 *
 * Call Langfuse via LiteLLM proxy. Works with Langfuse SDK.
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/langfuse)
 */
export const langfuseProxyRouteLangfuseEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<LangfuseProxyRouteLangfuseEndpointPostData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    LangfuseProxyRouteLangfuseEndpointPostResponses,
    LangfuseProxyRouteLangfuseEndpointPostErrors,
    ThrowOnError
  >({ url: '/langfuse/{endpoint}', ...options });

/**
 * Langfuse Proxy Route
 *
 * Call Langfuse via LiteLLM proxy. Works with Langfuse SDK.
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/langfuse)
 */
export const langfuseProxyRouteLangfuseEndpointPost2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<LangfuseProxyRouteLangfuseEndpointPost2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    LangfuseProxyRouteLangfuseEndpointPost2Responses,
    LangfuseProxyRouteLangfuseEndpointPost2Errors,
    ThrowOnError
  >({ url: '/langfuse/{endpoint}', ...options });

/**
 * Langfuse Proxy Route
 *
 * Call Langfuse via LiteLLM proxy. Works with Langfuse SDK.
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/langfuse)
 */
export const langfuseProxyRouteLangfuseEndpointPost3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<LangfuseProxyRouteLangfuseEndpointPost3Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    LangfuseProxyRouteLangfuseEndpointPost3Responses,
    LangfuseProxyRouteLangfuseEndpointPost3Errors,
    ThrowOnError
  >({ url: '/langfuse/{endpoint}', ...options });

/**
 * Langfuse Proxy Route
 *
 * Call Langfuse via LiteLLM proxy. Works with Langfuse SDK.
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/langfuse)
 */
export const langfuseProxyRouteLangfuseEndpointPost4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<LangfuseProxyRouteLangfuseEndpointPost4Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    LangfuseProxyRouteLangfuseEndpointPost4Responses,
    LangfuseProxyRouteLangfuseEndpointPost4Errors,
    ThrowOnError
  >({ url: '/langfuse/{endpoint}', ...options });

/**
 * Langfuse Proxy Route
 *
 * Call Langfuse via LiteLLM proxy. Works with Langfuse SDK.
 *
 * [Docs](https://docs.litellm.ai/docs/pass_through/langfuse)
 */
export const langfuseProxyRouteLangfuseEndpointPost5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<LangfuseProxyRouteLangfuseEndpointPost5Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    LangfuseProxyRouteLangfuseEndpointPost5Responses,
    LangfuseProxyRouteLangfuseEndpointPost5Errors,
    ThrowOnError
  >({ url: '/langfuse/{endpoint}', ...options });

/**
 * Get Pass Through Endpoints
 *
 * GET configured pass through endpoint.
 *
 * If no endpoint_id given, return all configured endpoints.
 */
export const getPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetResponses,
    GetPassThroughEndpointsConfigPassThroughEndpointTeamTeamIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/config/pass_through_endpoint/team/{team_id}',
    ...options,
  });

/**
 * Delete Pass Through Endpoints
 *
 * Delete a pass-through endpoint by ID.
 *
 * Returns - the deleted endpoint
 */
export const deletePassThroughEndpointsConfigPassThroughEndpointDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DeletePassThroughEndpointsConfigPassThroughEndpointDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    DeletePassThroughEndpointsConfigPassThroughEndpointDeleteResponses,
    DeletePassThroughEndpointsConfigPassThroughEndpointDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/config/pass_through_endpoint',
    ...options,
  });

/**
 * Get Pass Through Endpoints
 *
 * GET configured pass through endpoint.
 *
 * If no endpoint_id given, return all configured endpoints.
 */
export const getPassThroughEndpointsConfigPassThroughEndpointGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetPassThroughEndpointsConfigPassThroughEndpointGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetPassThroughEndpointsConfigPassThroughEndpointGetResponses,
    GetPassThroughEndpointsConfigPassThroughEndpointGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/config/pass_through_endpoint',
    ...options,
  });

/**
 * Create Pass Through Endpoints
 *
 * Create new pass-through endpoint
 */
export const createPassThroughEndpointsConfigPassThroughEndpointPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    CreatePassThroughEndpointsConfigPassThroughEndpointPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    CreatePassThroughEndpointsConfigPassThroughEndpointPostResponses,
    CreatePassThroughEndpointsConfigPassThroughEndpointPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/config/pass_through_endpoint',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Pass Through Endpoints
 *
 * Update a pass-through endpoint by ID.
 */
export const updatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPost =
  <ThrowOnError extends boolean = false>(
    options: Options<
      UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostData,
      ThrowOnError
    >,
  ) =>
    (options.client ?? client).post<
      UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostResponses,
      UpdatePassThroughEndpointsConfigPassThroughEndpointEndpointIdPostErrors,
      ThrowOnError
    >({
      security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
      url: '/config/pass_through_endpoint/{endpoint_id}',
      ...options,
      headers: {
        'Content-Type': 'application/json',
        ...options.headers,
      },
    });

/**
 * Test Endpoint
 *
 * [DEPRECATED] use `/health/liveliness` instead.
 *
 * A test endpoint that pings the proxy server to check if it's healthy.
 *
 * Parameters:
 * request (Request): The incoming request.
 *
 * Returns:
 * dict: A dictionary containing the route of the request URL.
 */
export const testEndpointTestGet = <ThrowOnError extends boolean = false>(
  options?: Options<TestEndpointTestGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    TestEndpointTestGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/test',
    ...options,
  });

/**
 * Health Services Endpoint
 *
 * Use this admin-only endpoint to check if the service is healthy.
 *
 * Example:
 * ```
 * curl -L -X GET 'http://0.0.0.0:4000/health/services?service=datadog'     -H 'Authorization: Bearer sk-1234'
 * ```
 */
export const healthServicesEndpointHealthServicesGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<HealthServicesEndpointHealthServicesGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    HealthServicesEndpointHealthServicesGetResponses,
    HealthServicesEndpointHealthServicesGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/health/services',
    ...options,
  });

/**
 * Health Endpoint
 *
 *  USE `/health/liveliness` to health check the proxy 
 *
 * See more  https://docs.litellm.ai/docs/proxy/health
 *
 *
 * Check the health of all the endpoints in config.yaml
 *
 * To run health checks in the background, add this to config.yaml:
 * ```
 * general_settings:
 * # ... other settings
 * background_health_checks: True
 * ```
 * else, the health checks will be run on models when /health is called.
 */
export const healthEndpointHealthGet = <ThrowOnError extends boolean = false>(
  options?: Options<HealthEndpointHealthGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    HealthEndpointHealthGetResponses,
    HealthEndpointHealthGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/health',
    ...options,
  });

/**
 * Health Check History Endpoint
 *
 * Get health check history for models
 *
 * Returns historical health check data with optional filtering.
 */
export const healthCheckHistoryEndpointHealthHistoryGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    HealthCheckHistoryEndpointHealthHistoryGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    HealthCheckHistoryEndpointHealthHistoryGetResponses,
    HealthCheckHistoryEndpointHealthHistoryGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/health/history',
    ...options,
  });

/**
 * Latest Health Checks Endpoint
 *
 * Get the latest health check status for all models
 *
 * Returns the most recent health check result for each model.
 */
export const latestHealthChecksEndpointHealthLatestGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    LatestHealthChecksEndpointHealthLatestGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    LatestHealthChecksEndpointHealthLatestGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/health/latest',
    ...options,
  });

/**
 * Shared Health Check Status Endpoint
 *
 * Get the status of shared health check coordination across pods.
 *
 * Returns information about Redis connectivity, lock status, and cache status.
 */
export const sharedHealthCheckStatusEndpointHealthSharedStatusGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    SharedHealthCheckStatusEndpointHealthSharedStatusGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    SharedHealthCheckStatusEndpointHealthSharedStatusGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/health/shared-status',
    ...options,
  });

/**
 * Active Callbacks
 *
 * Returns a list of litellm level settings
 *
 * This is useful for debugging and ensuring the proxy server is configured correctly.
 *
 * Response schema:
 * ```
 * {
 * "alerting": _alerting,
 * "litellm.callbacks": litellm_callbacks,
 * "litellm.input_callback": litellm_input_callbacks,
 * "litellm.failure_callback": litellm_failure_callbacks,
 * "litellm.success_callback": litellm_success_callbacks,
 * "litellm._async_success_callback": litellm_async_success_callbacks,
 * "litellm._async_failure_callback": litellm_async_failure_callbacks,
 * "litellm._async_input_callback": litellm_async_input_callbacks,
 * "all_litellm_callbacks": all_litellm_callbacks,
 * "num_callbacks": len(all_litellm_callbacks),
 * "num_alerting": _num_alerting,
 * "litellm.request_timeout": litellm.request_timeout,
 * }
 * ```
 */
export const activeCallbacksActiveCallbacksGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ActiveCallbacksActiveCallbacksGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ActiveCallbacksActiveCallbacksGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/active/callbacks',
    ...options,
  });

/**
 * Active Callbacks
 *
 * Returns a list of litellm level settings
 *
 * This is useful for debugging and ensuring the proxy server is configured correctly.
 *
 * Response schema:
 * ```
 * {
 * "alerting": _alerting,
 * "litellm.callbacks": litellm_callbacks,
 * "litellm.input_callback": litellm_input_callbacks,
 * "litellm.failure_callback": litellm_failure_callbacks,
 * "litellm.success_callback": litellm_success_callbacks,
 * "litellm._async_success_callback": litellm_async_success_callbacks,
 * "litellm._async_failure_callback": litellm_async_failure_callbacks,
 * "litellm._async_input_callback": litellm_async_input_callbacks,
 * "all_litellm_callbacks": all_litellm_callbacks,
 * "num_callbacks": len(all_litellm_callbacks),
 * "num_alerting": _num_alerting,
 * "litellm.request_timeout": litellm.request_timeout,
 * }
 * ```
 */
export const activeCallbacksSettingsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ActiveCallbacksSettingsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ActiveCallbacksSettingsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/settings',
    ...options,
  });

/**
 * Health Readiness
 *
 * Unprotected endpoint for checking if worker can receive requests
 */
export const healthReadinessHealthReadinessGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<HealthReadinessHealthReadinessGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    HealthReadinessHealthReadinessGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/health/readiness',
    ...options,
  });

/**
 * Health Readiness Options
 *
 * Options endpoint for health/readiness check.
 */
export const healthReadinessOptionsHealthReadinessOptions = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    HealthReadinessOptionsHealthReadinessOptionsData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).options<
    HealthReadinessOptionsHealthReadinessOptionsResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/health/readiness',
    ...options,
  });

/**
 * Health Liveliness
 *
 * Unprotected endpoint for checking if worker is alive
 */
export const healthLivelinessHealthLivenessGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<HealthLivelinessHealthLivenessGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    HealthLivelinessHealthLivenessGetResponses,
    unknown,
    ThrowOnError
  >({ url: '/health/liveness', ...options });

/**
 * Health Liveliness Options
 *
 * Options endpoint for health/liveliness check.
 */
export const healthLivelinessOptionsHealthLivenessOptions = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    HealthLivelinessOptionsHealthLivenessOptionsData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).options<
    HealthLivelinessOptionsHealthLivenessOptionsResponses,
    unknown,
    ThrowOnError
  >({ url: '/health/liveness', ...options });

/**
 * Health Liveliness
 *
 * Unprotected endpoint for checking if worker is alive
 */
export const healthLivelinessHealthLivelinessGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<HealthLivelinessHealthLivelinessGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    HealthLivelinessHealthLivelinessGetResponses,
    unknown,
    ThrowOnError
  >({ url: '/health/liveliness', ...options });

/**
 * Health Liveliness Options
 *
 * Options endpoint for health/liveliness check.
 */
export const healthLivelinessOptionsHealthLivelinessOptions = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    HealthLivelinessOptionsHealthLivelinessOptionsData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).options<
    HealthLivelinessOptionsHealthLivelinessOptionsResponses,
    unknown,
    ThrowOnError
  >({ url: '/health/liveliness', ...options });

/**
 * Test Model Connection
 *
 * Test a direct connection to a specific model.
 *
 * This endpoint allows you to verify if your proxy can successfully connect to a specific model.
 * It's useful for troubleshooting model connectivity issues without going through the full proxy routing.
 *
 * Example:
 * ```bash
 * curl -X POST 'http://localhost:4000/health/test_connection' \
 * -H 'Authorization: Bearer sk-1234' \
 * -H 'Content-Type: application/json' \
 * -d '{
 * "litellm_params": {
 * "model": "gpt-4",
 * "custom_llm_provider": "azure_ai",
 * "litellm_credential_name": null,
 * "api_key": "6xxxxxxx",
 * "api_base": "https://litellm8397336933.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-10-21",
 * },
 * "mode": "chat"
 * }'
 * ```
 *
 * Returns:
 * dict: A dictionary containing the health check result with either success information or error details.
 */
export const testModelConnectionHealthTestConnectionPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    TestModelConnectionHealthTestConnectionPostData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).post<
    TestModelConnectionHealthTestConnectionPostResponses,
    TestModelConnectionHealthTestConnectionPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/health/test_connection',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options?.headers,
    },
  });

/**
 * Generate Key Fn
 *
 * Generate an API key based on the provided data.
 *
 * Docs: https://docs.litellm.ai/docs/proxy/virtual_keys
 *
 * Parameters:
 * - duration: Optional[str] - Specify the length of time the token is valid for. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - key_alias: Optional[str] - User defined key alias
 * - key: Optional[str] - User defined key value. If not set, a 16-digit unique sk-key is created for you.
 * - team_id: Optional[str] - The team id of the key
 * - user_id: Optional[str] - The user id of the key
 * - organization_id: Optional[str] - The organization id of the key. If not set, and team_id is set, the organization id will be the same as the team id. If conflict, an error will be raised.
 * - budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.
 * - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)
 * - aliases: Optional[dict] - Any alias mappings, on top of anything in the config.yaml model list. - https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---upgradedowngrade-models
 * - config: Optional[dict] - any key-specific configs, overrides config in config.yaml
 * - spend: Optional[int] - Amount spent by key. Default is 0. Will be updated by proxy whenever key is used. https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---tracking-spend
 * - send_invite_email: Optional[bool] - Whether to send an invite email to the user_id, with the generate key
 * - max_budget: Optional[float] - Specify max budget for a given key.
 * - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.
 * - metadata: Optional[dict] - Metadata for key, store information for key. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 * - guardrails: Optional[List[str]] - List of active guardrails for the key
 * - disable_global_guardrails: Optional[bool] - Whether to disable global guardrails for the key.
 * - permissions: Optional[dict] - key-specific permissions. Currently just used for turning off pii masking (if connected). Example - {"pii": false}
 * - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}}. IF null or {} then no model specific budget.
 * - model_rpm_limit: Optional[dict] - key-specific model rpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific rpm limit.
 * - model_tpm_limit: Optional[dict] - key-specific model tpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific tpm limit.
 * - tpm_limit_type: Optional[str] - Type of tpm limit. Options: "best_effort_throughput" (no error if we're overallocating tpm), "guaranteed_throughput" (raise an error if we're overallocating tpm), "dynamic" (dynamically exceed limit when no 429 errors). Defaults to "best_effort_throughput".
 * - rpm_limit_type: Optional[str] - Type of rpm limit. Options: "best_effort_throughput" (no error if we're overallocating rpm), "guaranteed_throughput" (raise an error if we're overallocating rpm), "dynamic" (dynamically exceed limit when no 429 errors). Defaults to "best_effort_throughput".
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request
 * - blocked: Optional[bool] - Whether the key is blocked.
 * - rpm_limit: Optional[int] - Specify rpm limit for a given key (Requests per minute)
 * - tpm_limit: Optional[int] - Specify tpm limit for a given key (Tokens per minute)
 * - soft_budget: Optional[float] - Specify soft budget for a given key. Will trigger a slack alert when this soft budget is reached.
 * - tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - prompts: Optional[List[str]] - List of prompts that the key is allowed to use.
 * - enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)
 * - prompts: Optional[List[str]] - List of prompts that the key is allowed to use.
 * - allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys*"]
 * - allowed_passthrough_routes: Optional[list] - List of allowed pass through endpoints for the key. Store the actual endpoint or store a wildcard pattern for a set of endpoints. Example - ["/my-custom-endpoint"]. Use this instead of allowed_routes, if you just want to specify which pass through endpoints the key can access, without specifying the routes. If allowed_routes is specified, allowed_pass_through_endpoints is ignored.
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.
 * - key_type: Optional[str] - Type of key that determines default allowed routes. Options: "llm_api" (can call LLM API routes), "management" (can call management routes), "read_only" (can only call info/read routes), "default" (uses default allowed routes). Defaults to "default".
 * - prompts: Optional[List[str]] - List of allowed prompts for the key. If specified, the key will only be able to use these specific prompts.
 * - auto_rotate: Optional[bool] - Whether this key should be automatically rotated (regenerated)
 * - rotation_interval: Optional[str] - How often to auto-rotate this key (e.g., '30s', '30m', '30h', '30d'). Required if auto_rotate=True.
 * - allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.
 *
 *
 * Examples:
 *
 * 1. Allow users to turn on/off pii masking
 *
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/generate'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{
 * "permissions": {"allow_pii_controls": true}
 * }'
 * ```
 *
 * Returns:
 * - key: (str) The generated api key
 * - expires: (datetime) Datetime object for when key expires.
 * - user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.
 */
export const generateKeyFnKeyGeneratePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GenerateKeyFnKeyGeneratePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    GenerateKeyFnKeyGeneratePostResponses,
    GenerateKeyFnKeyGeneratePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/key/generate',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Generate Service Account Key Fn
 *
 * Generate a Service Account API key based on the provided data. This key does not belong to any user. It belongs to the team.
 *
 * Why use a service account key?
 * - Prevent key from being deleted when user is deleted.
 * - Apply team limits, not team member limits to key.
 *
 * Docs: https://docs.litellm.ai/docs/proxy/virtual_keys
 *
 * Parameters:
 * - duration: Optional[str] - Specify the length of time the token is valid for. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - key_alias: Optional[str] - User defined key alias
 * - key: Optional[str] - User defined key value. If not set, a 16-digit unique sk-key is created for you.
 * - team_id: Optional[str] - The team id of the key
 * - user_id: Optional[str] - [NON-FUNCTIONAL] THIS WILL BE IGNORED. The user id of the key
 * - budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.
 * - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)
 * - aliases: Optional[dict] - Any alias mappings, on top of anything in the config.yaml model list. - https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---upgradedowngrade-models
 * - config: Optional[dict] - any key-specific configs, overrides config in config.yaml
 * - spend: Optional[int] - Amount spent by key. Default is 0. Will be updated by proxy whenever key is used. https://docs.litellm.ai/docs/proxy/virtual_keys#managing-auth---tracking-spend
 * - send_invite_email: Optional[bool] - Whether to send an invite email to the user_id, with the generate key
 * - max_budget: Optional[float] - Specify max budget for a given key.
 * - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.
 * - metadata: Optional[dict] - Metadata for key, store information for key. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 * - guardrails: Optional[List[str]] - List of active guardrails for the key
 * - permissions: Optional[dict] - key-specific permissions. Currently just used for turning off pii masking (if connected). Example - {"pii": false}
 * - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}}. IF null or {} then no model specific budget.
 * - model_rpm_limit: Optional[dict] - key-specific model rpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific rpm limit.
 * - model_tpm_limit: Optional[dict] - key-specific model tpm limit. Example - {"text-davinci-002": 1000, "gpt-3.5-turbo": 1000}. IF null or {} then no model specific tpm limit.
 * - tpm_limit_type: Optional[str] - TPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"
 * - rpm_limit_type: Optional[str] - RPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request
 * - blocked: Optional[bool] - Whether the key is blocked.
 * - rpm_limit: Optional[int] - Specify rpm limit for a given key (Requests per minute)
 * - tpm_limit: Optional[int] - Specify tpm limit for a given key (Tokens per minute)
 * - soft_budget: Optional[float] - Specify soft budget for a given key. Will trigger a slack alert when this soft budget is reached.
 * - tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)
 * - allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys*"]
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.
 * Examples:
 * - allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.
 *
 *
 * 1. Allow users to turn on/off pii masking
 *
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/generate'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{
 * "permissions": {"allow_pii_controls": true}
 * }'
 * ```
 *
 * Returns:
 * - key: (str) The generated api key
 * - expires: (datetime) Datetime object for when key expires.
 * - user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.
 */
export const generateServiceAccountKeyFnKeyServiceAccountGeneratePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostResponses,
    GenerateServiceAccountKeyFnKeyServiceAccountGeneratePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/key/service-account/generate',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Key Fn
 *
 * Update an existing API key's parameters.
 *
 * Parameters:
 * - key: str - The key to update
 * - key_alias: Optional[str] - User-friendly key alias
 * - user_id: Optional[str] - User ID associated with key
 * - team_id: Optional[str] - Team ID associated with key
 * - budget_id: Optional[str] - The budget id associated with the key. Created by calling `/budget/new`.
 * - models: Optional[list] - Model_name's a user is allowed to call
 * - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)
 * - prompts: Optional[List[str]] - List of prompts that the key is allowed to use.
 * - enforced_params: Optional[List[str]] - List of enforced params for the key (Enterprise only). [Docs](https://docs.litellm.ai/docs/proxy/enterprise#enforce-required-params-for-llm-requests)
 * - spend: Optional[float] - Amount spent by key
 * - max_budget: Optional[float] - Max budget for key
 * - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}
 * - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 * - soft_budget: Optional[float] - [TODO] Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.
 * - max_parallel_requests: Optional[int] - Rate limit for parallel requests
 * - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}
 * - tpm_limit: Optional[int] - Tokens per minute limit
 * - rpm_limit: Optional[int] - Requests per minute limit
 * - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}
 * - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}
 * - tpm_limit_type: Optional[str] - TPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"
 * - rpm_limit_type: Optional[str] - RPM rate limit type - "best_effort_throughput", "guaranteed_throughput", or "dynamic"
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values
 * - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)
 * - permissions: Optional[dict] - Key-specific permissions
 * - send_invite_email: Optional[bool] - Send invite email to user_id
 * - guardrails: Optional[List[str]] - List of active guardrails for the key
 * - disable_global_guardrails: Optional[bool] - Whether to disable global guardrails for the key.
 * - prompts: Optional[List[str]] - List of prompts that the key is allowed to use.
 * - blocked: Optional[bool] - Whether the key is blocked
 * - aliases: Optional[dict] - Model aliases for the key - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)
 * - config: Optional[dict] - [DEPRECATED PARAM] Key-specific config.
 * - temp_budget_increase: Optional[float] - Temporary budget increase for the key (Enterprise only).
 * - temp_budget_expiry: Optional[str] - Expiry time for the temporary budget increase (Enterprise only).
 * - allowed_routes: Optional[list] - List of allowed routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/chat/completions", "/embeddings", "/keys*"]
 * - allowed_passthrough_routes: Optional[list] - List of allowed pass through routes for the key. Store the actual route or store a wildcard pattern for a set of routes. Example - ["/my-custom-endpoint"]. Use this instead of allowed_routes, if you just want to specify which pass through routes the key can access, without specifying the routes. If allowed_routes is specified, allowed_passthrough_routes is ignored.
 * - prompts: Optional[List[str]] - List of allowed prompts for the key. If specified, the key will only be able to use these specific prompts.
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - key-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.
 * - auto_rotate: Optional[bool] - Whether this key should be automatically rotated
 * - rotation_interval: Optional[str] - How often to rotate this key (e.g., '30d', '90d'). Required if auto_rotate=True
 * - allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.
 *
 * Example:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "key": "sk-1234",
 * "key_alias": "my-key",
 * "user_id": "user-1234",
 * "team_id": "team-1234",
 * "max_budget": 100,
 * "metadata": {"any_key": "any-val"},
 * }'
 * ```
 */
export const updateKeyFnKeyUpdatePost = <ThrowOnError extends boolean = false>(
  options: Options<UpdateKeyFnKeyUpdatePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UpdateKeyFnKeyUpdatePostResponses,
    UpdateKeyFnKeyUpdatePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/key/update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Delete Key Fn
 *
 * Delete a key from the key management system.
 *
 * Parameters::
 * - keys (List[str]): A list of keys or hashed keys to delete. Example {"keys": ["sk-QWrxEynunsNpV1zT48HIrw", "837e17519f44683334df5291321d97b8bf1098cd490e49e215f6fea935aa28be"]}
 * - key_aliases (List[str]): A list of key aliases to delete. Can be passed instead of `keys`.Example {"key_aliases": ["alias1", "alias2"]}
 *
 * Returns:
 * - deleted_keys (List[str]): A list of deleted keys. Example {"deleted_keys": ["sk-QWrxEynunsNpV1zT48HIrw", "837e17519f44683334df5291321d97b8bf1098cd490e49e215f6fea935aa28be"]}
 *
 * Example:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "keys": ["sk-QWrxEynunsNpV1zT48HIrw"]
 * }'
 * ```
 *
 * Raises:
 * HTTPException: If an error occurs during key deletion.
 */
export const deleteKeyFnKeyDeletePost = <ThrowOnError extends boolean = false>(
  options: Options<DeleteKeyFnKeyDeletePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    DeleteKeyFnKeyDeletePostResponses,
    DeleteKeyFnKeyDeletePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/key/delete',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Info Key Fn
 *
 * Retrieve information about a key.
 * Parameters:
 * key: Optional[str] = Query parameter representing the key in the request
 * user_api_key_dict: UserAPIKeyAuth = Dependency representing the user's API key
 * Returns:
 * Dict containing the key and its associated information
 *
 * Example Curl:
 * ```
 * curl -X GET "http://0.0.0.0:4000/key/info?key=sk-02Wr4IAlN3NvPXvL5JVvDA" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Curl - if no key is passed, it will use the Key Passed in Authorization Header
 * ```
 * curl -X GET "http://0.0.0.0:4000/key/info" -H "Authorization: Bearer sk-02Wr4IAlN3NvPXvL5JVvDA"
 * ```
 */
export const infoKeyFnKeyInfoGet = <ThrowOnError extends boolean = false>(
  options?: Options<InfoKeyFnKeyInfoGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    InfoKeyFnKeyInfoGetResponses,
    InfoKeyFnKeyInfoGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/key/info',
    ...options,
  });

/**
 * Regenerate Key Fn
 *
 * Regenerate an existing API key while optionally updating its parameters.
 *
 * Parameters:
 * - key: str (path parameter) - The key to regenerate
 * - data: Optional[RegenerateKeyRequest] - Request body containing optional parameters to update
 * - key: Optional[str] - The key to regenerate.
 * - new_master_key: Optional[str] - The new master key to use, if key is the master key.
 * - new_key: Optional[str] - The new key to use, if key is not the master key. If both set, new_master_key will be used.
 * - key_alias: Optional[str] - User-friendly key alias
 * - user_id: Optional[str] - User ID associated with key
 * - team_id: Optional[str] - Team ID associated with key
 * - models: Optional[list] - Model_name's a user is allowed to call
 * - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)
 * - spend: Optional[float] - Amount spent by key
 * - max_budget: Optional[float] - Max budget for key
 * - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}
 * - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 * - soft_budget: Optional[float] - Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.
 * - max_parallel_requests: Optional[int] - Rate limit for parallel requests
 * - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}
 * - tpm_limit: Optional[int] - Tokens per minute limit
 * - rpm_limit: Optional[int] - Requests per minute limit
 * - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}
 * - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values
 * - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)
 * - permissions: Optional[dict] - Key-specific permissions
 * - guardrails: Optional[List[str]] - List of active guardrails for the key
 * - blocked: Optional[bool] - Whether the key is blocked
 *
 *
 * Returns:
 * - GenerateKeyResponse containing the new key and its updated parameters
 *
 * Example:
 * ```bash
 * curl --location --request POST 'http://localhost:4000/key/sk-1234/regenerate'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 * "max_budget": 100,
 * "metadata": {"team": "core-infra"},
 * "models": ["gpt-4", "gpt-3.5-turbo"]
 * }'
 * ```
 *
 * Note: This is an Enterprise feature. It requires a premium license to use.
 */
export const regenerateKeyFnKeyRegeneratePost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<RegenerateKeyFnKeyRegeneratePostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    RegenerateKeyFnKeyRegeneratePostResponses,
    RegenerateKeyFnKeyRegeneratePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/key/regenerate',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options?.headers,
    },
  });

/**
 * Regenerate Key Fn
 *
 * Regenerate an existing API key while optionally updating its parameters.
 *
 * Parameters:
 * - key: str (path parameter) - The key to regenerate
 * - data: Optional[RegenerateKeyRequest] - Request body containing optional parameters to update
 * - key: Optional[str] - The key to regenerate.
 * - new_master_key: Optional[str] - The new master key to use, if key is the master key.
 * - new_key: Optional[str] - The new key to use, if key is not the master key. If both set, new_master_key will be used.
 * - key_alias: Optional[str] - User-friendly key alias
 * - user_id: Optional[str] - User ID associated with key
 * - team_id: Optional[str] - Team ID associated with key
 * - models: Optional[list] - Model_name's a user is allowed to call
 * - tags: Optional[List[str]] - Tags for organizing keys (Enterprise only)
 * - spend: Optional[float] - Amount spent by key
 * - max_budget: Optional[float] - Max budget for key
 * - model_max_budget: Optional[Dict[str, BudgetConfig]] - Model-specific budgets {"gpt-4": {"budget_limit": 0.0005, "time_period": "30d"}}
 * - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 * - soft_budget: Optional[float] - Soft budget limit (warning vs. hard stop). Will trigger a slack alert when this soft budget is reached.
 * - max_parallel_requests: Optional[int] - Rate limit for parallel requests
 * - metadata: Optional[dict] - Metadata for key. Example {"team": "core-infra", "app": "app2"}
 * - tpm_limit: Optional[int] - Tokens per minute limit
 * - rpm_limit: Optional[int] - Requests per minute limit
 * - model_rpm_limit: Optional[dict] - Model-specific RPM limits {"gpt-4": 100, "claude-v1": 200}
 * - model_tpm_limit: Optional[dict] - Model-specific TPM limits {"gpt-4": 100000, "claude-v1": 200000}
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values
 * - duration: Optional[str] - Key validity duration ("30d", "1h", etc.)
 * - permissions: Optional[dict] - Key-specific permissions
 * - guardrails: Optional[List[str]] - List of active guardrails for the key
 * - blocked: Optional[bool] - Whether the key is blocked
 *
 *
 * Returns:
 * - GenerateKeyResponse containing the new key and its updated parameters
 *
 * Example:
 * ```bash
 * curl --location --request POST 'http://localhost:4000/key/sk-1234/regenerate'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 * "max_budget": 100,
 * "metadata": {"team": "core-infra"},
 * "models": ["gpt-4", "gpt-3.5-turbo"]
 * }'
 * ```
 *
 * Note: This is an Enterprise feature. It requires a premium license to use.
 */
export const regenerateKeyFnKeyKeyRegeneratePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<RegenerateKeyFnKeyKeyRegeneratePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    RegenerateKeyFnKeyKeyRegeneratePostResponses,
    RegenerateKeyFnKeyKeyRegeneratePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/key/{key}/regenerate',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * List Keys
 *
 * List all keys for a given user / team / organization.
 *
 * Returns:
 * {
 * "keys": List[str] or List[UserAPIKeyAuth],
 * "total_count": int,
 * "current_page": int,
 * "total_pages": int,
 * }
 */
export const listKeysKeyListGet = <ThrowOnError extends boolean = false>(
  options?: Options<ListKeysKeyListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListKeysKeyListGetResponses,
    ListKeysKeyListGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/key/list',
    ...options,
  });

/**
 * Key Aliases
 *
 * Lists all key aliases
 *
 * Returns:
 * {
 * "aliases": List[str]
 * }
 */
export const keyAliasesKeyAliasesGet = <ThrowOnError extends boolean = false>(
  options?: Options<KeyAliasesKeyAliasesGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    KeyAliasesKeyAliasesGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/key/aliases',
    ...options,
  });

/**
 * Block Key
 *
 * Block an Virtual key from making any requests.
 *
 * Parameters:
 * - key: str - The key to block. Can be either the unhashed key (sk-...) or the hashed key value
 *
 * Example:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/block'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "key": "sk-Fn8Ej39NxjAXrvpUGKghGw"
 * }'
 * ```
 *
 * Note: This is an admin-only endpoint. Only proxy admins can block keys.
 */
export const blockKeyKeyBlockPost = <ThrowOnError extends boolean = false>(
  options: Options<BlockKeyKeyBlockPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    BlockKeyKeyBlockPostResponses,
    BlockKeyKeyBlockPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/key/block',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Unblock Key
 *
 * Unblock a Virtual key to allow it to make requests again.
 *
 * Parameters:
 * - key: str - The key to unblock. Can be either the unhashed key (sk-...) or the hashed key value
 *
 * Example:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/key/unblock'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "key": "sk-Fn8Ej39NxjAXrvpUGKghGw"
 * }'
 * ```
 *
 * Note: This is an admin-only endpoint. Only proxy admins can unblock keys.
 */
export const unblockKeyKeyUnblockPost = <ThrowOnError extends boolean = false>(
  options: Options<UnblockKeyKeyUnblockPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UnblockKeyKeyUnblockPostResponses,
    UnblockKeyKeyUnblockPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/key/unblock',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Key Health
 *
 * Check the health of the key
 *
 * Checks:
 * - If key based logging is configured correctly - sends a test log
 *
 * Usage
 *
 * Pass the key in the request header
 *
 * ```bash
 * curl -X POST "http://localhost:4000/key/health"      -H "Authorization: Bearer sk-1234"      -H "Content-Type: application/json"
 * ```
 *
 * Response when logging callbacks are setup correctly:
 *
 * ```json
 * {
 * "key": "healthy",
 * "logging_callbacks": {
 * "callbacks": [
 * "gcs_bucket"
 * ],
 * "status": "healthy",
 * "details": "No logger exceptions triggered, system is healthy. Manually check if logs were sent to ['gcs_bucket']"
 * }
 * }
 * ```
 *
 *
 * Response when logging callbacks are not setup correctly:
 * ```json
 * {
 * "key": "unhealthy",
 * "logging_callbacks": {
 * "callbacks": [
 * "gcs_bucket"
 * ],
 * "status": "unhealthy",
 * "details": "Logger exceptions triggered, system is unhealthy: Failed to load vertex credentials. Check to see if credentials containing partial/invalid information."
 * }
 * }
 * ```
 */
export const keyHealthKeyHealthPost = <ThrowOnError extends boolean = false>(
  options?: Options<KeyHealthKeyHealthPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    KeyHealthKeyHealthPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/key/health',
    ...options,
  });

/**
 * New User
 *
 * Use this to create a new INTERNAL user with a budget.
 * Internal Users can access LiteLLM Admin UI to make keys, request access to models.
 * This creates a new user and generates a new api key for the new user. The new api key is returned.
 *
 * Returns user id, budget + new key.
 *
 * Parameters:
 * - user_id: Optional[str] - Specify a user id. If not set, a unique id will be generated.
 * - user_alias: Optional[str] - A descriptive name for you to know who this user id refers to.
 * - teams: Optional[list] - specify a list of team id's a user belongs to.
 * - user_email: Optional[str] - Specify a user email.
 * - send_invite_email: Optional[bool] - Specify if an invite email should be sent.
 * - user_role: Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`
 * - max_budget: Optional[float] - Specify max budget for a given user.
 * - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").
 * - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models). Set to ['no-default-models'] to block all model access. Restricting user to only team-based model access.
 * - tpm_limit: Optional[int] - Specify tpm limit for a given user (Tokens per minute)
 * - rpm_limit: Optional[int] - Specify rpm limit for a given user (Requests per minute)
 * - auto_create_key: bool - Default=True. Flag used for returning a key as part of the /user/new response
 * - aliases: Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)
 * - config: Optional[dict] - [DEPRECATED PARAM] User-specific config.
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-
 * - blocked: Optional[bool] - [Not Implemented Yet] Whether the user is blocked.
 * - guardrails: Optional[List[str]] - [Not Implemented Yet] List of active guardrails for the user
 * - permissions: Optional[dict] - [Not Implemented Yet] User-specific permissions, eg. turning off pii masking.
 * - metadata: Optional[dict] - Metadata for user, store information for user. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 * - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.
 * - soft_budget: Optional[float] - Get alerts when user crosses given budget, doesn't block requests.
 * - model_max_budget: Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)
 * - model_rpm_limit: Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)
 * - model_tpm_limit: Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)
 * - spend: Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").
 * - team_id: Optional[str] - [DEPRECATED PARAM] The team id of the user. Default is None.
 * - duration: Optional[str] - Duration for the key auto-created on `/user/new`. Default is None.
 * - key_alias: Optional[str] - Alias for the key auto-created on `/user/new`. Default is None.
 * - sso_user_id: Optional[str] - The id of the user in the SSO provider.
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - internal user-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.
 * - prompts: Optional[List[str]] - List of allowed prompts for the user. If specified, the user will only be able to use these specific prompts.
 * - organizations: List[str] - List of organization id's the user is a member of
 * Returns:
 * - key: (str) The generated api key for the user
 * - expires: (datetime) Datetime object for when key expires.
 * - user_id: (str) Unique user id - used for tracking spend across multiple keys for same user id.
 * - max_budget: (float|None) Max budget for given user.
 *
 * Usage Example
 *
 * ```shell
 * curl -X POST "http://localhost:4000/user/new"      -H "Content-Type: application/json"      -H "Authorization: Bearer sk-1234"      -d '{
 * "username": "new_user",
 * "email": "new_user@example.com"
 * }'
 * ```
 */
export const newUserUserNewPost = <ThrowOnError extends boolean = false>(
  options: Options<NewUserUserNewPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    NewUserUserNewPostResponses,
    NewUserUserNewPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/user/new',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * User Info
 *
 * [10/07/2024]
 * Note: To get all users (+pagination), use `/user/list` endpoint.
 *
 *
 * Use this to get user information. (user row + all user key info)
 *
 * Example request
 * ```
 * curl -X GET 'http://localhost:4000/user/info?user_id=krrish7%40berri.ai'     --header 'Authorization: Bearer sk-1234'
 * ```
 */
export const userInfoUserInfoGet = <ThrowOnError extends boolean = false>(
  options?: Options<UserInfoUserInfoGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    UserInfoUserInfoGetResponses,
    UserInfoUserInfoGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/user/info',
    ...options,
  });

/**
 * User Update
 *
 * Example curl
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/user/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "user_id": "test-litellm-user-4",
 * "user_role": "proxy_admin_viewer"
 * }'
 * ```
 *
 * Parameters:
 * - user_id: Optional[str] - Specify a user id. If not set, a unique id will be generated.
 * - user_email: Optional[str] - Specify a user email.
 * - password: Optional[str] - Specify a user password.
 * - user_alias: Optional[str] - A descriptive name for you to know who this user id refers to.
 * - teams: Optional[list] - specify a list of team id's a user belongs to.
 * - send_invite_email: Optional[bool] - Specify if an invite email should be sent.
 * - user_role: Optional[str] - Specify a user role - "proxy_admin", "proxy_admin_viewer", "internal_user", "internal_user_viewer", "team", "customer". Info about each role here: `https://github.com/BerriAI/litellm/litellm/proxy/_types.py#L20`
 * - max_budget: Optional[float] - Specify max budget for a given user.
 * - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").
 * - models: Optional[list] - Model_name's a user is allowed to call. (if empty, key is allowed to call all models)
 * - tpm_limit: Optional[int] - Specify tpm limit for a given user (Tokens per minute)
 * - rpm_limit: Optional[int] - Specify rpm limit for a given user (Requests per minute)
 * - auto_create_key: bool - Default=True. Flag used for returning a key as part of the /user/new response
 * - aliases: Optional[dict] - Model aliases for the user - [Docs](https://litellm.vercel.app/docs/proxy/virtual_keys#model-aliases)
 * - config: Optional[dict] - [DEPRECATED PARAM] User-specific config.
 * - allowed_cache_controls: Optional[list] - List of allowed cache control values. Example - ["no-cache", "no-store"]. See all values - https://docs.litellm.ai/docs/proxy/caching#turn-on--off-caching-per-request-
 * - blocked: Optional[bool] - [Not Implemented Yet] Whether the user is blocked.
 * - guardrails: Optional[List[str]] - [Not Implemented Yet] List of active guardrails for the user
 * - permissions: Optional[dict] - [Not Implemented Yet] User-specific permissions, eg. turning off pii masking.
 * - metadata: Optional[dict] - Metadata for user, store information for user. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 * - max_parallel_requests: Optional[int] - Rate limit a user based on the number of parallel requests. Raises 429 error, if user's parallel requests > x.
 * - soft_budget: Optional[float] - Get alerts when user crosses given budget, doesn't block requests.
 * - model_max_budget: Optional[dict] - Model-specific max budget for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-budgets-to-keys)
 * - model_rpm_limit: Optional[float] - Model-specific rpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)
 * - model_tpm_limit: Optional[float] - Model-specific tpm limit for user. [Docs](https://docs.litellm.ai/docs/proxy/users#add-model-specific-limits-to-keys)
 * - spend: Optional[float] - Amount spent by user. Default is 0. Will be updated by proxy whenever user is used. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d"), months ("1mo").
 * - team_id: Optional[str] - [DEPRECATED PARAM] The team id of the user. Default is None.
 * - duration: Optional[str] - [NOT IMPLEMENTED].
 * - key_alias: Optional[str] - [NOT IMPLEMENTED].
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - internal user-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.
 * - prompts: Optional[List[str]] - List of allowed prompts for the user. If specified, the user will only be able to use these specific prompts.
 */
export const userUpdateUserUpdatePost = <ThrowOnError extends boolean = false>(
  options: Options<UserUpdateUserUpdatePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UserUpdateUserUpdatePostResponses,
    UserUpdateUserUpdatePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/user/update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Bulk User Update
 *
 * Bulk update multiple users at once.
 *
 * This endpoint allows updating multiple users in a single request. Each user update
 * is processed independently - if some updates fail, others will still succeed.
 *
 * Parameters:
 * - users: Optional[List[UpdateUserRequest]] - List of specific user update requests
 * - all_users: Optional[bool] - Set to true to update all users in the system
 * - user_updates: Optional[UpdateUserRequest] - Updates to apply when all_users=True
 *
 * Returns:
 * - results: List of individual update results
 * - total_requested: Total number of users requested for update
 * - successful_updates: Number of successful updates
 * - failed_updates: Number of failed updates
 *
 * Example request for specific users:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/user/bulk_update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "users": [
 * {
 * "user_id": "user1",
 * "user_role": "internal_user",
 * "max_budget": 100.0
 * },
 * {
 * "user_email": "user2@example.com",
 * "user_role": "internal_user_viewer",
 * "max_budget": 50.0
 * }
 * ]
 * }'
 * ```
 *
 * Example request for all users:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/user/bulk_update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "all_users": true,
 * "user_updates": {
 * "user_role": "internal_user",
 * "max_budget": 50.0
 * }
 * }'
 * ```
 */
export const bulkUserUpdateUserBulkUpdatePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<BulkUserUpdateUserBulkUpdatePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    BulkUserUpdateUserBulkUpdatePostResponses,
    BulkUserUpdateUserBulkUpdatePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/user/bulk_update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Users
 *
 * Get a paginated list of users with filtering and sorting options.
 *
 * Parameters:
 * role: Optional[str]
 * Filter users by role. Can be one of:
 * - proxy_admin
 * - proxy_admin_viewer
 * - internal_user
 * - internal_user_viewer
 * user_ids: Optional[str]
 * Get list of users by user_ids. Comma separated list of user_ids.
 * sso_ids: Optional[str]
 * Get list of users by sso_ids. Comma separated list of sso_ids.
 * user_email: Optional[str]
 * Filter users by partial email match
 * team: Optional[str]
 * Filter users by team id. Will match if user has this team in their teams array.
 * page: int
 * The page number to return
 * page_size: int
 * The number of items per page
 * sort_by: Optional[str]
 * Column to sort by (e.g. 'user_id', 'user_email', 'created_at', 'spend')
 * sort_order: Optional[str]
 * Sort order ('asc' or 'desc')
 */
export const getUsersUserListGet = <ThrowOnError extends boolean = false>(
  options?: Options<GetUsersUserListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetUsersUserListGetResponses,
    GetUsersUserListGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/user/list',
    ...options,
  });

/**
 * Delete User
 *
 * delete user and associated user keys
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/user/delete'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data-raw '{
 * "user_ids": ["45e3e396-ee08-4a61-a88e-16b3ce7e0849"]
 * }'
 * ```
 *
 * Parameters:
 * - user_ids: List[str] - The list of user id's to be deleted.
 */
export const deleteUserUserDeletePost = <ThrowOnError extends boolean = false>(
  options: Options<DeleteUserUserDeletePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    DeleteUserUserDeletePostResponses,
    DeleteUserUserDeletePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/user/delete',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get User Daily Activity
 *
 * [BETA] This is a beta endpoint. It will change.
 *
 * Meant to optimize querying spend data for analytics for a user.
 *
 * Returns:
 * (by date)
 * - spend
 * - prompt_tokens
 * - completion_tokens
 * - cache_read_input_tokens
 * - cache_creation_input_tokens
 * - total_tokens
 * - api_requests
 * - breakdown by model, api_key, provider
 */
export const getUserDailyActivityUserDailyActivityGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetUserDailyActivityUserDailyActivityGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetUserDailyActivityUserDailyActivityGetResponses,
    GetUserDailyActivityUserDailyActivityGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/user/daily/activity',
    ...options,
  });

/**
 * Get User Daily Activity Aggregated
 *
 * Aggregated analytics for a user's daily activity without pagination.
 * Returns the same response shape as the paginated endpoint with page metadata set to single-page.
 */
export const getUserDailyActivityAggregatedUserDailyActivityAggregatedGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetResponses,
    GetUserDailyActivityAggregatedUserDailyActivityAggregatedGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/user/daily/activity/aggregated',
    ...options,
  });

/**
 * New Team
 *
 * Allow users to create a new team. Apply user permissions to their team.
 *
 *  [Detailed Doc on setting team budgets](https://docs.litellm.ai/docs/proxy/team_budgets)
 *
 *
 * Parameters:
 * - team_alias: Optional[str] - User defined team alias
 * - team_id: Optional[str] - The team id of the user. If none passed, we'll generate it.
 * - members_with_roles: List[{"role": "admin" or "user", "user_id": "<user-id>"}] - A list of users and their roles in the team. Get user_id when making a new user via `/user/new`.
 * - team_member_permissions: Optional[List[str]] - A list of routes that non-admin team members can access. example: ["/key/generate", "/key/update", "/key/delete"]
 * - metadata: Optional[dict] - Metadata for team, store information for team. Example metadata = {"extra_info": "some info"}
 * - model_rpm_limit: Optional[Dict[str, int]] - The RPM (Requests Per Minute) limit for this team - applied across all keys for this team.
 * - model_tpm_limit: Optional[Dict[str, int]] - The TPM (Tokens Per Minute) limit for this team - applied across all keys for this team.
 * - tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for this team - all keys with this team_id will have at max this TPM limit
 * - rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for this team - all keys associated with this team_id will have at max this RPM limit
 * - rpm_limit_type: Optional[Literal["guaranteed_throughput", "best_effort_throughput"]] - The type of RPM limit enforcement. Use "guaranteed_throughput" to raise an error if overallocating RPM, or "best_effort_throughput" for best effort enforcement.
 * - tpm_limit_type: Optional[Literal["guaranteed_throughput", "best_effort_throughput"]] - The type of TPM limit enforcement. Use "guaranteed_throughput" to raise an error if overallocating TPM, or "best_effort_throughput" for best effort enforcement.
 * - max_budget: Optional[float] - The maximum budget allocated to the team - all keys for this team_id will have at max this max_budget
 * - budget_duration: Optional[str] - The duration of the budget for the team. Doc [here](https://docs.litellm.ai/docs/proxy/team_budgets)
 * - models: Optional[list] - A list of models associated with the team - all keys for this team_id will have at most, these models. If empty, assumes all models are allowed.
 * - blocked: bool - Flag indicating if the team is blocked or not - will stop all calls from keys with this team_id.
 * - members: Optional[List] - Control team members via `/team/member/add` and `/team/member/delete`.
 * - tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - prompts: Optional[List[str]] - List of prompts that the team is allowed to use.
 * - organization_id: Optional[str] - The organization id of the team. Default is None. Create via `/organization/new`.
 * - model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)
 * - guardrails: Optional[List[str]] - Guardrails for the team. [Docs](https://docs.litellm.ai/docs/proxy/guardrails)
 * - disable_global_guardrails: Optional[bool] - Whether to disable global guardrails for the key.
 * - prompts: Optional[List[str]] - List of prompts that the team is allowed to use.
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - team-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.
 * - team_member_budget: Optional[float] - The maximum budget allocated to an individual team member.
 * - team_member_rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for individual team members.
 * - team_member_tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for individual team members.
 * - team_member_key_duration: Optional[str] - The duration for a team member's key. e.g. "1d", "1w", "1mo"
 * - prompts: Optional[List[str]] - List of allowed prompts for the team. If specified, the team will only be able to use these specific prompts.
 * - allowed_passthrough_routes: Optional[List[str]] - List of allowed pass through routes for the team.
 * - allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.
 *
 *
 *
 * Returns:
 * - team_id: (str) Unique team id - used for tracking spend across multiple keys for same team id.
 *
 * _deprecated_params:
 * - admins: list - A list of user_id's for the admin role
 * - users: list - A list of user_id's for the user role
 *
 * Example Request:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/new'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "team_alias": "my-new-team_2",
 * "members_with_roles": [{"role": "admin", "user_id": "user-1234"},
 * {"role": "user", "user_id": "user-2434"}]
 * }'
 *
 * ```
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/team/new'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "team_alias": "QA Prod Bot",
 * "max_budget": 0.000000001,
 * "budget_duration": "1d"
 * }'
 * ```
 */
export const newTeamTeamNewPost = <ThrowOnError extends boolean = false>(
  options: Options<NewTeamTeamNewPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    NewTeamTeamNewPostResponses,
    NewTeamTeamNewPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/new',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Team
 *
 * Use `/team/member_add` AND `/team/member/delete` to add/remove new team members
 *
 * You can now update team budget / rate limits via /team/update
 *
 * Parameters:
 * - team_id: str - The team id of the user. Required param.
 * - team_alias: Optional[str] - User defined team alias
 * - team_member_permissions: Optional[List[str]] - A list of routes that non-admin team members can access. example: ["/key/generate", "/key/update", "/key/delete"]
 * - metadata: Optional[dict] - Metadata for team, store information for team. Example metadata = {"team": "core-infra", "app": "app2", "email": "ishaan@berri.ai" }
 * - tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for this team - all keys with this team_id will have at max this TPM limit
 * - rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for this team - all keys associated with this team_id will have at max this RPM limit
 * - max_budget: Optional[float] - The maximum budget allocated to the team - all keys for this team_id will have at max this max_budget
 * - budget_duration: Optional[str] - The duration of the budget for the team. Doc [here](https://docs.litellm.ai/docs/proxy/team_budgets)
 * - models: Optional[list] - A list of models associated with the team - all keys for this team_id will have at most, these models. If empty, assumes all models are allowed.
 * - prompts: Optional[List[str]] - List of prompts that the team is allowed to use.
 * - blocked: bool - Flag indicating if the team is blocked or not - will stop all calls from keys with this team_id.
 * - tags: Optional[List[str]] - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - organization_id: Optional[str] - The organization id of the team. Default is None. Create via `/organization/new`.
 * - model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)
 * - guardrails: Optional[List[str]] - Guardrails for the team. [Docs](https://docs.litellm.ai/docs/proxy/guardrails)
 * - disable_global_guardrails: Optional[bool] - Whether to disable global guardrails for the key.
 * - prompts: Optional[List[str]] - List of prompts that the team is allowed to use.
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - team-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"], "mcp_tool_permissions": {"server_id_1": ["tool1", "tool2"]}}. IF null or {} then no object permission.
 * - team_member_budget: Optional[float] - The maximum budget allocated to an individual team member.
 * - team_member_rpm_limit: Optional[int] - The RPM (Requests Per Minute) limit for individual team members.
 * - team_member_tpm_limit: Optional[int] - The TPM (Tokens Per Minute) limit for individual team members.
 * - team_member_key_duration: Optional[str] - The duration for a team member's key. e.g. "1d", "1w", "1mo"
 * - allowed_passthrough_routes: Optional[List[str]] - List of allowed pass through routes for the team.
 * - model_rpm_limit: Optional[Dict[str, int]] - The RPM (Requests Per Minute) limit per model for this team. Example: {"gpt-4": 100, "gpt-3.5-turbo": 200}
 * - model_tpm_limit: Optional[Dict[str, int]] - The TPM (Tokens Per Minute) limit per model for this team. Example: {"gpt-4": 10000, "gpt-3.5-turbo": 20000}
 * Example - update team TPM Limit
 * - allowed_vector_store_indexes: Optional[List[dict]] - List of allowed vector store indexes for the key. Example - [{"index_name": "my-index", "index_permissions": ["write", "read"]}]. If specified, the key will only be able to use these specific vector store indexes. Create index, using `/v1/indexes` endpoint.
 *
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/team/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 * "team_id": "8d916b1c-510d-4894-a334-1c16a93344f5",
 * "tpm_limit": 100
 * }'
 * ```
 *
 * Example - Update Team `max_budget` budget
 * ```
 * curl --location 'http://0.0.0.0:4000/team/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 * "team_id": "8d916b1c-510d-4894-a334-1c16a93344f5",
 * "max_budget": 10
 * }'
 * ```
 */
export const updateTeamTeamUpdatePost = <ThrowOnError extends boolean = false>(
  options: Options<UpdateTeamTeamUpdatePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UpdateTeamTeamUpdatePostResponses,
    UpdateTeamTeamUpdatePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Team Member Add
 *
 * Add new members (either via user_email or user_id) to a team
 *
 * If user doesn't exist, new user row will also be added to User Table
 *
 * Only proxy_admin or admin of team, allowed to access this endpoint.
 * ```
 *
 * curl -X POST 'http://0.0.0.0:4000/team/member_add'     -H 'Authorization: Bearer sk-1234'     -H 'Content-Type: application/json'     -d '{"team_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849", "member": {"role": "user", "user_id": "krrish247652@berri.ai"}}'
 *
 * ```
 */
export const teamMemberAddTeamMemberAddPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<TeamMemberAddTeamMemberAddPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TeamMemberAddTeamMemberAddPostResponses,
    TeamMemberAddTeamMemberAddPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/member_add',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Team Member Delete
 *
 * [BETA]
 *
 * delete members (either via user_email or user_id) from a team
 *
 * If user doesn't exist, an exception will be raised
 * ```
 * curl -X POST 'http://0.0.0.0:8000/team/member_delete'
 * -H 'Authorization: Bearer sk-1234'
 * -H 'Content-Type: application/json'
 * -d '{
 * "team_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849",
 * "user_id": "krrish247652@berri.ai"
 * }'
 * ```
 */
export const teamMemberDeleteTeamMemberDeletePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<TeamMemberDeleteTeamMemberDeletePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TeamMemberDeleteTeamMemberDeletePostResponses,
    TeamMemberDeleteTeamMemberDeletePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/member_delete',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Team Member Update
 *
 * [BETA]
 *
 * Update team member budgets and team member role
 */
export const teamMemberUpdateTeamMemberUpdatePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<TeamMemberUpdateTeamMemberUpdatePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TeamMemberUpdateTeamMemberUpdatePostResponses,
    TeamMemberUpdateTeamMemberUpdatePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/member_update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Bulk Team Member Add
 *
 * Bulk add multiple members to a team at once.
 *
 * This endpoint reuses the same logic as /team/member_add but provides a bulk-friendly response format.
 *
 * Parameters:
 * - team_id: str - The ID of the team to add members to
 * - members: List[Member] - List of members to add to the team
 * - all_users: Optional[bool] - Flag to add all users on Proxy to the team
 * - max_budget_in_team: Optional[float] - Maximum budget allocated to each user within the team
 *
 * Returns:
 * - results: List of individual member addition results
 * - total_requested: Total number of members requested for addition
 * - successful_additions: Number of successful additions
 * - failed_additions: Number of failed additions
 * - updated_team: The updated team object
 *
 * Example request:
 * ```bash
 * curl --location 'http://0.0.0.0:4000/team/bulk_member_add'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "team_id": "team-1234",
 * "members": [
 * {
 * "user_id": "user1",
 * "role": "user"
 * },
 * {
 * "user_email": "user2@example.com",
 * "role": "admin"
 * }
 * ],
 * "max_budget_in_team": 100.0
 * }'
 * ```
 */
export const bulkTeamMemberAddTeamBulkMemberAddPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<BulkTeamMemberAddTeamBulkMemberAddPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    BulkTeamMemberAddTeamBulkMemberAddPostResponses,
    BulkTeamMemberAddTeamBulkMemberAddPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/bulk_member_add',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Delete Team
 *
 * delete team and associated team keys
 *
 * Parameters:
 * - team_ids: List[str] - Required. List of team IDs to delete. Example: ["team-1234", "team-5678"]
 *
 * ```
 * curl --location 'http://0.0.0.0:4000/team/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data-raw '{
 * "team_ids": ["8d916b1c-510d-4894-a334-1c16a93344f5"]
 * }'
 * ```
 */
export const deleteTeamTeamDeletePost = <ThrowOnError extends boolean = false>(
  options: Options<DeleteTeamTeamDeletePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    DeleteTeamTeamDeletePostResponses,
    DeleteTeamTeamDeletePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/delete',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Team Info
 *
 * get info on team + related keys
 *
 * Parameters:
 * - team_id: str - Required. The unique identifier of the team to get info on.
 *
 * ```
 * curl --location 'http://localhost:4000/team/info?team_id=your_team_id_here'     --header 'Authorization: Bearer your_api_key_here'
 * ```
 */
export const teamInfoTeamInfoGet = <ThrowOnError extends boolean = false>(
  options?: Options<TeamInfoTeamInfoGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    TeamInfoTeamInfoGetResponses,
    TeamInfoTeamInfoGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/info',
    ...options,
  });

/**
 * Block Team
 *
 * Blocks all calls from keys with this team id.
 *
 * Parameters:
 * - team_id: str - Required. The unique identifier of the team to block.
 *
 * Example:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/block'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "team_id": "team-1234"
 * }'
 * ```
 *
 * Returns:
 * - The updated team record with blocked=True
 */
export const blockTeamTeamBlockPost = <ThrowOnError extends boolean = false>(
  options: Options<BlockTeamTeamBlockPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    BlockTeamTeamBlockPostResponses,
    BlockTeamTeamBlockPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/block',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Unblock Team
 *
 * Blocks all calls from keys with this team id.
 *
 * Parameters:
 * - team_id: str - Required. The unique identifier of the team to unblock.
 *
 * Example:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/unblock'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "team_id": "team-1234"
 * }'
 * ```
 */
export const unblockTeamTeamUnblockPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UnblockTeamTeamUnblockPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UnblockTeamTeamUnblockPostResponses,
    UnblockTeamTeamUnblockPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/unblock',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * List Available Teams
 */
export const listAvailableTeamsTeamAvailableGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListAvailableTeamsTeamAvailableGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListAvailableTeamsTeamAvailableGetResponses,
    ListAvailableTeamsTeamAvailableGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/available',
    ...options,
  });

/**
 * List Team V2
 *
 * Get a paginated list of teams with filtering and sorting options.
 *
 * Parameters:
 * user_id: Optional[str]
 * Only return teams which this user belongs to
 * organization_id: Optional[str]
 * Only return teams which belong to this organization
 * team_id: Optional[str]
 * Filter teams by exact team_id match
 * team_alias: Optional[str]
 * Filter teams by partial team_alias match
 * page: int
 * The page number to return
 * page_size: int
 * The number of items per page
 * sort_by: Optional[str]
 * Column to sort by (e.g. 'team_id', 'team_alias', 'created_at')
 * sort_order: str
 * Sort order ('asc' or 'desc')
 */
export const listTeamV2V2TeamListGet = <ThrowOnError extends boolean = false>(
  options?: Options<ListTeamV2V2TeamListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListTeamV2V2TeamListGetResponses,
    ListTeamV2V2TeamListGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v2/team/list',
    ...options,
  });

/**
 * List Team
 *
 * ```
 * curl --location --request GET 'http://0.0.0.0:4000/team/list'         --header 'Authorization: Bearer sk-1234'
 * ```
 *
 * Parameters:
 * - user_id: str - Optional. If passed will only return teams that the user_id is a member of.
 * - organization_id: str - Optional. If passed will only return teams that belong to the organization_id. Pass 'default_organization' to get all teams without organization_id.
 */
export const listTeamTeamListGet = <ThrowOnError extends boolean = false>(
  options?: Options<ListTeamTeamListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListTeamTeamListGetResponses,
    ListTeamTeamListGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/list',
    ...options,
  });

/**
 * Team Model Add
 *
 * Add models to a team's allowed model list. Only proxy admin or team admin can add models.
 *
 * Parameters:
 * - team_id: str - Required. The team to add models to
 * - models: List[str] - Required. List of models to add to the team
 *
 * Example Request:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/model/add'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "team_id": "team-1234",
 * "models": ["gpt-4", "claude-2"]
 * }'
 * ```
 */
export const teamModelAddTeamModelAddPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<TeamModelAddTeamModelAddPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TeamModelAddTeamModelAddPostResponses,
    TeamModelAddTeamModelAddPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/model/add',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Team Model Delete
 *
 * Remove models from a team's allowed model list. Only proxy admin or team admin can remove models.
 *
 * Parameters:
 * - team_id: str - Required. The team to remove models from
 * - models: List[str] - Required. List of models to remove from the team
 *
 * Example Request:
 * ```
 * curl --location 'http://0.0.0.0:4000/team/model/delete'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "team_id": "team-1234",
 * "models": ["gpt-4"]
 * }'
 * ```
 */
export const teamModelDeleteTeamModelDeletePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<TeamModelDeleteTeamModelDeletePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TeamModelDeleteTeamModelDeletePostResponses,
    TeamModelDeleteTeamModelDeletePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/model/delete',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Team Member Permissions
 *
 * Get the team member permissions for a team
 */
export const teamMemberPermissionsTeamPermissionsListGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    TeamMemberPermissionsTeamPermissionsListGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    TeamMemberPermissionsTeamPermissionsListGetResponses,
    TeamMemberPermissionsTeamPermissionsListGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/permissions_list',
    ...options,
  });

/**
 * Update Team Member Permissions
 *
 * Update the team member permissions for a team
 */
export const updateTeamMemberPermissionsTeamPermissionsUpdatePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    UpdateTeamMemberPermissionsTeamPermissionsUpdatePostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    UpdateTeamMemberPermissionsTeamPermissionsUpdatePostResponses,
    UpdateTeamMemberPermissionsTeamPermissionsUpdatePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/permissions_update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Team Daily Activity
 *
 * Get daily activity for specific teams or all teams.
 *
 * Args:
 * team_ids (Optional[str]): Comma-separated list of team IDs to filter by. If not provided, returns data for all teams.
 * start_date (Optional[str]): Start date for the activity period (YYYY-MM-DD).
 * end_date (Optional[str]): End date for the activity period (YYYY-MM-DD).
 * model (Optional[str]): Filter by model name.
 * api_key (Optional[str]): Filter by API key.
 * page (int): Page number for pagination.
 * page_size (int): Number of items per page.
 * exclude_team_ids (Optional[str]): Comma-separated list of team IDs to exclude.
 * Returns:
 * SpendAnalyticsPaginatedResponse: Paginated response containing daily activity data.
 */
export const getTeamDailyActivityTeamDailyActivityGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetTeamDailyActivityTeamDailyActivityGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetTeamDailyActivityTeamDailyActivityGetResponses,
    GetTeamDailyActivityTeamDailyActivityGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/daily/activity',
    ...options,
  });

/**
 * Get Service Provider Config
 *
 * Return SCIM Service Provider Configuration.
 */
export const getServiceProviderConfigScimV2ServiceProviderConfigGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetServiceProviderConfigScimV2ServiceProviderConfigGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetServiceProviderConfigScimV2ServiceProviderConfigGetResponses,
    GetServiceProviderConfigScimV2ServiceProviderConfigGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/ServiceProviderConfig',
    ...options,
  });

/**
 * Get Users
 *
 * Get a list of users according to SCIM v2 protocol
 */
export const getUsersScimV2UsersGet = <ThrowOnError extends boolean = false>(
  options?: Options<GetUsersScimV2UsersGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetUsersScimV2UsersGetResponses,
    GetUsersScimV2UsersGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/Users',
    ...options,
  });

/**
 * Create User
 *
 * Create a user according to SCIM v2 protocol
 */
export const createUserScimV2UsersPost = <ThrowOnError extends boolean = false>(
  options: Options<CreateUserScimV2UsersPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateUserScimV2UsersPostResponses,
    CreateUserScimV2UsersPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/Users',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Delete User
 *
 * Delete a user according to SCIM v2 protocol
 */
export const deleteUserScimV2UsersUserIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteUserScimV2UsersUserIdDeleteData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    DeleteUserScimV2UsersUserIdDeleteResponses,
    DeleteUserScimV2UsersUserIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/Users/{user_id}',
    ...options,
  });

/**
 * Get User
 *
 * Get a single user by ID according to SCIM v2 protocol
 */
export const getUserScimV2UsersUserIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetUserScimV2UsersUserIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetUserScimV2UsersUserIdGetResponses,
    GetUserScimV2UsersUserIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/Users/{user_id}',
    ...options,
  });

/**
 * Patch User
 *
 * Patch a user according to SCIM v2 protocol
 */
export const patchUserScimV2UsersUserIdPatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<PatchUserScimV2UsersUserIdPatchData, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    PatchUserScimV2UsersUserIdPatchResponses,
    PatchUserScimV2UsersUserIdPatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/Users/{user_id}',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update User
 *
 * Update a user according to SCIM v2 protocol (full replacement)
 */
export const updateUserScimV2UsersUserIdPut = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UpdateUserScimV2UsersUserIdPutData, ThrowOnError>,
) =>
  (options.client ?? client).put<
    UpdateUserScimV2UsersUserIdPutResponses,
    UpdateUserScimV2UsersUserIdPutErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/Users/{user_id}',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Groups
 *
 * Get a list of groups according to SCIM v2 protocol
 */
export const getGroupsScimV2GroupsGet = <ThrowOnError extends boolean = false>(
  options?: Options<GetGroupsScimV2GroupsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetGroupsScimV2GroupsGetResponses,
    GetGroupsScimV2GroupsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/Groups',
    ...options,
  });

/**
 * Create Group
 *
 * Create a group according to SCIM v2 protocol
 */
export const createGroupScimV2GroupsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CreateGroupScimV2GroupsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateGroupScimV2GroupsPostResponses,
    CreateGroupScimV2GroupsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/Groups',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Delete Group
 *
 * Delete a group according to SCIM v2 protocol
 */
export const deleteGroupScimV2GroupsGroupIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteGroupScimV2GroupsGroupIdDeleteData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    DeleteGroupScimV2GroupsGroupIdDeleteResponses,
    DeleteGroupScimV2GroupsGroupIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/Groups/{group_id}',
    ...options,
  });

/**
 * Get Group
 *
 * Get a single group by ID according to SCIM v2 protocol
 */
export const getGroupScimV2GroupsGroupIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetGroupScimV2GroupsGroupIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetGroupScimV2GroupsGroupIdGetResponses,
    GetGroupScimV2GroupsGroupIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/Groups/{group_id}',
    ...options,
  });

/**
 * Patch Group
 *
 * Patch a group according to SCIM v2 protocol
 */
export const patchGroupScimV2GroupsGroupIdPatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<PatchGroupScimV2GroupsGroupIdPatchData, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    PatchGroupScimV2GroupsGroupIdPatchResponses,
    PatchGroupScimV2GroupsGroupIdPatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/Groups/{group_id}',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Group
 *
 * Update a group according to SCIM v2 protocol
 */
export const updateGroupScimV2GroupsGroupIdPut = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UpdateGroupScimV2GroupsGroupIdPutData, ThrowOnError>,
) =>
  (options.client ?? client).put<
    UpdateGroupScimV2GroupsGroupIdPutResponses,
    UpdateGroupScimV2GroupsGroupIdPutErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/scim/v2/Groups/{group_id}',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * New Organization
 *
 * Allow orgs to own teams
 *
 * Set org level budgets + model access.
 *
 * Only admins can create orgs.
 *
 * # Parameters
 *
 * - organization_alias: *str* - The name of the organization.
 * - models: *List* - The models the organization has access to.
 * - budget_id: *Optional[str]* - The id for a budget (tpm/rpm/max budget) for the organization.
 * ### IF NO BUDGET ID - CREATE ONE WITH THESE PARAMS ###
 * - max_budget: *Optional[float]* - Max budget for org
 * - tpm_limit: *Optional[int]* - Max tpm limit for org
 * - rpm_limit: *Optional[int]* - Max rpm limit for org
 * - model_rpm_limit: *Optional[Dict[str, int]]* - The RPM (Requests Per Minute) limit per model for this organization.
 * - model_tpm_limit: *Optional[Dict[str, int]]* - The TPM (Tokens Per Minute) limit per model for this organization.
 * - max_parallel_requests: *Optional[int]* - [Not Implemented Yet] Max parallel requests for org
 * - soft_budget: *Optional[float]* - [Not Implemented Yet] Get a slack alert when this soft budget is reached. Don't block requests.
 * - model_max_budget: *Optional[dict]* - Max budget for a specific model
 * - budget_duration: *Optional[str]* - Frequency of reseting org budget
 * - metadata: *Optional[dict]* - Metadata for organization, store information for organization. Example metadata - {"extra_info": "some info"}
 * - blocked: *bool* - Flag indicating if the org is blocked or not - will stop all calls from keys with this org_id.
 * - tags: *Optional[List[str]]* - Tags for [tracking spend](https://litellm.vercel.app/docs/proxy/enterprise#tracking-spend-for-custom-tags) and/or doing [tag-based routing](https://litellm.vercel.app/docs/proxy/tag_routing).
 * - organization_id: *Optional[str]* - The organization id of the team. Default is None. Create via `/organization/new`.
 * - model_aliases: Optional[dict] - Model aliases for the team. [Docs](https://docs.litellm.ai/docs/proxy/team_based_routing#create-team-with-model-alias)
 * - object_permission: Optional[LiteLLM_ObjectPermissionBase] - organization-specific object permission. Example - {"vector_stores": ["vector_store_1", "vector_store_2"]}. IF null or {} then no object permission.
 * Case 1: Create new org **without** a budget_id
 *
 * ```bash
 * curl --location 'http://0.0.0.0:4000/organization/new'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data '{
 * "organization_alias": "my-secret-org",
 * "models": ["model1", "model2"],
 * "max_budget": 100
 * }'
 *
 *
 * ```
 *
 * Case 2: Create new org **with** a budget_id
 *
 * ```bash
 * curl --location 'http://0.0.0.0:4000/organization/new'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data '{
 * "organization_alias": "my-secret-org",
 * "models": ["model1", "model2"],
 * "budget_id": "428eeaa8-f3ac-4e85-a8fb-7dc8d7aa8689"
 * }'
 * ```
 */
export const newOrganizationOrganizationNewPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<NewOrganizationOrganizationNewPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    NewOrganizationOrganizationNewPostResponses,
    NewOrganizationOrganizationNewPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/organization/new',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Organization Daily Activity
 *
 * Get daily activity for specific organizations or all accessible organizations.
 */
export const getOrganizationDailyActivityOrganizationDailyActivityGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetOrganizationDailyActivityOrganizationDailyActivityGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetOrganizationDailyActivityOrganizationDailyActivityGetResponses,
    GetOrganizationDailyActivityOrganizationDailyActivityGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/organization/daily/activity',
    ...options,
  });

/**
 * Update Organization
 *
 * Update an organization
 */
export const updateOrganizationOrganizationUpdatePatch = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    UpdateOrganizationOrganizationUpdatePatchData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).patch<
    UpdateOrganizationOrganizationUpdatePatchResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/organization/update',
    ...options,
  });

/**
 * Delete Organization
 *
 * Delete an organization
 *
 * # Parameters:
 *
 * - organization_ids: List[str] - The organization ids to delete.
 */
export const deleteOrganizationOrganizationDeleteDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DeleteOrganizationOrganizationDeleteDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    DeleteOrganizationOrganizationDeleteDeleteResponses,
    DeleteOrganizationOrganizationDeleteDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/organization/delete',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * List Organization
 *
 * ```
 * curl --location --request GET 'http://0.0.0.0:4000/organization/list'         --header 'Authorization: Bearer sk-1234'
 * ```
 */
export const listOrganizationOrganizationListGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListOrganizationOrganizationListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListOrganizationOrganizationListGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/organization/list',
    ...options,
  });

/**
 * Info Organization
 *
 * Get the org specific information
 */
export const infoOrganizationOrganizationInfoGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<InfoOrganizationOrganizationInfoGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    InfoOrganizationOrganizationInfoGetResponses,
    InfoOrganizationOrganizationInfoGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/organization/info',
    ...options,
  });

/**
 * Deprecated Info Organization
 *
 * DEPRECATED: Use GET /organization/info instead
 */
export const deprecatedInfoOrganizationOrganizationInfoPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DeprecatedInfoOrganizationOrganizationInfoPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    DeprecatedInfoOrganizationOrganizationInfoPostResponses,
    DeprecatedInfoOrganizationOrganizationInfoPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/organization/info',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Organization Member Add
 *
 * [BETA]
 *
 * Add new members (either via user_email or user_id) to an organization
 *
 * If user doesn't exist, new user row will also be added to User Table
 *
 * Only proxy_admin or org_admin of organization, allowed to access this endpoint.
 *
 * # Parameters:
 *
 * - organization_id: str (required)
 * - member: Union[List[Member], Member] (required)
 * - role: Literal[LitellmUserRoles] (required)
 * - user_id: Optional[str]
 * - user_email: Optional[str]
 *
 * Note: Either user_id or user_email must be provided for each member.
 *
 * Example:
 * ```
 * curl -X POST 'http://0.0.0.0:4000/organization/member_add'     -H 'Authorization: Bearer sk-1234'     -H 'Content-Type: application/json'     -d '{
 * "organization_id": "45e3e396-ee08-4a61-a88e-16b3ce7e0849",
 * "member": {
 * "role": "internal_user",
 * "user_id": "krrish247652@berri.ai"
 * },
 * "max_budget_in_organization": 100.0
 * }'
 * ```
 *
 * The following is executed in this function:
 *
 * 1. Check if organization exists
 * 2. Creates a new Internal User if the user_id or user_email is not found in LiteLLM_UserTable
 * 3. Add Internal User to the `LiteLLM_OrganizationMembership` table
 */
export const organizationMemberAddOrganizationMemberAddPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    OrganizationMemberAddOrganizationMemberAddPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    OrganizationMemberAddOrganizationMemberAddPostResponses,
    OrganizationMemberAddOrganizationMemberAddPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/organization/member_add',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Organization Member Update
 *
 * Update a member's role in an organization
 */
export const organizationMemberUpdateOrganizationMemberUpdatePatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    OrganizationMemberUpdateOrganizationMemberUpdatePatchData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).patch<
    OrganizationMemberUpdateOrganizationMemberUpdatePatchResponses,
    OrganizationMemberUpdateOrganizationMemberUpdatePatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/organization/member_update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Organization Member Delete
 *
 * Delete a member from an organization
 */
export const organizationMemberDeleteOrganizationMemberDeleteDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    OrganizationMemberDeleteOrganizationMemberDeleteDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    OrganizationMemberDeleteOrganizationMemberDeleteDeleteResponses,
    OrganizationMemberDeleteOrganizationMemberDeleteDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/organization/member_delete',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Block User
 *
 * [BETA] Reject calls with this end-user id
 *
 * Parameters:
 * - user_ids (List[str], required): The unique `user_id`s for the users to block
 *
 * (any /chat/completion call with this user={end-user-id} param, will be rejected.)
 *
 * ```
 * curl -X POST "http://0.0.0.0:8000/user/block"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "user_ids": [<user_id>, ...]
 * }'
 * ```
 */
export const blockUserCustomerBlockPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<BlockUserCustomerBlockPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    BlockUserCustomerBlockPostResponses,
    BlockUserCustomerBlockPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/customer/block',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Unblock User
 *
 * [BETA] Unblock calls with this user id
 *
 * Example
 * ```
 * curl -X POST "http://0.0.0.0:8000/user/unblock"
 * -H "Authorization: Bearer sk-1234"
 * -d '{
 * "user_ids": [<user_id>, ...]
 * }'
 * ```
 */
export const unblockUserCustomerUnblockPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UnblockUserCustomerUnblockPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UnblockUserCustomerUnblockPostResponses,
    UnblockUserCustomerUnblockPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/customer/unblock',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * New End User
 *
 * Allow creating a new Customer
 *
 *
 * Parameters:
 * - user_id: str - The unique identifier for the user.
 * - alias: Optional[str] - A human-friendly alias for the user.
 * - blocked: bool - Flag to allow or disallow requests for this end-user. Default is False.
 * - max_budget: Optional[float] - The maximum budget allocated to the user. Either 'max_budget' or 'budget_id' should be provided, not both.
 * - budget_id: Optional[str] - The identifier for an existing budget allocated to the user. Either 'max_budget' or 'budget_id' should be provided, not both.
 * - allowed_model_region: Optional[Union[Literal["eu"], Literal["us"]]] - Require all user requests to use models in this specific region.
 * - default_model: Optional[str] - If no equivalent model in the allowed region, default all requests to this model.
 * - metadata: Optional[dict] = Metadata for customer, store information for customer. Example metadata = {"data_training_opt_out": True}
 * - budget_duration: Optional[str] - Budget is reset at the end of specified duration. If not set, budget is never reset. You can set duration as seconds ("30s"), minutes ("30m"), hours ("30h"), days ("30d").
 * - tpm_limit: Optional[int] - [Not Implemented Yet] Specify tpm limit for a given customer (Tokens per minute)
 * - rpm_limit: Optional[int] - [Not Implemented Yet] Specify rpm limit for a given customer (Requests per minute)
 * - model_max_budget: Optional[dict] - [Not Implemented Yet] Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d"}}
 * - max_parallel_requests: Optional[int] - [Not Implemented Yet] Specify max parallel requests for a given customer.
 * - soft_budget: Optional[float] - [Not Implemented Yet] Get alerts when customer crosses given budget, doesn't block requests.
 * - spend: Optional[float] - Specify initial spend for a given customer.
 * - budget_reset_at: Optional[str] - Specify the date and time when the budget should be reset.
 *
 *
 * - Allow specifying allowed regions
 * - Allow specifying default model
 *
 * Example curl:
 * ```
 * curl --location 'http://0.0.0.0:4000/customer/new'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{
 * "user_id" : "ishaan-jaff-3",
 * "allowed_region": "eu",
 * "budget_id": "free_tier",
 * "default_model": "azure/gpt-3.5-turbo-eu" <- all calls from this user, use this model?
 * }'
 *
 * # return end-user object
 * ```
 *
 * NOTE: This used to be called `/end_user/new`, we will still be maintaining compatibility for /end_user/XXX for these endpoints
 */
export const newEndUserCustomerNewPost = <ThrowOnError extends boolean = false>(
  options: Options<NewEndUserCustomerNewPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    NewEndUserCustomerNewPostResponses,
    NewEndUserCustomerNewPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/customer/new',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * End User Info
 *
 * Get information about an end-user. An `end_user` is a customer (external user) of the proxy.
 *
 * Parameters:
 * - end_user_id (str, required): The unique identifier for the end-user
 *
 * Example curl:
 * ```
 * curl -X GET 'http://localhost:4000/customer/info?end_user_id=test-litellm-user-4'         -H 'Authorization: Bearer sk-1234'
 * ```
 */
export const endUserInfoCustomerInfoGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<EndUserInfoCustomerInfoGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    EndUserInfoCustomerInfoGetResponses,
    EndUserInfoCustomerInfoGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/customer/info',
    ...options,
  });

/**
 * Update End User
 *
 * Example curl
 *
 * Parameters:
 * - user_id: str
 * - alias: Optional[str] = None  # human-friendly alias
 * - blocked: bool = False  # allow/disallow requests for this end-user
 * - max_budget: Optional[float] = None
 * - budget_id: Optional[str] = None  # give either a budget_id or max_budget
 * - allowed_model_region: Optional[AllowedModelRegion] = (
 * None  # require all user requests to use models in this specific region
 * )
 * - default_model: Optional[str] = (
 * None  # if no equivalent model in allowed region - default all requests to this model
 * )
 *
 * Example curl:
 * ```
 * curl --location 'http://0.0.0.0:4000/customer/update'     --header 'Authorization: Bearer sk-1234'     --header 'Content-Type: application/json'     --data '{
 * "user_id": "test-litellm-user-4",
 * "budget_id": "paid_tier"
 * }'
 *
 * See below for all params
 * ```
 */
export const updateEndUserCustomerUpdatePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UpdateEndUserCustomerUpdatePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UpdateEndUserCustomerUpdatePostResponses,
    UpdateEndUserCustomerUpdatePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/customer/update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Delete End User
 *
 * Delete multiple end-users.
 *
 * Parameters:
 * - user_ids (List[str], required): The unique `user_id`s for the users to delete
 *
 * Example curl:
 * ```
 * curl --location 'http://0.0.0.0:4000/customer/delete'         --header 'Authorization: Bearer sk-1234'         --header 'Content-Type: application/json'         --data '{
 * "user_ids" :["ishaan-jaff-5"]
 * }'
 *
 * See below for all params
 * ```
 */
export const deleteEndUserCustomerDeletePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteEndUserCustomerDeletePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    DeleteEndUserCustomerDeletePostResponses,
    DeleteEndUserCustomerDeletePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/customer/delete',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * List End User
 *
 * [Admin-only] List all available customers
 *
 * Example curl:
 * ```
 * curl --location --request GET 'http://0.0.0.0:4000/customer/list'         --header 'Authorization: Bearer sk-1234'
 * ```
 */
export const listEndUserCustomerListGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListEndUserCustomerListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListEndUserCustomerListGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/customer/list',
    ...options,
  });

/**
 * View Spend Tags
 *
 * LiteLLM Enterprise - View Spend Per Request Tag
 *
 * Example Request:
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/tags" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Spend with Start Date and End Date
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/tags?start_date=2022-01-01&end_date=2022-02-01" -H "Authorization: Bearer sk-1234"
 * ```
 */
export const viewSpendTagsSpendTagsGet = <ThrowOnError extends boolean = false>(
  options?: Options<ViewSpendTagsSpendTagsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ViewSpendTagsSpendTagsGetResponses,
    ViewSpendTagsSpendTagsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/spend/tags',
    ...options,
  });

/**
 * Get Global Spend Report
 *
 * Get Daily Spend per Team, based on specific startTime and endTime. Per team, view usage by each key, model
 * [
 * {
 * "group-by-day": "2024-05-10",
 * "teams": [
 * {
 * "team_name": "team-1"
 * "spend": 10,
 * "keys": [
 * "key": "1213",
 * "usage": {
 * "model-1": {
 * "cost": 12.50,
 * "input_tokens": 1000,
 * "output_tokens": 5000,
 * "requests": 100
 * },
 * "audio-modelname1": {
 * "cost": 25.50,
 * "seconds": 25,
 * "requests": 50
 * },
 * }
 * }
 * ]
 * ]
 * }
 */
export const getGlobalSpendReportGlobalSpendReportGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetGlobalSpendReportGlobalSpendReportGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetGlobalSpendReportGlobalSpendReportGetResponses,
    GetGlobalSpendReportGlobalSpendReportGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/global/spend/report',
    ...options,
  });

/**
 * Global View Spend Tags
 *
 * LiteLLM Enterprise - View Spend Per Request Tag. Used by LiteLLM UI
 *
 * Example Request:
 * ```
 * curl -X GET "http://0.0.0.0:4000/spend/tags" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Spend with Start Date and End Date
 * ```
 * curl -X GET "http://0.0.0.0:4000/spend/tags?start_date=2022-01-01&end_date=2022-02-01" -H "Authorization: Bearer sk-1234"
 * ```
 */
export const globalViewSpendTagsGlobalSpendTagsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GlobalViewSpendTagsGlobalSpendTagsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GlobalViewSpendTagsGlobalSpendTagsGetResponses,
    GlobalViewSpendTagsGlobalSpendTagsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/global/spend/tags',
    ...options,
  });

/**
 * Calculate Spend
 *
 * Accepts all the params of completion_cost.
 *
 * Calculate spend **before** making call:
 *
 * Note: If you see a spend of $0.0 you need to set custom_pricing for your model: https://docs.litellm.ai/docs/proxy/custom_pricing
 *
 * ```
 * curl --location 'http://localhost:4000/spend/calculate'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data '{
 * "model": "anthropic.claude-v2",
 * "messages": [{"role": "user", "content": "Hey, how'''s it going?"}]
 * }'
 * ```
 *
 * Calculate spend **after** making call:
 *
 * ```
 * curl --location 'http://localhost:4000/spend/calculate'
 * --header 'Authorization: Bearer sk-1234'
 * --header 'Content-Type: application/json'
 * --data '{
 * "completion_response": {
 * "id": "chatcmpl-123",
 * "object": "chat.completion",
 * "created": 1677652288,
 * "model": "gpt-3.5-turbo-0125",
 * "system_fingerprint": "fp_44709d6fcb",
 * "choices": [{
 * "index": 0,
 * "message": {
 * "role": "assistant",
 * "content": "Hello there, how may I assist you today?"
 * },
 * "logprobs": null,
 * "finish_reason": "stop"
 * }]
 * "usage": {
 * "prompt_tokens": 9,
 * "completion_tokens": 12,
 * "total_tokens": 21
 * }
 * }
 * }'
 * ```
 */
export const calculateSpendSpendCalculatePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CalculateSpendSpendCalculatePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CalculateSpendSpendCalculatePostResponses,
    CalculateSpendSpendCalculatePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/spend/calculate',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Ui View Spend Logs
 *
 * View spend logs with pagination support.
 * Available at both `/spend/logs/v2` (public API) and `/spend/logs/ui` (internal UI).
 *
 * Returns paginated response with data, total, page, page_size, and total_pages.
 *
 * Example:
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs/v2?start_date=2025-11-25%2000:00:00&end_date=2025-11-26%2023:59:59&page=1&page_size=50" -H "Authorization: Bearer sk-1234"
 * ```
 */
export const uiViewSpendLogsSpendLogsV2Get = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<UiViewSpendLogsSpendLogsV2GetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    UiViewSpendLogsSpendLogsV2GetResponses,
    UiViewSpendLogsSpendLogsV2GetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/spend/logs/v2',
    ...options,
  });

/**
 * View Spend Logs
 *
 * [DEPRECATED] This endpoint is not paginated and can cause performance issues.
 * Please use `/spend/logs/v2` instead for paginated access to spend logs.
 *
 * View all spend logs, if request_id is provided, only logs for that request_id will be returned
 *
 * When start_date and end_date are provided:
 * - summarize=true (default): Returns aggregated spend data grouped by date (maintains backward compatibility)
 * - summarize=false: Returns filtered individual log entries within the date range
 *
 * Example Request for all logs
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Request for specific request_id
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs?request_id=chatcmpl-6dcb2540-d3d7-4e49-bb27-291f863f112e" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Request for specific api_key
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs?api_key=sk-Fn8Ej39NkBQmUagFEoUWPQ" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Request for specific user_id
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs?user_id=ishaan@berri.ai" -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Request for date range with individual logs (unsummarized)
 * ```
 * curl -X GET "http://0.0.0.0:8000/spend/logs?start_date=2024-01-01&end_date=2024-01-02&summarize=false" -H "Authorization: Bearer sk-1234"
 * ```
 */
export const viewSpendLogsSpendLogsGet = <ThrowOnError extends boolean = false>(
  options?: Options<ViewSpendLogsSpendLogsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ViewSpendLogsSpendLogsGetResponses,
    ViewSpendLogsSpendLogsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/spend/logs',
    ...options,
  });

/**
 * Global Spend Reset
 *
 * ADMIN ONLY / MASTER KEY Only Endpoint
 *
 * Globally reset spend for All API Keys and Teams, maintain LiteLLM_SpendLogs
 *
 * 1. LiteLLM_SpendLogs will maintain the logs on spend, no data gets deleted from there
 * 2. LiteLLM_VerificationTokens spend will be set = 0
 * 3. LiteLLM_TeamTable spend will be set = 0
 */
export const globalSpendResetGlobalSpendResetPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GlobalSpendResetGlobalSpendResetPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    GlobalSpendResetGlobalSpendResetPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/global/spend/reset',
    ...options,
  });

/**
 * Provider Budgets
 *
 * Provider Budget Routing - Get Budget, Spend Details https://docs.litellm.ai/docs/proxy/provider_budget_routing
 *
 * Use this endpoint to check current budget, spend and budget reset time for a provider
 *
 * Example Request
 *
 * ```bash
 * curl -X GET http://localhost:4000/provider/budgets     -H "Content-Type: application/json"     -H "Authorization: Bearer sk-1234"
 * ```
 *
 * Example Response
 *
 * ```json
 * {
 * "providers": {
 * "openai": {
 * "budget_limit": 1e-12,
 * "time_period": "1d",
 * "spend": 0.0,
 * "budget_reset_at": null
 * },
 * "azure": {
 * "budget_limit": 100.0,
 * "time_period": "1d",
 * "spend": 0.0,
 * "budget_reset_at": null
 * },
 * "anthropic": {
 * "budget_limit": 100.0,
 * "time_period": "10d",
 * "spend": 0.0,
 * "budget_reset_at": null
 * },
 * "vertex_ai": {
 * "budget_limit": 100.0,
 * "time_period": "12d",
 * "spend": 0.0,
 * "budget_reset_at": null
 * }
 * }
 * }
 * ```
 */
export const providerBudgetsProviderBudgetsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ProviderBudgetsProviderBudgetsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ProviderBudgetsProviderBudgetsGetResponses,
    unknown,
    ThrowOnError
  >({ url: '/provider/budgets', ...options });

/**
 * Get Cloudzero Settings
 *
 * View current CloudZero settings.
 *
 * Returns the current CloudZero configuration with the API key masked for security.
 * Only the first 4 and last 4 characters of the API key are shown.
 *
 * Only admin users can view CloudZero settings.
 */
export const getCloudzeroSettingsCloudzeroSettingsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetCloudzeroSettingsCloudzeroSettingsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetCloudzeroSettingsCloudzeroSettingsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cloudzero/settings',
    ...options,
  });

/**
 * Update Cloudzero Settings
 *
 * Update existing CloudZero settings.
 *
 * Allows updating individual CloudZero configuration fields without requiring all fields.
 * Only provided fields will be updated; others will remain unchanged.
 *
 * Parameters:
 * - api_key: (Optional) New CloudZero API key for authentication
 * - connection_id: (Optional) New CloudZero connection ID for data submission
 * - timezone: (Optional) New timezone for date handling
 *
 * Only admin users can update CloudZero settings.
 */
export const updateCloudzeroSettingsCloudzeroSettingsPut = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    UpdateCloudzeroSettingsCloudzeroSettingsPutData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).put<
    UpdateCloudzeroSettingsCloudzeroSettingsPutResponses,
    UpdateCloudzeroSettingsCloudzeroSettingsPutErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cloudzero/settings',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Init Cloudzero Settings
 *
 * Initialize CloudZero settings and store in the database.
 *
 * This endpoint stores the CloudZero API key, connection ID, and timezone configuration
 * in the proxy database for use by the CloudZero logger.
 *
 * Parameters:
 * - api_key: CloudZero API key for authentication
 * - connection_id: CloudZero connection ID for data submission
 * - timezone: Timezone for date handling (default: UTC)
 *
 * Only admin users can configure CloudZero settings.
 */
export const initCloudzeroSettingsCloudzeroInitPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<InitCloudzeroSettingsCloudzeroInitPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    InitCloudzeroSettingsCloudzeroInitPostResponses,
    InitCloudzeroSettingsCloudzeroInitPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cloudzero/init',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Cloudzero Dry Run Export
 *
 * Perform a dry run export using the CloudZero logger.
 *
 * This endpoint uses the CloudZero logger to perform a dry run export,
 * which returns the data that would be exported without actually sending it to CloudZero.
 *
 * Parameters:
 * - limit: Optional limit on number of records to process (default: 10000)
 *
 * Returns:
 * - usage_data: Sample of the raw usage data (first 50 records)
 * - cbf_data: CloudZero CBF formatted data ready for export
 * - summary: Statistics including total cost, tokens, and record counts
 *
 * Only admin users can perform CloudZero exports.
 */
export const cloudzeroDryRunExportCloudzeroDryRunPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CloudzeroDryRunExportCloudzeroDryRunPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CloudzeroDryRunExportCloudzeroDryRunPostResponses,
    CloudzeroDryRunExportCloudzeroDryRunPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cloudzero/dry-run',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Cloudzero Export
 *
 * Perform an actual export using the CloudZero logger.
 *
 * This endpoint uses the CloudZero logger to export usage data to CloudZero AnyCost API.
 *
 * Parameters:
 * - limit: Optional limit on number of records to export
 * - operation: CloudZero operation type ("replace_hourly" or "sum", default: "replace_hourly")
 *
 * Only admin users can perform CloudZero exports.
 */
export const cloudzeroExportCloudzeroExportPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CloudzeroExportCloudzeroExportPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CloudzeroExportCloudzeroExportPostResponses,
    CloudzeroExportCloudzeroExportPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cloudzero/export',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Cache Ping
 *
 * Endpoint for checking if cache can be pinged
 */
export const cachePingCachePingGet = <ThrowOnError extends boolean = false>(
  options?: Options<CachePingCachePingGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    CachePingCachePingGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cache/ping',
    ...options,
  });

/**
 * Cache Delete
 *
 * Endpoint for deleting a key from the cache. All responses from litellm proxy have `x-litellm-cache-key` in the headers
 *
 * Parameters:
 * - **keys**: *Optional[List[str]]* - A list of keys to delete from the cache. Example {"keys": ["key1", "key2"]}
 *
 * ```shell
 * curl -X POST "http://0.0.0.0:4000/cache/delete"     -H "Authorization: Bearer sk-1234"     -d '{"keys": ["key1", "key2"]}'
 * ```
 */
export const cacheDeleteCacheDeletePost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<CacheDeleteCacheDeletePostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CacheDeleteCacheDeletePostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cache/delete',
    ...options,
  });

/**
 * Cache Redis Info
 *
 * Endpoint for getting /redis/info
 */
export const cacheRedisInfoCacheRedisInfoGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<CacheRedisInfoCacheRedisInfoGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    CacheRedisInfoCacheRedisInfoGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cache/redis/info',
    ...options,
  });

/**
 * Cache Flushall
 *
 * A function to flush all items from the cache. (All items will be deleted from the cache with this)
 * Raises HTTPException if the cache is not initialized or if the cache type does not support flushing.
 * Returns a dictionary with the status of the operation.
 *
 * Usage:
 * ```
 * curl -X POST http://0.0.0.0:4000/cache/flushall -H "Authorization: Bearer sk-1234"
 * ```
 */
export const cacheFlushallCacheFlushallPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<CacheFlushallCacheFlushallPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CacheFlushallCacheFlushallPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cache/flushall',
    ...options,
  });

/**
 * List Guardrails
 *
 * List the guardrails that are available on the proxy server
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/guardrails/list" -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "guardrails": [
 * {
 * "guardrail_name": "bedrock-pre-guard",
 * "guardrail_info": {
 * "params": [
 * {
 * "name": "toxicity_score",
 * "type": "float",
 * "description": "Score between 0-1 indicating content toxicity level"
 * },
 * {
 * "name": "pii_detection",
 * "type": "boolean"
 * }
 * ]
 * }
 * }
 * ]
 * }
 * ```
 */
export const listGuardrailsGuardrailsListGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListGuardrailsGuardrailsListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListGuardrailsGuardrailsListGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/guardrails/list',
    ...options,
  });

/**
 * List Guardrails V2
 *
 * List the guardrails that are available in the database using GuardrailRegistry
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/v2/guardrails/list" -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "guardrails": [
 * {
 * "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",
 * "guardrail_name": "my-bedrock-guard",
 * "litellm_params": {
 * "guardrail": "bedrock",
 * "mode": "pre_call",
 * "guardrailIdentifier": "ff6ujrregl1q",
 * "guardrailVersion": "DRAFT",
 * "default_on": true
 * },
 * "guardrail_info": {
 * "description": "Bedrock content moderation guardrail"
 * }
 * }
 * ]
 * }
 * ```
 */
export const listGuardrailsV2V2GuardrailsListGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListGuardrailsV2V2GuardrailsListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListGuardrailsV2V2GuardrailsListGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v2/guardrails/list',
    ...options,
  });

/**
 * Create Guardrail
 *
 * Create a new guardrail
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X POST "http://localhost:4000/guardrails" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "guardrail": {
 * "guardrail_name": "my-bedrock-guard",
 * "litellm_params": {
 * "guardrail": "bedrock",
 * "mode": "pre_call",
 * "guardrailIdentifier": "ff6ujrregl1q",
 * "guardrailVersion": "DRAFT",
 * "default_on": true
 * },
 * "guardrail_info": {
 * "description": "Bedrock content moderation guardrail"
 * }
 * }
 * }'
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",
 * "guardrail_name": "my-bedrock-guard",
 * "litellm_params": {
 * "guardrail": "bedrock",
 * "mode": "pre_call",
 * "guardrailIdentifier": "ff6ujrregl1q",
 * "guardrailVersion": "DRAFT",
 * "default_on": true
 * },
 * "guardrail_info": {
 * "description": "Bedrock content moderation guardrail"
 * },
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T12:34:56.789Z"
 * }
 * ```
 */
export const createGuardrailGuardrailsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CreateGuardrailGuardrailsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateGuardrailGuardrailsPostResponses,
    CreateGuardrailGuardrailsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/guardrails',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Delete Guardrail
 *
 * Delete a guardrail
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X DELETE "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \
 * -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "message": "Guardrail 123e4567-e89b-12d3-a456-426614174000 deleted successfully"
 * }
 * ```
 */
export const deleteGuardrailGuardrailsGuardrailIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DeleteGuardrailGuardrailsGuardrailIdDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    DeleteGuardrailGuardrailsGuardrailIdDeleteResponses,
    DeleteGuardrailGuardrailsGuardrailIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/guardrails/{guardrail_id}',
    ...options,
  });

/**
 * Get Guardrail Info
 *
 * Get detailed information about a specific guardrail by ID
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000/info" \
 * -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",
 * "guardrail_name": "my-bedrock-guard",
 * "litellm_params": {
 * "guardrail": "bedrock",
 * "mode": "pre_call",
 * "guardrailIdentifier": "ff6ujrregl1q",
 * "guardrailVersion": "DRAFT",
 * "default_on": true
 * },
 * "guardrail_info": {
 * "description": "Bedrock content moderation guardrail"
 * },
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T12:34:56.789Z"
 * }
 * ```
 */
export const getGuardrailInfoGuardrailsGuardrailIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetGuardrailInfoGuardrailsGuardrailIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetGuardrailInfoGuardrailsGuardrailIdGetResponses,
    GetGuardrailInfoGuardrailsGuardrailIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/guardrails/{guardrail_id}',
    ...options,
  });

/**
 * Patch Guardrail
 *
 * Partially update an existing guardrail
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * This endpoint allows updating specific fields of a guardrail without sending the entire object.
 * Only the following fields can be updated:
 * - guardrail_name: The name of the guardrail
 * - default_on: Whether the guardrail is enabled by default
 * - guardrail_info: Additional information about the guardrail
 *
 * Example Request:
 * ```bash
 * curl -X PATCH "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "guardrail_name": "updated-name",
 * "default_on": true,
 * "guardrail_info": {
 * "description": "Updated description"
 * }
 * }'
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",
 * "guardrail_name": "updated-name",
 * "litellm_params": {
 * "guardrail": "bedrock",
 * "mode": "pre_call",
 * "guardrailIdentifier": "ff6ujrregl1q",
 * "guardrailVersion": "DRAFT",
 * "default_on": true
 * },
 * "guardrail_info": {
 * "description": "Updated description"
 * },
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T14:22:33.456Z"
 * }
 * ```
 */
export const patchGuardrailGuardrailsGuardrailIdPatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<PatchGuardrailGuardrailsGuardrailIdPatchData, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    PatchGuardrailGuardrailsGuardrailIdPatchResponses,
    PatchGuardrailGuardrailsGuardrailIdPatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/guardrails/{guardrail_id}',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Guardrail
 *
 * Update an existing guardrail
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X PUT "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "guardrail": {
 * "guardrail_name": "updated-bedrock-guard",
 * "litellm_params": {
 * "guardrail": "bedrock",
 * "mode": "pre_call",
 * "guardrailIdentifier": "ff6ujrregl1q",
 * "guardrailVersion": "1.0",
 * "default_on": true
 * },
 * "guardrail_info": {
 * "description": "Updated Bedrock content moderation guardrail"
 * }
 * }
 * }'
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",
 * "guardrail_name": "updated-bedrock-guard",
 * "litellm_params": {
 * "guardrail": "bedrock",
 * "mode": "pre_call",
 * "guardrailIdentifier": "ff6ujrregl1q",
 * "guardrailVersion": "1.0",
 * "default_on": true
 * },
 * "guardrail_info": {
 * "description": "Updated Bedrock content moderation guardrail"
 * },
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T13:45:12.345Z"
 * }
 * ```
 */
export const updateGuardrailGuardrailsGuardrailIdPut = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UpdateGuardrailGuardrailsGuardrailIdPutData, ThrowOnError>,
) =>
  (options.client ?? client).put<
    UpdateGuardrailGuardrailsGuardrailIdPutResponses,
    UpdateGuardrailGuardrailsGuardrailIdPutErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/guardrails/{guardrail_id}',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Guardrail Info
 *
 * Get detailed information about a specific guardrail by ID
 *
 *  [Guardrail docs](https://docs.litellm.ai/docs/proxy/guardrails/quick_start)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/guardrails/123e4567-e89b-12d3-a456-426614174000/info" \
 * -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "guardrail_id": "123e4567-e89b-12d3-a456-426614174000",
 * "guardrail_name": "my-bedrock-guard",
 * "litellm_params": {
 * "guardrail": "bedrock",
 * "mode": "pre_call",
 * "guardrailIdentifier": "ff6ujrregl1q",
 * "guardrailVersion": "DRAFT",
 * "default_on": true
 * },
 * "guardrail_info": {
 * "description": "Bedrock content moderation guardrail"
 * },
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T12:34:56.789Z"
 * }
 * ```
 */
export const getGuardrailInfoGuardrailsGuardrailIdInfoGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GetGuardrailInfoGuardrailsGuardrailIdInfoGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    GetGuardrailInfoGuardrailsGuardrailIdInfoGetResponses,
    GetGuardrailInfoGuardrailsGuardrailIdInfoGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/guardrails/{guardrail_id}/info',
    ...options,
  });

/**
 * Get Guardrail Ui Settings
 *
 * Get the UI settings for the guardrails
 *
 * Returns:
 * - Supported entities for guardrails
 * - Supported modes for guardrails
 * - PII entity categories for UI organization
 * - Content filter settings (patterns and categories)
 */
export const getGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetGuardrailUiSettingsGuardrailsUiAddGuardrailSettingsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/guardrails/ui/add_guardrail_settings',
    ...options,
  });

/**
 * Validate Blocked Words File
 *
 * Validate a blocked_words YAML file content.
 *
 * Args:
 * request: Dictionary with 'file_content' key containing the YAML string
 *
 * Returns:
 * Dictionary with 'valid' boolean and either 'message'/'errors' depending on result
 *
 * Example Request:
 * ```json
 * {
 * "file_content": "blocked_words:\n  - keyword: \"test\"\n    action: \"BLOCK\""
 * }
 * ```
 *
 * Example Success Response:
 * ```json
 * {
 * "valid": true,
 * "message": "Valid YAML file with 2 blocked words"
 * }
 * ```
 *
 * Example Error Response:
 * ```json
 * {
 * "valid": false,
 * "errors": ["Entry 0: missing 'action' field"]
 * }
 * ```
 */
export const validateBlockedWordsFileGuardrailsValidateBlockedWordsFilePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostResponses,
    ValidateBlockedWordsFileGuardrailsValidateBlockedWordsFilePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/guardrails/validate_blocked_words_file',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Provider Specific Params
 *
 * Get provider-specific parameters for different guardrail types.
 *
 * Returns a dictionary mapping guardrail providers to their specific parameters,
 * including parameter names, descriptions, and whether they are required.
 *
 * Example Response:
 * ```json
 * {
 * "bedrock": {
 * "guardrailIdentifier": {
 * "description": "The ID of your guardrail on Bedrock",
 * "required": true,
 * "type": null
 * },
 * "guardrailVersion": {
 * "description": "The version of your Bedrock guardrail (e.g., DRAFT or version number)",
 * "required": true,
 * "type": null
 * }
 * },
 * "azure_content_safety_text_moderation": {
 * "api_key": {
 * "description": "API key for the Azure Content Safety Text Moderation guardrail",
 * "required": false,
 * "type": null
 * },
 * "optional_params": {
 * "description": "Optional parameters for the Azure Content Safety Text Moderation guardrail",
 * "required": true,
 * "type": "nested",
 * "fields": {
 * "severity_threshold": {
 * "description": "Severity threshold for the Azure Content Safety Text Moderation guardrail across all categories",
 * "required": false,
 * "type": null
 * },
 * "categories": {
 * "description": "Categories to scan for the Azure Content Safety Text Moderation guardrail",
 * "required": false,
 * "type": "multiselect",
 * "options": ["Hate", "SelfHarm", "Sexual", "Violence"],
 * "default_value": None
 * }
 * }
 * }
 * }
 * }
 * ```
 */
export const getProviderSpecificParamsGuardrailsUiProviderSpecificParamsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetProviderSpecificParamsGuardrailsUiProviderSpecificParamsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/guardrails/ui/provider_specific_params',
    ...options,
  });

/**
 * Apply Guardrail
 *
 * Apply a guardrail to text input and return the processed result.
 *
 * This endpoint allows testing guardrails by applying them to custom text inputs.
 */
export const applyGuardrailApplyGuardrailPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<ApplyGuardrailApplyGuardrailPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    ApplyGuardrailApplyGuardrailPostResponses,
    ApplyGuardrailApplyGuardrailPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/apply_guardrail',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Apply Guardrail
 *
 * Apply a guardrail to text input and return the processed result.
 *
 * This endpoint allows testing guardrails by applying them to custom text inputs.
 */
export const applyGuardrailGuardrailsApplyGuardrailPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    ApplyGuardrailGuardrailsApplyGuardrailPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    ApplyGuardrailGuardrailsApplyGuardrailPostResponses,
    ApplyGuardrailGuardrailsApplyGuardrailPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/guardrails/apply_guardrail',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * List Search Tools
 *
 * List all search tools that are available in the database.
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/search_tools/list" -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "search_tools": [
 * {
 * "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",
 * "search_tool_name": "litellm-search",
 * "litellm_params": {
 * "search_provider": "perplexity",
 * "api_key": "sk-***",
 * "api_base": "https://api.perplexity.ai"
 * },
 * "search_tool_info": {
 * "description": "Perplexity search tool"
 * },
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T12:34:56.789Z"
 * }
 * ]
 * }
 * ```
 */
export const listSearchToolsSearchToolsListGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListSearchToolsSearchToolsListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListSearchToolsSearchToolsListGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/search_tools/list',
    ...options,
  });

/**
 * Create Search Tool
 *
 * Create a new search tool.
 *
 * Example Request:
 * ```bash
 * curl -X POST "http://localhost:4000/search_tools" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "search_tool": {
 * "search_tool_name": "litellm-search",
 * "litellm_params": {
 * "search_provider": "perplexity",
 * "api_key": "sk-..."
 * },
 * "search_tool_info": {
 * "description": "Perplexity search tool"
 * }
 * }
 * }'
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",
 * "search_tool_name": "litellm-search",
 * "litellm_params": {
 * "search_provider": "perplexity",
 * "api_key": "sk-..."
 * },
 * "search_tool_info": {
 * "description": "Perplexity search tool"
 * },
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T12:34:56.789Z"
 * }
 * ```
 */
export const createSearchToolSearchToolsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CreateSearchToolSearchToolsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateSearchToolSearchToolsPostResponses,
    CreateSearchToolSearchToolsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/search_tools',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Delete Search Tool
 *
 * Delete a search tool.
 *
 * Example Request:
 * ```bash
 * curl -X DELETE "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \
 * -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "message": "Search tool 123e4567-e89b-12d3-a456-426614174000 deleted successfully",
 * "search_tool_name": "litellm-search"
 * }
 * ```
 */
export const deleteSearchToolSearchToolsSearchToolIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DeleteSearchToolSearchToolsSearchToolIdDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    DeleteSearchToolSearchToolsSearchToolIdDeleteResponses,
    DeleteSearchToolSearchToolsSearchToolIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/search_tools/{search_tool_id}',
    ...options,
  });

/**
 * Get Search Tool Info
 *
 * Get detailed information about a specific search tool by ID.
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \
 * -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",
 * "search_tool_name": "litellm-search",
 * "litellm_params": {
 * "search_provider": "perplexity",
 * "api_key": "sk-***"
 * },
 * "search_tool_info": {
 * "description": "Perplexity search tool"
 * },
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T12:34:56.789Z"
 * }
 * ```
 */
export const getSearchToolInfoSearchToolsSearchToolIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GetSearchToolInfoSearchToolsSearchToolIdGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    GetSearchToolInfoSearchToolsSearchToolIdGetResponses,
    GetSearchToolInfoSearchToolsSearchToolIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/search_tools/{search_tool_id}',
    ...options,
  });

/**
 * Update Search Tool
 *
 * Update an existing search tool.
 *
 * Example Request:
 * ```bash
 * curl -X PUT "http://localhost:4000/search_tools/123e4567-e89b-12d3-a456-426614174000" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "search_tool": {
 * "search_tool_name": "updated-search",
 * "litellm_params": {
 * "search_provider": "perplexity",
 * "api_key": "sk-new-key"
 * },
 * "search_tool_info": {
 * "description": "Updated search tool"
 * }
 * }
 * }'
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "search_tool_id": "123e4567-e89b-12d3-a456-426614174000",
 * "search_tool_name": "updated-search",
 * "litellm_params": {
 * "search_provider": "perplexity",
 * "api_key": "sk-new-key"
 * },
 * "search_tool_info": {
 * "description": "Updated search tool"
 * },
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T13:45:12.345Z"
 * }
 * ```
 */
export const updateSearchToolSearchToolsSearchToolIdPut = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    UpdateSearchToolSearchToolsSearchToolIdPutData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).put<
    UpdateSearchToolSearchToolsSearchToolIdPutResponses,
    UpdateSearchToolSearchToolsSearchToolIdPutErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/search_tools/{search_tool_id}',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Test Search Tool Connection
 *
 * Test connection to a search provider with the given configuration.
 *
 * Makes a simple test search query to verify the API key and configuration are valid.
 *
 * Example Request:
 * ```bash
 * curl -X POST "http://localhost:4000/search_tools/test_connection" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "litellm_params": {
 * "search_provider": "perplexity",
 * "api_key": "sk-..."
 * }
 * }'
 * ```
 *
 * Example Response (Success):
 * ```json
 * {
 * "status": "success",
 * "message": "Successfully connected to perplexity search provider",
 * "test_query": "test",
 * "results_count": 5
 * }
 * ```
 *
 * Example Response (Failure):
 * ```json
 * {
 * "status": "error",
 * "message": "Authentication failed: Invalid API key",
 * "error_type": "AuthenticationError"
 * }
 * ```
 */
export const testSearchToolConnectionSearchToolsTestConnectionPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    TestSearchToolConnectionSearchToolsTestConnectionPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    TestSearchToolConnectionSearchToolsTestConnectionPostResponses,
    TestSearchToolConnectionSearchToolsTestConnectionPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/search_tools/test_connection',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Available Search Providers
 *
 * Get the list of available search providers with their configuration fields.
 *
 * Auto-discovers search providers and their UI-friendly names from transformation configs.
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/search_tools/ui/available_providers" \
 * -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "providers": [
 * {
 * "provider_name": "perplexity",
 * "ui_friendly_name": "Perplexity"
 * },
 * {
 * "provider_name": "tavily",
 * "ui_friendly_name": "Tavily"
 * }
 * ]
 * }
 * ```
 */
export const getAvailableSearchProvidersSearchToolsUiAvailableProvidersGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetAvailableSearchProvidersSearchToolsUiAvailableProvidersGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/search_tools/ui/available_providers',
    ...options,
  });

/**
 * List Prompts
 *
 * List the prompts that are available on the proxy server
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/prompts/list" -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "prompts": [
 * {
 * "prompt_id": "my_prompt_id",
 * "litellm_params": {
 * "prompt_id": "my_prompt_id",
 * "prompt_integration": "dotprompt",
 * "prompt_directory": "/path/to/prompts"
 * },
 * "prompt_info": {
 * "prompt_type": "config"
 * },
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T12:34:56.789Z"
 * }
 * ]
 * }
 * ```
 */
export const listPromptsPromptsListGet = <ThrowOnError extends boolean = false>(
  options?: Options<ListPromptsPromptsListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListPromptsPromptsListGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/prompts/list',
    ...options,
  });

/**
 * Get Prompt Versions
 *
 * Get all versions of a specific prompt by base prompt ID
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/prompts/jack_success/versions" \
 * -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "prompts": [
 * {
 * "prompt_id": "jack_success.v1",
 * "litellm_params": {...},
 * "prompt_info": {"prompt_type": "db"},
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T12:34:56.789Z"
 * },
 * {
 * "prompt_id": "jack_success.v2",
 * "litellm_params": {...},
 * "prompt_info": {"prompt_type": "db"},
 * "created_at": "2023-11-09T13:45:12.345Z",
 * "updated_at": "2023-11-09T13:45:12.345Z"
 * }
 * ]
 * }
 * ```
 */
export const getPromptVersionsPromptsPromptIdVersionsGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GetPromptVersionsPromptsPromptIdVersionsGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    GetPromptVersionsPromptsPromptIdVersionsGetResponses,
    GetPromptVersionsPromptsPromptIdVersionsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/prompts/{prompt_id}/versions',
    ...options,
  });

/**
 * Get Prompt Info
 *
 * Get detailed information about a specific prompt by ID, including prompt content
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/prompts/my_prompt_id/info" \
 * -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "prompt_id": "my_prompt_id",
 * "litellm_params": {
 * "prompt_id": "my_prompt_id",
 * "prompt_integration": "dotprompt",
 * "prompt_directory": "/path/to/prompts"
 * },
 * "prompt_info": {
 * "prompt_type": "config"
 * },
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T12:34:56.789Z",
 * "content": "System: You are a helpful assistant.
 *
 * User: {{user_message}}"
 * }
 * ```
 */
export const getPromptInfoPromptsPromptIdInfoGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetPromptInfoPromptsPromptIdInfoGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetPromptInfoPromptsPromptIdInfoGetResponses,
    GetPromptInfoPromptsPromptIdInfoGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/prompts/{prompt_id}/info',
    ...options,
  });

/**
 * Delete Prompt
 *
 * Delete a prompt
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * Example Request:
 * ```bash
 * curl -X DELETE "http://localhost:4000/prompts/my_prompt_id" \
 * -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "message": "Prompt my_prompt_id deleted successfully"
 * }
 * ```
 */
export const deletePromptPromptsPromptIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeletePromptPromptsPromptIdDeleteData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    DeletePromptPromptsPromptIdDeleteResponses,
    DeletePromptPromptsPromptIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/prompts/{prompt_id}',
    ...options,
  });

/**
 * Get Prompt Info
 *
 * Get detailed information about a specific prompt by ID, including prompt content
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/prompts/my_prompt_id/info" \
 * -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "prompt_id": "my_prompt_id",
 * "litellm_params": {
 * "prompt_id": "my_prompt_id",
 * "prompt_integration": "dotprompt",
 * "prompt_directory": "/path/to/prompts"
 * },
 * "prompt_info": {
 * "prompt_type": "config"
 * },
 * "created_at": "2023-11-09T12:34:56.789Z",
 * "updated_at": "2023-11-09T12:34:56.789Z",
 * "content": "System: You are a helpful assistant.
 *
 * User: {{user_message}}"
 * }
 * ```
 */
export const getPromptInfoPromptsPromptIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetPromptInfoPromptsPromptIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetPromptInfoPromptsPromptIdGetResponses,
    GetPromptInfoPromptsPromptIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/prompts/{prompt_id}',
    ...options,
  });

/**
 * Patch Prompt
 *
 * Partially update an existing prompt
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * This endpoint allows updating specific fields of a prompt without sending the entire object.
 * Only the following fields can be updated:
 * - litellm_params: LiteLLM parameters for the prompt
 * - prompt_info: Additional information about the prompt
 *
 * Example Request:
 * ```bash
 * curl -X PATCH "http://localhost:4000/prompts/my_prompt_id" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "prompt_info": {
 * "prompt_type": "db"
 * }
 * }'
 * ```
 */
export const patchPromptPromptsPromptIdPatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<PatchPromptPromptsPromptIdPatchData, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    PatchPromptPromptsPromptIdPatchResponses,
    PatchPromptPromptsPromptIdPatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/prompts/{prompt_id}',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Prompt
 *
 * Update an existing prompt
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * Example Request:
 * ```bash
 * curl -X PUT "http://localhost:4000/prompts/my_prompt_id" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "prompt_id": "my_prompt",
 * "litellm_params": {
 * "prompt_id": "my_prompt",
 * "prompt_integration": "dotprompt",
 * "prompt_directory": "/path/to/prompts"
 * },
 * "prompt_info": {
 * "prompt_type": "config"
 * }
 * }
 * }'
 * ```
 */
export const updatePromptPromptsPromptIdPut = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UpdatePromptPromptsPromptIdPutData, ThrowOnError>,
) =>
  (options.client ?? client).put<
    UpdatePromptPromptsPromptIdPutResponses,
    UpdatePromptPromptsPromptIdPutErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/prompts/{prompt_id}',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Create Prompt
 *
 * Create a new prompt
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * Example Request:
 * ```bash
 * curl -X POST "http://localhost:4000/prompts" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "prompt_id": "my_prompt",
 * "litellm_params": {
 * "prompt_id": "json_prompt",
 * "prompt_integration": "dotprompt",
 * ### EITHER prompt_directory OR prompt_data MUST BE PROVIDED
 * "prompt_directory": "/path/to/dotprompt/folder",
 * "prompt_data": {"json_prompt": {"content": "This is a prompt", "metadata": {"model": "gpt-4"}}}
 * },
 * "prompt_info": {
 * "prompt_type": "config"
 * }
 * }'
 * ```
 */
export const createPromptPromptsPost = <ThrowOnError extends boolean = false>(
  options: Options<CreatePromptPromptsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreatePromptPromptsPostResponses,
    CreatePromptPromptsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/prompts',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Test Prompt
 *
 * Test a prompt by rendering it with variables and executing an LLM call.
 *
 * This endpoint allows testing prompts before saving them to the database.
 * The response is always streamed.
 *
 *  [Prompt docs](https://docs.litellm.ai/docs/proxy/prompt_management)
 *
 * Example Request:
 * ```bash
 * curl -X POST "http://localhost:4000/prompts/test" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "dotprompt_content": "---\nmodel: gpt-4o\ntemperature: 0.7\n---\n\nUser: Hello {{name}}",
 * "prompt_variables": {
 * "name": "World"
 * }
 * }'
 * ```
 */
export const testPromptPromptsTestPost = <ThrowOnError extends boolean = false>(
  options: Options<TestPromptPromptsTestPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TestPromptPromptsTestPostResponses,
    TestPromptPromptsTestPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/prompts/test',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Convert Prompt File To Json
 *
 * Convert a .prompt file to JSON format.
 *
 * This endpoint accepts a .prompt file upload and returns the equivalent JSON representation
 * that can be stored in a database or used programmatically.
 *
 * Returns the JSON structure with 'content' and 'metadata' fields.
 */
export const convertPromptFileToJsonUtilsDotpromptJsonConverterPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostResponses,
    ConvertPromptFileToJsonUtilsDotpromptJsonConverterPostErrors,
    ThrowOnError
  >({
    ...formDataBodySerializer,
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/utils/dotprompt_json_converter',
    ...options,
    headers: {
      'Content-Type': null,
      ...options.headers,
    },
  });

/**
 * List Callbacks
 *
 * View List of Active Logging Callbacks
 */
export const listCallbacksCallbacksListGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListCallbacksCallbacksListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListCallbacksCallbacksListGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/callbacks/list',
    ...options,
  });

/**
 * Get Callback Configs
 *
 * Get Available Callback Configurations
 *
 * Returns the configuration details for all available logging callbacks,
 * including supported parameters, field types, and descriptions.
 */
export const getCallbackConfigsCallbacksConfigsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetCallbackConfigsCallbacksConfigsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetCallbackConfigsCallbacksConfigsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/callbacks/configs',
    ...options,
  });

/**
 * Get Active Tasks Stats
 *
 * Returns:
 * total_active_tasks: int
 * by_name: { coroutine_name: count }
 */
export const getActiveTasksStatsDebugAsyncioTasksGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetActiveTasksStatsDebugAsyncioTasksGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetActiveTasksStatsDebugAsyncioTasksGetResponses,
    unknown,
    ThrowOnError
  >({ url: '/debug/asyncio-tasks', ...options });

/**
 * Add Allowed Ip
 */
export const addAllowedIpAddAllowedIpPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AddAllowedIpAddAllowedIpPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    AddAllowedIpAddAllowedIpPostResponses,
    AddAllowedIpAddAllowedIpPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/add/allowed_ip',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Delete Allowed Ip
 */
export const deleteAllowedIpDeleteAllowedIpPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteAllowedIpDeleteAllowedIpPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    DeleteAllowedIpDeleteAllowedIpPostResponses,
    DeleteAllowedIpDeleteAllowedIpPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/delete/allowed_ip',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Internal User Settings
 *
 * Get all SSO settings from the litellm_settings configuration.
 * Returns a structured object with values and descriptions for UI display.
 */
export const getInternalUserSettingsGetInternalUserSettingsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetInternalUserSettingsGetInternalUserSettingsGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetInternalUserSettingsGetInternalUserSettingsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/get/internal_user_settings',
    ...options,
  });

/**
 * Get Default Team Settings
 *
 * Get all SSO settings from the litellm_settings configuration.
 * Returns a structured object with values and descriptions for UI display.
 */
export const getDefaultTeamSettingsGetDefaultTeamSettingsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetDefaultTeamSettingsGetDefaultTeamSettingsGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetDefaultTeamSettingsGetDefaultTeamSettingsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/get/default_team_settings',
    ...options,
  });

/**
 * Update Internal User Settings
 *
 * Update the default internal user parameters for SSO users.
 * These settings will be applied to new users who sign in via SSO.
 */
export const updateInternalUserSettingsUpdateInternalUserSettingsPatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    UpdateInternalUserSettingsUpdateInternalUserSettingsPatchData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).patch<
    UpdateInternalUserSettingsUpdateInternalUserSettingsPatchResponses,
    UpdateInternalUserSettingsUpdateInternalUserSettingsPatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/update/internal_user_settings',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Default Team Settings
 *
 * Update the default team parameters for SSO users.
 * These settings will be applied to new teams created from SSO.
 */
export const updateDefaultTeamSettingsUpdateDefaultTeamSettingsPatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).patch<
    UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchResponses,
    UpdateDefaultTeamSettingsUpdateDefaultTeamSettingsPatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/update/default_team_settings',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Sso Settings
 *
 * Get all SSO configuration settings from the dedicated SSO table.
 * Returns a structured object with values and descriptions for UI display.
 */
export const getSsoSettingsGetSsoSettingsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetSsoSettingsGetSsoSettingsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetSsoSettingsGetSsoSettingsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/get/sso_settings',
    ...options,
  });

/**
 * Update Sso Settings
 *
 * Update SSO configuration by saving to the dedicated SSO table.
 */
export const updateSsoSettingsUpdateSsoSettingsPatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UpdateSsoSettingsUpdateSsoSettingsPatchData, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    UpdateSsoSettingsUpdateSsoSettingsPatchResponses,
    UpdateSsoSettingsUpdateSsoSettingsPatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/update/sso_settings',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Ui Theme Settings
 *
 * Get UI theme configuration from the litellm_settings.
 * Returns current logo settings for UI customization.
 *
 * Note: This endpoint is public (no authentication required) so all users can see custom branding.
 * Only the /update/ui_theme_settings endpoint requires authentication for admins to change settings.
 */
export const getUiThemeSettingsGetUiThemeSettingsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetUiThemeSettingsGetUiThemeSettingsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetUiThemeSettingsGetUiThemeSettingsGetResponses,
    unknown,
    ThrowOnError
  >({ url: '/get/ui_theme_settings', ...options });

/**
 * Update Ui Theme Settings
 *
 * Update UI theme configuration.
 * Updates logo settings for the admin UI.
 */
export const updateUiThemeSettingsUpdateUiThemeSettingsPatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    UpdateUiThemeSettingsUpdateUiThemeSettingsPatchData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).patch<
    UpdateUiThemeSettingsUpdateUiThemeSettingsPatchResponses,
    UpdateUiThemeSettingsUpdateUiThemeSettingsPatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/update/ui_theme_settings',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Upload Logo
 *
 * Upload a custom logo for the admin UI.
 * Accepts image files (PNG, JPG, JPEG, SVG) and stores them for use in the UI.
 */
export const uploadLogoUploadLogoPost = <ThrowOnError extends boolean = false>(
  options: Options<UploadLogoUploadLogoPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UploadLogoUploadLogoPostResponses,
    UploadLogoUploadLogoPostErrors,
    ThrowOnError
  >({
    ...formDataBodySerializer,
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/upload/logo',
    ...options,
    headers: {
      'Content-Type': null,
      ...options.headers,
    },
  });

/**
 * List Files
 *
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const listFilesFilesGet = <ThrowOnError extends boolean = false>(
  options?: Options<ListFilesFilesGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListFilesFilesGetResponses,
    ListFilesFilesGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/files',
    ...options,
  });

/**
 * Create File
 *
 * Upload a file that can be used across - Assistants API, Batch API
 * This is the equivalent of POST https://api.openai.com/v1/files
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/create
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"
 *
 * ```
 */
export const createFileFilesPost = <ThrowOnError extends boolean = false>(
  options: Options<CreateFileFilesPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateFileFilesPostResponses,
    CreateFileFilesPostErrors,
    ThrowOnError
  >({
    ...formDataBodySerializer,
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/files',
    ...options,
    headers: {
      'Content-Type': null,
      ...options.headers,
    },
  });

/**
 * List Files
 *
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const listFilesV1FilesGet = <ThrowOnError extends boolean = false>(
  options?: Options<ListFilesV1FilesGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListFilesV1FilesGetResponses,
    ListFilesV1FilesGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/files',
    ...options,
  });

/**
 * Create File
 *
 * Upload a file that can be used across - Assistants API, Batch API
 * This is the equivalent of POST https://api.openai.com/v1/files
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/create
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"
 *
 * ```
 */
export const createFileV1FilesPost = <ThrowOnError extends boolean = false>(
  options: Options<CreateFileV1FilesPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateFileV1FilesPostResponses,
    CreateFileV1FilesPostErrors,
    ThrowOnError
  >({
    ...formDataBodySerializer,
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/files',
    ...options,
    headers: {
      'Content-Type': null,
      ...options.headers,
    },
  });

/**
 * List Files
 *
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/list
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files        -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const listFilesProviderV1FilesGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<ListFilesProviderV1FilesGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    ListFilesProviderV1FilesGetResponses,
    ListFilesProviderV1FilesGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/{provider}/v1/files',
    ...options,
  });

/**
 * Create File
 *
 * Upload a file that can be used across - Assistants API, Batch API
 * This is the equivalent of POST https://api.openai.com/v1/files
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/create
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files         -H "Authorization: Bearer sk-1234"         -F purpose="batch"         -F file="@mydata.jsonl"
 *
 * ```
 */
export const createFileProviderV1FilesPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CreateFileProviderV1FilesPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateFileProviderV1FilesPostResponses,
    CreateFileProviderV1FilesPostErrors,
    ThrowOnError
  >({
    ...formDataBodySerializer,
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/{provider}/v1/files',
    ...options,
    headers: {
      'Content-Type': null,
      ...options.headers,
    },
  });

/**
 * Get File Content
 *
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/content
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contents
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileContentFilesFileIdContentGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetFileContentFilesFileIdContentGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetFileContentFilesFileIdContentGetResponses,
    GetFileContentFilesFileIdContentGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/files/{file_id}/content',
    ...options,
  });

/**
 * Get File Content
 *
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/content
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contents
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileContentV1FilesFileIdContentGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetFileContentV1FilesFileIdContentGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetFileContentV1FilesFileIdContentGetResponses,
    GetFileContentV1FilesFileIdContentGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/files/{file_id}/content',
    ...options,
  });

/**
 * Get File Content
 *
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}/content
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve-contents
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123/content         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileContentProviderV1FilesFileIdContentGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GetFileContentProviderV1FilesFileIdContentGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    GetFileContentProviderV1FilesFileIdContentGetResponses,
    GetFileContentProviderV1FilesFileIdContentGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/{provider}/v1/files/{file_id}/content',
    ...options,
  });

/**
 * Delete File
 *
 * Deletes a specified file. that can be used across - Assistants API, Batch API
 * This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/delete
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"
 *
 * ```
 */
export const deleteFileFilesFileIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteFileFilesFileIdDeleteData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    DeleteFileFilesFileIdDeleteResponses,
    DeleteFileFilesFileIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/files/{file_id}',
    ...options,
  });

/**
 * Get File
 *
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileFilesFileIdGet = <ThrowOnError extends boolean = false>(
  options: Options<GetFileFilesFileIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetFileFilesFileIdGetResponses,
    GetFileFilesFileIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/files/{file_id}',
    ...options,
  });

/**
 * Delete File
 *
 * Deletes a specified file. that can be used across - Assistants API, Batch API
 * This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/delete
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"
 *
 * ```
 */
export const deleteFileV1FilesFileIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteFileV1FilesFileIdDeleteData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    DeleteFileV1FilesFileIdDeleteResponses,
    DeleteFileV1FilesFileIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/files/{file_id}',
    ...options,
  });

/**
 * Get File
 *
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileV1FilesFileIdGet = <ThrowOnError extends boolean = false>(
  options: Options<GetFileV1FilesFileIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetFileV1FilesFileIdGetResponses,
    GetFileV1FilesFileIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/files/{file_id}',
    ...options,
  });

/**
 * Delete File
 *
 * Deletes a specified file. that can be used across - Assistants API, Batch API
 * This is the equivalent of DELETE https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/delete
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123     -X DELETE     -H "Authorization: Bearer $OPENAI_API_KEY"
 *
 * ```
 */
export const deleteFileProviderV1FilesFileIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteFileProviderV1FilesFileIdDeleteData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    DeleteFileProviderV1FilesFileIdDeleteResponses,
    DeleteFileProviderV1FilesFileIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/{provider}/v1/files/{file_id}',
    ...options,
  });

/**
 * Get File
 *
 * Returns information about a specific file. that can be used across - Assistants API, Batch API
 * This is the equivalent of GET https://api.openai.com/v1/files/{file_id}
 *
 * Supports Identical Params as: https://platform.openai.com/docs/api-reference/files/retrieve
 *
 * Example Curl
 * ```
 * curl http://localhost:4000/v1/files/file-abc123         -H "Authorization: Bearer sk-1234"
 *
 * ```
 */
export const getFileProviderV1FilesFileIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetFileProviderV1FilesFileIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetFileProviderV1FilesFileIdGetResponses,
    GetFileProviderV1FilesFileIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/{provider}/v1/files/{file_id}',
    ...options,
  });

/**
 * Get Team Callbacks
 *
 * Get the success/failure callbacks and variables for a team
 *
 * Parameters:
 * - team_id (str, required): The unique identifier for the team
 *
 * Example curl:
 * ```
 * curl -X GET 'http://localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/callback'         -H 'Authorization: Bearer sk-1234'
 * ```
 *
 * This will return the callback settings for the team with id dbe2f686-a686-4896-864a-4c3924458709
 *
 * Returns {
 * "status": "success",
 * "data": {
 * "team_id": team_id,
 * "success_callbacks": team_callback_settings_obj.success_callback,
 * "failure_callbacks": team_callback_settings_obj.failure_callback,
 * "callback_vars": team_callback_settings_obj.callback_vars,
 * },
 * }
 */
export const getTeamCallbacksTeamTeamIdCallbackGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetTeamCallbacksTeamTeamIdCallbackGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetTeamCallbacksTeamTeamIdCallbackGetResponses,
    GetTeamCallbacksTeamTeamIdCallbackGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/{team_id}/callback',
    ...options,
  });

/**
 * Add Team Callbacks
 *
 * Add a success/failure callback to a team
 *
 * Use this if if you want different teams to have different success/failure callbacks
 *
 * Parameters:
 * - callback_name (Literal["langfuse", "langsmith", "gcs"], required): The name of the callback to add
 * - callback_type (Literal["success", "failure", "success_and_failure"], required): The type of callback to add. One of:
 * - "success": Callback for successful LLM calls
 * - "failure": Callback for failed LLM calls
 * - "success_and_failure": Callback for both successful and failed LLM calls
 * - callback_vars (StandardCallbackDynamicParams, required): A dictionary of variables to pass to the callback
 * - langfuse_public_key: The public key for the Langfuse callback
 * - langfuse_secret_key: The secret key for the Langfuse callback
 * - langfuse_secret: The secret for the Langfuse callback
 * - langfuse_host: The host for the Langfuse callback
 * - gcs_bucket_name: The name of the GCS bucket
 * - gcs_path_service_account: The path to the GCS service account
 * - langsmith_api_key: The API key for the Langsmith callback
 * - langsmith_project: The project for the Langsmith callback
 * - langsmith_base_url: The base URL for the Langsmith callback
 *
 * Example curl:
 * ```
 * curl -X POST 'http:/localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/callback'         -H 'Content-Type: application/json'         -H 'Authorization: Bearer sk-1234'         -d '{
 * "callback_name": "langfuse",
 * "callback_type": "success",
 * "callback_vars": {"langfuse_public_key": "pk-lf-xxxx1", "langfuse_secret_key": "sk-xxxxx"}
 *
 * }'
 * ```
 *
 * This means for the team where team_id = dbe2f686-a686-4896-864a-4c3924458709, all LLM calls will be logged to langfuse using the public key pk-lf-xxxx1 and the secret key sk-xxxxx
 */
export const addTeamCallbacksTeamTeamIdCallbackPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AddTeamCallbacksTeamTeamIdCallbackPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    AddTeamCallbacksTeamTeamIdCallbackPostResponses,
    AddTeamCallbacksTeamTeamIdCallbackPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/{team_id}/callback',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Disable Team Logging
 *
 * Disable all logging callbacks for a team
 *
 * Parameters:
 * - team_id (str, required): The unique identifier for the team
 *
 * Example curl:
 * ```
 * curl -X POST 'http://localhost:4000/team/dbe2f686-a686-4896-864a-4c3924458709/disable_logging'         -H 'Authorization: Bearer sk-1234'
 * ```
 */
export const disableTeamLoggingTeamTeamIdDisableLoggingPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DisableTeamLoggingTeamTeamIdDisableLoggingPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    DisableTeamLoggingTeamTeamIdDisableLoggingPostResponses,
    DisableTeamLoggingTeamTeamIdDisableLoggingPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/team/{team_id}/disable_logging',
    ...options,
  });

/**
 * New Budget
 *
 * Create a new budget object. Can apply this to teams, orgs, end-users, keys.
 *
 * Parameters:
 * - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 * - budget_id: Optional[str] - The id of the budget. If not provided, a new id will be generated.
 * - max_budget: Optional[float] - The max budget for the budget.
 * - soft_budget: Optional[float] - The soft budget for the budget.
 * - max_parallel_requests: Optional[int] - The max number of parallel requests for the budget.
 * - tpm_limit: Optional[int] - The tokens per minute limit for the budget.
 * - rpm_limit: Optional[int] - The requests per minute limit for the budget.
 * - model_max_budget: Optional[dict] - Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d", "tpm_limit": 100000, "rpm_limit": 100000}}
 * - budget_reset_at: Optional[datetime] - Datetime when the initial budget is reset. Default is now.
 */
export const newBudgetBudgetNewPost = <ThrowOnError extends boolean = false>(
  options: Options<NewBudgetBudgetNewPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    NewBudgetBudgetNewPostResponses,
    NewBudgetBudgetNewPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/budget/new',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Budget
 *
 * Update an existing budget object.
 *
 * Parameters:
 * - budget_duration: Optional[str] - Budget reset period ("30d", "1h", etc.)
 * - budget_id: Optional[str] - The id of the budget. If not provided, a new id will be generated.
 * - max_budget: Optional[float] - The max budget for the budget.
 * - soft_budget: Optional[float] - The soft budget for the budget.
 * - max_parallel_requests: Optional[int] - The max number of parallel requests for the budget.
 * - tpm_limit: Optional[int] - The tokens per minute limit for the budget.
 * - rpm_limit: Optional[int] - The requests per minute limit for the budget.
 * - model_max_budget: Optional[dict] - Specify max budget for a given model. Example: {"openai/gpt-4o-mini": {"max_budget": 100.0, "budget_duration": "1d", "tpm_limit": 100000, "rpm_limit": 100000}}
 * - budget_reset_at: Optional[datetime] - Update the Datetime when the budget was last reset.
 */
export const updateBudgetBudgetUpdatePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UpdateBudgetBudgetUpdatePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UpdateBudgetBudgetUpdatePostResponses,
    UpdateBudgetBudgetUpdatePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/budget/update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Info Budget
 *
 * Get the budget id specific information
 *
 * Parameters:
 * - budgets: List[str] - The list of budget ids to get information for
 */
export const infoBudgetBudgetInfoPost = <ThrowOnError extends boolean = false>(
  options: Options<InfoBudgetBudgetInfoPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    InfoBudgetBudgetInfoPostResponses,
    InfoBudgetBudgetInfoPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/budget/info',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Budget Settings
 *
 * Get list of configurable params + current value for a budget item + description of each field
 *
 * Used on Admin UI.
 *
 * Query Parameters:
 * - budget_id: str - The budget id to get information for
 */
export const budgetSettingsBudgetSettingsGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<BudgetSettingsBudgetSettingsGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    BudgetSettingsBudgetSettingsGetResponses,
    BudgetSettingsBudgetSettingsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/budget/settings',
    ...options,
  });

/**
 * List Budget
 *
 * List all the created budgets in proxy db. Used on Admin UI.
 */
export const listBudgetBudgetListGet = <ThrowOnError extends boolean = false>(
  options?: Options<ListBudgetBudgetListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListBudgetBudgetListGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/budget/list',
    ...options,
  });

/**
 * Delete Budget
 *
 * Delete budget
 *
 * Parameters:
 * - id: str - The budget id to delete
 */
export const deleteBudgetBudgetDeletePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteBudgetBudgetDeletePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    DeleteBudgetBudgetDeletePostResponses,
    DeleteBudgetBudgetDeletePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/budget/delete',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Patch Model
 *
 * PATCH Endpoint for partial model updates.
 *
 * Only updates the fields specified in the request while preserving other existing values.
 * Follows proper PATCH semantics by only modifying provided fields.
 *
 * Args:
 * model_id: The ID of the model to update
 * patch_data: The fields to update and their new values
 * user_api_key_dict: User authentication information
 *
 * Returns:
 * Updated model information
 *
 * Raises:
 * ProxyException: For various error conditions including authentication and database errors
 */
export const patchModelModelModelIdUpdatePatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<PatchModelModelModelIdUpdatePatchData, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    PatchModelModelModelIdUpdatePatchResponses,
    PatchModelModelModelIdUpdatePatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/model/{model_id}/update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Delete Model
 *
 * Allows deleting models in the model list in the config.yaml
 */
export const deleteModelModelDeletePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteModelModelDeletePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    DeleteModelModelDeletePostResponses,
    DeleteModelModelDeletePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/model/delete',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Add New Model
 *
 * Allows adding new models to the model list in the config.yaml
 */
export const addNewModelModelNewPost = <ThrowOnError extends boolean = false>(
  options: Options<AddNewModelModelNewPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    AddNewModelModelNewPostResponses,
    AddNewModelModelNewPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/model/new',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Model
 *
 * Edit existing model params
 */
export const updateModelModelUpdatePost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UpdateModelModelUpdatePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UpdateModelModelUpdatePostResponses,
    UpdateModelModelUpdatePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/model/update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Public Model Groups
 *
 * Update which model groups are public
 */
export const updatePublicModelGroupsModelGroupMakePublicPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    UpdatePublicModelGroupsModelGroupMakePublicPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    UpdatePublicModelGroupsModelGroupMakePublicPostResponses,
    UpdatePublicModelGroupsModelGroupMakePublicPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/model_group/make_public',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Useful Links
 *
 * Update useful links
 */
export const updateUsefulLinksModelHubUpdateUsefulLinksPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    UpdateUsefulLinksModelHubUpdateUsefulLinksPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    UpdateUsefulLinksModelHubUpdateUsefulLinksPostResponses,
    UpdateUsefulLinksModelHubUpdateUsefulLinksPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/model_hub/update_useful_links',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Create Model Group
 *
 * Create a new access group containing multiple model names.
 *
 * An access group is a named collection of model groups that can be referenced
 * by teams/keys for simplified access control.
 *
 * Example:
 * ```bash
 * curl -X POST 'http://localhost:4000/access_group/new' \
 * -H 'Authorization: Bearer sk-1234' \
 * -H 'Content-Type: application/json' \
 * -d '{
 * "access_group": "production-models",
 * "model_names": ["gpt-4", "claude-3-opus", "gemini-pro"]
 * }'
 * ```
 *
 * Parameters:
 * - access_group: str - The access group name (e.g., "production-models")
 * - model_names: List[str] - List of existing model groups to include
 *
 * Returns:
 * - NewModelGroupResponse with the created access group details
 *
 * Raises:
 * - HTTPException 400: If any model names don't exist
 * - HTTPException 500: If database operations fail
 */
export const createModelGroupAccessGroupNewPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<CreateModelGroupAccessGroupNewPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateModelGroupAccessGroupNewPostResponses,
    CreateModelGroupAccessGroupNewPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/access_group/new',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * List Access Groups
 *
 * List all access groups.
 *
 * Returns a list of all access groups with their model names and deployment counts.
 *
 * Example:
 * ```bash
 * curl -X GET 'http://localhost:4000/access_group/list' \
 * -H 'Authorization: Bearer sk-1234'
 * ```
 *
 * Returns:
 * - ListAccessGroupsResponse with all access groups
 */
export const listAccessGroupsAccessGroupListGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListAccessGroupsAccessGroupListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListAccessGroupsAccessGroupListGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/access_group/list',
    ...options,
  });

/**
 * Get Access Group Info
 *
 * Get information about a specific access group.
 *
 * Example:
 * ```bash
 * curl -X GET 'http://localhost:4000/access_group/production-models/info' \
 * -H 'Authorization: Bearer sk-1234'
 * ```
 *
 * Parameters:
 * - access_group: str - The access group name (URL path parameter)
 *
 * Returns:
 * - AccessGroupInfo with the access group details
 *
 * Raises:
 * - HTTPException 404: If access group not found
 */
export const getAccessGroupInfoAccessGroupAccessGroupInfoGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    GetAccessGroupInfoAccessGroupAccessGroupInfoGetData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).get<
    GetAccessGroupInfoAccessGroupAccessGroupInfoGetResponses,
    GetAccessGroupInfoAccessGroupAccessGroupInfoGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/access_group/{access_group}/info',
    ...options,
  });

/**
 * Update Access Group
 *
 * Update an access group's model names.
 *
 * This will:
 * 1. Remove the access group from all current deployments
 * 2. Add the access group to all deployments for the new model_names list
 *
 * Example:
 * ```bash
 * curl -X PUT 'http://localhost:4000/access_group/production-models/update' \
 * -H 'Authorization: Bearer sk-1234' \
 * -H 'Content-Type: application/json' \
 * -d '{
 * "model_names": ["gpt-4", "claude-3-sonnet"]
 * }'
 * ```
 *
 * Parameters:
 * - access_group: str - The access group name (URL path parameter)
 * - model_names: List[str] - New list of model groups to include
 *
 * Returns:
 * - NewModelGroupResponse with the updated access group details
 *
 * Raises:
 * - HTTPException 400: If any model names don't exist
 * - HTTPException 404: If access group not found
 */
export const updateAccessGroupAccessGroupAccessGroupUpdatePut = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    UpdateAccessGroupAccessGroupAccessGroupUpdatePutData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).put<
    UpdateAccessGroupAccessGroupAccessGroupUpdatePutResponses,
    UpdateAccessGroupAccessGroupAccessGroupUpdatePutErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/access_group/{access_group}/update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Delete Access Group
 *
 * Delete an access group.
 *
 * Removes the access group from all deployments that have it.
 *
 * Example:
 * ```bash
 * curl -X DELETE 'http://localhost:4000/access_group/production-models/delete' \
 * -H 'Authorization: Bearer sk-1234'
 * ```
 *
 * Parameters:
 * - access_group: str - The access group name (URL path parameter)
 *
 * Returns:
 * - DeleteModelGroupResponse with deletion details
 *
 * Raises:
 * - HTTPException 404: If access group not found
 */
export const deleteAccessGroupAccessGroupAccessGroupDeleteDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    DeleteAccessGroupAccessGroupAccessGroupDeleteDeleteData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).delete<
    DeleteAccessGroupAccessGroupAccessGroupDeleteDeleteResponses,
    DeleteAccessGroupAccessGroupAccessGroupDeleteDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/access_group/{access_group}/delete',
    ...options,
  });

/**
 * New Tag
 *
 * Create a new tag.
 *
 * Parameters:
 * - name: str - The name of the tag
 * - description: Optional[str] - Description of what this tag represents
 * - models: List[str] - List of either 'model_id' or 'model_name' allowed for this tag
 * - budget_id: Optional[str] - The id for a budget (tpm/rpm/max budget) for the tag
 *
 * ### IF NO BUDGET ID - CREATE ONE WITH THESE PARAMS ###
 * - max_budget: Optional[float] - Max budget for tag
 * - tpm_limit: Optional[int] - Max tpm limit for tag
 * - rpm_limit: Optional[int] - Max rpm limit for tag
 * - max_parallel_requests: Optional[int] - Max parallel requests for tag
 * - soft_budget: Optional[float] - Get a slack alert when this soft budget is reached
 * - model_max_budget: Optional[dict] - Max budget for a specific model
 * - budget_duration: Optional[str] - Frequency of resetting tag budget
 */
export const newTagTagNewPost = <ThrowOnError extends boolean = false>(
  options: Options<NewTagTagNewPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    NewTagTagNewPostResponses,
    NewTagTagNewPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/tag/new',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Tag
 *
 * Update an existing tag.
 *
 * Parameters:
 * - name: str - The name of the tag to update
 * - description: Optional[str] - Updated description
 * - models: List[str] - Updated list of allowed LLM models
 * - budget_id: Optional[str] - The id for a budget to associate with the tag
 *
 * ### BUDGET UPDATE PARAMS ###
 * - max_budget: Optional[float] - Max budget for tag
 * - tpm_limit: Optional[int] - Max tpm limit for tag
 * - rpm_limit: Optional[int] - Max rpm limit for tag
 * - max_parallel_requests: Optional[int] - Max parallel requests for tag
 * - soft_budget: Optional[float] - Get a slack alert when this soft budget is reached
 * - model_max_budget: Optional[dict] - Max budget for a specific model
 * - budget_duration: Optional[str] - Frequency of resetting tag budget
 */
export const updateTagTagUpdatePost = <ThrowOnError extends boolean = false>(
  options: Options<UpdateTagTagUpdatePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UpdateTagTagUpdatePostResponses,
    UpdateTagTagUpdatePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/tag/update',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Info Tag
 *
 * Get information about specific tags.
 *
 * Parameters:
 * - names: List[str] - List of tag names to get information for
 */
export const infoTagTagInfoPost = <ThrowOnError extends boolean = false>(
  options: Options<InfoTagTagInfoPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    InfoTagTagInfoPostResponses,
    InfoTagTagInfoPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/tag/info',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * List Tags
 *
 * List all available tags with their budget information.
 */
export const listTagsTagListGet = <ThrowOnError extends boolean = false>(
  options?: Options<ListTagsTagListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListTagsTagListGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/tag/list',
    ...options,
  });

/**
 * Delete Tag
 *
 * Delete a tag.
 *
 * Parameters:
 * - name: str - The name of the tag to delete
 */
export const deleteTagTagDeletePost = <ThrowOnError extends boolean = false>(
  options: Options<DeleteTagTagDeletePostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    DeleteTagTagDeletePostResponses,
    DeleteTagTagDeletePostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/tag/delete',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Tag Daily Activity
 *
 * Get daily activity for specific tags or all tags.
 *
 * Args:
 * tags (Optional[str]): Comma-separated list of tags to filter by. If not provided, returns data for all tags.
 * start_date (Optional[str]): Start date for the activity period (YYYY-MM-DD).
 * end_date (Optional[str]): End date for the activity period (YYYY-MM-DD).
 * model (Optional[str]): Filter by model name.
 * api_key (Optional[str]): Filter by API key.
 * page (int): Page number for pagination.
 * page_size (int): Number of items per page.
 *
 * Returns:
 * SpendAnalyticsPaginatedResponse: Paginated response containing daily activity data.
 */
export const getTagDailyActivityTagDailyActivityGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetTagDailyActivityTagDailyActivityGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetTagDailyActivityTagDailyActivityGetResponses,
    GetTagDailyActivityTagDailyActivityGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/tag/daily/activity',
    ...options,
  });

/**
 * Get Cost Discount Config
 *
 * Get current cost discount configuration.
 *
 * Returns the cost_discount_config from litellm_settings.
 */
export const getCostDiscountConfigConfigCostDiscountConfigGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetCostDiscountConfigConfigCostDiscountConfigGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetCostDiscountConfigConfigCostDiscountConfigGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/config/cost_discount_config',
    ...options,
  });

/**
 * Update Cost Discount Config
 *
 * Update cost discount configuration.
 *
 * Updates the cost_discount_config in litellm_settings.
 * Discounts should be between 0 and 1 (e.g., 0.05 = 5% discount).
 *
 * Example:
 * ```json
 * {
 * "vertex_ai": 0.05,
 * "gemini": 0.05,
 * "openai": 0.01
 * }
 * ```
 */
export const updateCostDiscountConfigConfigCostDiscountConfigPatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    UpdateCostDiscountConfigConfigCostDiscountConfigPatchData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).patch<
    UpdateCostDiscountConfigConfigCostDiscountConfigPatchResponses,
    UpdateCostDiscountConfigConfigCostDiscountConfigPatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/config/cost_discount_config',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Router Settings
 *
 * Get router configuration and available settings.
 *
 * Returns:
 * - fields: List of all configurable router settings with their metadata (type, description, default, options)
 * The routing_strategy field includes available options extracted from the Router class
 * - current_values: Current values of router settings from config
 */
export const getRouterSettingsRouterSettingsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetRouterSettingsRouterSettingsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetRouterSettingsRouterSettingsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/router/settings',
    ...options,
  });

/**
 * Get Cache Settings
 *
 * Get cache configuration and available settings.
 *
 * Returns:
 * - fields: List of all configurable cache settings with their metadata (type, description, default, options)
 * - current_values: Current values of cache settings from database
 */
export const getCacheSettingsCacheSettingsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetCacheSettingsCacheSettingsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetCacheSettingsCacheSettingsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cache/settings',
    ...options,
  });

/**
 * Update Cache Settings
 *
 * Save cache settings to database and initialize cache.
 *
 * This endpoint:
 * 1. Encrypts sensitive fields (passwords, etc.)
 * 2. Saves to LiteLLM_CacheConfig table
 * 3. Reinitializes cache with new settings
 */
export const updateCacheSettingsCacheSettingsPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UpdateCacheSettingsCacheSettingsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    UpdateCacheSettingsCacheSettingsPostResponses,
    UpdateCacheSettingsCacheSettingsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cache/settings',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Test Cache Connection
 *
 * Test cache connection with provided credentials.
 *
 * Creates a temporary cache instance and uses its test_connection method
 * to verify the credentials work without affecting global state.
 */
export const testCacheConnectionCacheSettingsTestPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<TestCacheConnectionCacheSettingsTestPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TestCacheConnectionCacheSettingsTestPostResponses,
    TestCacheConnectionCacheSettingsTestPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/cache/settings/test',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Get Distinct User Agent Tags
 *
 * Get all distinct user agent tags up to a maximum of {MAX_TAGS} tags.
 *
 * This endpoint returns all unique user agent tags found in the database,
 * sorted by frequency of usage.
 *
 * Returns:
 * DistinctTagsResponse: List of distinct user agent tags
 */
export const getDistinctUserAgentTagsTagDistinctGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetDistinctUserAgentTagsTagDistinctGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetDistinctUserAgentTagsTagDistinctGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/tag/distinct',
    ...options,
  });

/**
 * Get Daily Active Users
 *
 * Get Daily Active Users (DAU) by tags for the last {MAX_DAYS} days ending on UTC today + 1 day.
 *
 * This endpoint efficiently calculates unique users per tag for each of the last {MAX_DAYS} days
 * using a single optimized SQL query, perfect for dashboard time series visualization.
 *
 * Args:
 * tag_filter: Optional filter to specific tag (legacy)
 * tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)
 *
 * Returns:
 * ActiveUsersAnalyticsResponse: DAU data by tag for each of the last {MAX_DAYS} days
 */
export const getDailyActiveUsersTagDauGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetDailyActiveUsersTagDauGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetDailyActiveUsersTagDauGetResponses,
    GetDailyActiveUsersTagDauGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/tag/dau',
    ...options,
  });

/**
 * Get Weekly Active Users
 *
 * Get Weekly Active Users (WAU) by tags for the last {MAX_WEEKS} weeks ending on UTC today + 1 day.
 *
 * Shows week-by-week breakdown:
 * - Week 1 (Jan 1): Earliest week (7 weeks ago)
 * - Week 2 (Jan 8): Next week (6 weeks ago)
 * - Week 3 (Jan 15): Next week (5 weeks ago)
 * - ... and so on for {MAX_WEEKS} weeks total
 * - Week 7: Most recent week ending on UTC today + 1 day
 *
 * Args:
 * tag_filter: Optional filter to specific tag (legacy)
 * tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)
 *
 * Returns:
 * ActiveUsersAnalyticsResponse: WAU data by tag for each of the last {MAX_WEEKS} weeks with descriptive week labels (e.g., "Week 1 (Jan 1)")
 */
export const getWeeklyActiveUsersTagWauGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetWeeklyActiveUsersTagWauGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetWeeklyActiveUsersTagWauGetResponses,
    GetWeeklyActiveUsersTagWauGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/tag/wau',
    ...options,
  });

/**
 * Get Monthly Active Users
 *
 * Get Monthly Active Users (MAU) by tags for the last {MAX_MONTHS} months ending on UTC today + 1 day.
 *
 * Shows month-by-month breakdown:
 * - Month 1 (Nov): Earliest month (7 months ago, 30-day period)
 * - Month 2 (Dec): Next month (6 months ago)
 * - Month 3 (Jan): Next month (5 months ago)
 * - ... and so on for {MAX_MONTHS} months total
 * - Month 7: Most recent month ending on UTC today + 1 day
 *
 * Args:
 * tag_filter: Optional filter to specific tag (legacy)
 * tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)
 *
 * Returns:
 * ActiveUsersAnalyticsResponse: MAU data by tag for each of the last {MAX_MONTHS} months with descriptive month labels (e.g., "Month 1 (Nov)")
 */
export const getMonthlyActiveUsersTagMauGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetMonthlyActiveUsersTagMauGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetMonthlyActiveUsersTagMauGetResponses,
    GetMonthlyActiveUsersTagMauGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/tag/mau',
    ...options,
  });

/**
 * Get Tag Summary
 *
 * Get summary analytics for tags including unique users, requests, tokens, and spend.
 *
 * Args:
 * start_date: Start date for the analytics period (YYYY-MM-DD)
 * end_date: End date for the analytics period (YYYY-MM-DD)
 * tag_filter: Optional filter to specific tag (legacy)
 * tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)
 *
 * Returns:
 * TagSummaryResponse: Summary analytics data by tag
 */
export const getTagSummaryTagSummaryGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetTagSummaryTagSummaryGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetTagSummaryTagSummaryGetResponses,
    GetTagSummaryTagSummaryGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/tag/summary',
    ...options,
  });

/**
 * Get Per User Analytics
 *
 * Get per-user analytics including successful requests, tokens, and spend by individual users.
 *
 * This endpoint provides usage metrics broken down by individual users based on their
 * tag activity during the last 30 days ending on UTC today + 1 day.
 *
 * Args:
 * tag_filter: Optional filter to specific tag (legacy)
 * tag_filters: Optional filter to multiple specific tags (takes precedence over tag_filter)
 * page: Page number for pagination
 * page_size: Number of items per page
 *
 * Returns:
 * PerUserAnalyticsResponse: Analytics data broken down by individual users for the last 30 days
 */
export const getPerUserAnalyticsTagUserAgentPerUserAnalyticsGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetResponses,
    GetPerUserAnalyticsTagUserAgentPerUserAnalyticsGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/tag/user-agent/per-user-analytics',
    ...options,
  });

/**
 * Get Ui Config
 */
export const getUiConfigLitellmWellKnownLitellmUiConfigGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    GetUiConfigLitellmWellKnownLitellmUiConfigGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    GetUiConfigLitellmWellKnownLitellmUiConfigGetResponses,
    unknown,
    ThrowOnError
  >({ url: '/litellm/.well-known/litellm-ui-config', ...options });

/**
 * Get Ui Config
 */
export const getUiConfigWellKnownLitellmUiConfigGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<GetUiConfigWellKnownLitellmUiConfigGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetUiConfigWellKnownLitellmUiConfigGetResponses,
    unknown,
    ThrowOnError
  >({ url: '/.well-known/litellm-ui-config', ...options });

/**
 * Get Agents
 *
 * Example usage:
 * ```
 * curl -X GET "http://localhost:4000/v1/agents"       -H "Content-Type: application/json"       -H "Authorization: Bearer your-key"     ```
 *
 * Returns: List[AgentResponse]
 */
export const getAgentsV1AgentsGet = <ThrowOnError extends boolean = false>(
  options?: Options<GetAgentsV1AgentsGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    GetAgentsV1AgentsGetResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/agents',
    ...options,
  });

/**
 * Create Agent
 *
 * Create a new agent
 *
 * Example Request:
 * ```bash
 * curl -X POST "http://localhost:4000/agents" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "agent": {
 * "agent_name": "my-custom-agent",
 * "agent_card_params": {
 * "protocolVersion": "1.0",
 * "name": "Hello World Agent",
 * "description": "Just a hello world agent",
 * "url": "http://localhost:9999/",
 * "version": "1.0.0",
 * "defaultInputModes": ["text"],
 * "defaultOutputModes": ["text"],
 * "capabilities": {
 * "streaming": true
 * },
 * "skills": [
 * {
 * "id": "hello_world",
 * "name": "Returns hello world",
 * "description": "just returns hello world",
 * "tags": ["hello world"],
 * "examples": ["hi", "hello world"]
 * }
 * ]
 * },
 * "litellm_params": {
 * "make_public": true
 * }
 * }
 * }'
 * ```
 */
export const createAgentV1AgentsPost = <ThrowOnError extends boolean = false>(
  options: Options<CreateAgentV1AgentsPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    CreateAgentV1AgentsPostResponses,
    CreateAgentV1AgentsPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/agents',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Delete Agent
 *
 * Delete an agent
 *
 * Example Request:
 * ```bash
 * curl -X DELETE "http://localhost:4000/agents/123e4567-e89b-12d3-a456-426614174000" \
 * -H "Authorization: Bearer <your_api_key>"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "message": "Agent 123e4567-e89b-12d3-a456-426614174000 deleted successfully"
 * }
 * ```
 */
export const deleteAgentV1AgentsAgentIdDelete = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DeleteAgentV1AgentsAgentIdDeleteData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    DeleteAgentV1AgentsAgentIdDeleteResponses,
    DeleteAgentV1AgentsAgentIdDeleteErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/agents/{agent_id}',
    ...options,
  });

/**
 * Get Agent By Id
 *
 * Get a specific agent by ID
 *
 * Example Request:
 * ```bash
 * curl -X GET "http://localhost:4000/agents/123e4567-e89b-12d3-a456-426614174000" \
 * -H "Authorization: Bearer <your_api_key>"
 * ```
 */
export const getAgentByIdV1AgentsAgentIdGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<GetAgentByIdV1AgentsAgentIdGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    GetAgentByIdV1AgentsAgentIdGetResponses,
    GetAgentByIdV1AgentsAgentIdGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/agents/{agent_id}',
    ...options,
  });

/**
 * Patch Agent
 *
 * Update an existing agent
 *
 * Example Request:
 * ```bash
 * curl -X PUT "http://localhost:4000/agents/123e4567-e89b-12d3-a456-426614174000" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "agent": {
 * "agent_name": "updated-agent",
 * "agent_card_params": {
 * "protocolVersion": "1.0",
 * "name": "Updated Agent",
 * "description": "Updated description",
 * "url": "http://localhost:9999/",
 * "version": "1.1.0",
 * "defaultInputModes": ["text"],
 * "defaultOutputModes": ["text"],
 * "capabilities": {
 * "streaming": true
 * },
 * "skills": []
 * },
 * "litellm_params": {
 * "make_public": false
 * }
 * }
 * }'
 * ```
 */
export const patchAgentV1AgentsAgentIdPatch = <
  ThrowOnError extends boolean = false,
>(
  options: Options<PatchAgentV1AgentsAgentIdPatchData, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    PatchAgentV1AgentsAgentIdPatchResponses,
    PatchAgentV1AgentsAgentIdPatchErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/agents/{agent_id}',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Update Agent
 *
 * Update an existing agent
 *
 * Example Request:
 * ```bash
 * curl -X PUT "http://localhost:4000/agents/123e4567-e89b-12d3-a456-426614174000" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "agent": {
 * "agent_name": "updated-agent",
 * "agent_card_params": {
 * "protocolVersion": "1.0",
 * "name": "Updated Agent",
 * "description": "Updated description",
 * "url": "http://localhost:9999/",
 * "version": "1.1.0",
 * "defaultInputModes": ["text"],
 * "defaultOutputModes": ["text"],
 * "capabilities": {
 * "streaming": true
 * },
 * "skills": []
 * },
 * "litellm_params": {
 * "make_public": false
 * }
 * }
 * }'
 * ```
 */
export const updateAgentV1AgentsAgentIdPut = <
  ThrowOnError extends boolean = false,
>(
  options: Options<UpdateAgentV1AgentsAgentIdPutData, ThrowOnError>,
) =>
  (options.client ?? client).put<
    UpdateAgentV1AgentsAgentIdPutResponses,
    UpdateAgentV1AgentsAgentIdPutErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/agents/{agent_id}',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Make Agent Public
 *
 * Make an agent publicly discoverable
 *
 * Example Request:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/agents/123e4567-e89b-12d3-a456-426614174000/make_public" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json"
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "agent_id": "123e4567-e89b-12d3-a456-426614174000",
 * "agent_name": "my-custom-agent",
 * "litellm_params": {
 * "make_public": true
 * },
 * "agent_card_params": {...},
 * "created_at": "2025-11-15T10:30:00Z",
 * "updated_at": "2025-11-15T10:35:00Z",
 * "created_by": "user123",
 * "updated_by": "user123"
 * }
 * ```
 */
export const makeAgentPublicV1AgentsAgentIdMakePublicPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<
    MakeAgentPublicV1AgentsAgentIdMakePublicPostData,
    ThrowOnError
  >,
) =>
  (options.client ?? client).post<
    MakeAgentPublicV1AgentsAgentIdMakePublicPostResponses,
    MakeAgentPublicV1AgentsAgentIdMakePublicPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/agents/{agent_id}/make_public',
    ...options,
  });

/**
 * Make Agents Public
 *
 * Make multiple agents publicly discoverable
 *
 * Example Request:
 * ```bash
 * curl -X POST "http://localhost:4000/v1/agents/make_public" \
 * -H "Authorization: Bearer <your_api_key>" \
 * -H "Content-Type: application/json" \
 * -d '{
 * "agent_ids": ["123e4567-e89b-12d3-a456-426614174000", "123e4567-e89b-12d3-a456-426614174001"]
 * }'
 * ```
 *
 * Example Response:
 * ```json
 * {
 * "agent_id": "123e4567-e89b-12d3-a456-426614174000",
 * "agent_name": "my-custom-agent",
 * "litellm_params": {
 * "make_public": true
 * },
 * "agent_card_params": {...},
 * "created_at": "2025-11-15T10:30:00Z",
 * "updated_at": "2025-11-15T10:35:00Z",
 * "created_by": "user123",
 * "updated_by": "user123"
 * }
 * ```
 */
export const makeAgentsPublicV1AgentsMakePublicPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<MakeAgentsPublicV1AgentsMakePublicPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    MakeAgentsPublicV1AgentsMakePublicPostResponses,
    MakeAgentsPublicV1AgentsMakePublicPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/v1/agents/make_public',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Dynamic Mcp Route
 *
 * Handle dynamic MCP server routes like /github_mcp/mcp
 */
export const dynamicMcpRouteMcpServerNameMcpOptions = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DynamicMcpRouteMcpServerNameMcpOptionsData, ThrowOnError>,
) =>
  (options.client ?? client).delete<
    DynamicMcpRouteMcpServerNameMcpOptionsResponses,
    DynamicMcpRouteMcpServerNameMcpOptionsErrors,
    ThrowOnError
  >({ url: '/{mcp_server_name}/mcp', ...options });

/**
 * Dynamic Mcp Route
 *
 * Handle dynamic MCP server routes like /github_mcp/mcp
 */
export const dynamicMcpRouteMcpServerNameMcpOptions2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DynamicMcpRouteMcpServerNameMcpOptions2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<
    DynamicMcpRouteMcpServerNameMcpOptions2Responses,
    DynamicMcpRouteMcpServerNameMcpOptions2Errors,
    ThrowOnError
  >({ url: '/{mcp_server_name}/mcp', ...options });

/**
 * Dynamic Mcp Route
 *
 * Handle dynamic MCP server routes like /github_mcp/mcp
 */
export const dynamicMcpRouteMcpServerNameMcpOptions3 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DynamicMcpRouteMcpServerNameMcpOptions3Data, ThrowOnError>,
) =>
  (options.client ?? client).head<
    DynamicMcpRouteMcpServerNameMcpOptions3Responses,
    DynamicMcpRouteMcpServerNameMcpOptions3Errors,
    ThrowOnError
  >({ url: '/{mcp_server_name}/mcp', ...options });

/**
 * Dynamic Mcp Route
 *
 * Handle dynamic MCP server routes like /github_mcp/mcp
 */
export const dynamicMcpRouteMcpServerNameMcpOptions4 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DynamicMcpRouteMcpServerNameMcpOptions4Data, ThrowOnError>,
) =>
  (options.client ?? client).options<
    DynamicMcpRouteMcpServerNameMcpOptions4Responses,
    DynamicMcpRouteMcpServerNameMcpOptions4Errors,
    ThrowOnError
  >({ url: '/{mcp_server_name}/mcp', ...options });

/**
 * Dynamic Mcp Route
 *
 * Handle dynamic MCP server routes like /github_mcp/mcp
 */
export const dynamicMcpRouteMcpServerNameMcpOptions5 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DynamicMcpRouteMcpServerNameMcpOptions5Data, ThrowOnError>,
) =>
  (options.client ?? client).patch<
    DynamicMcpRouteMcpServerNameMcpOptions5Responses,
    DynamicMcpRouteMcpServerNameMcpOptions5Errors,
    ThrowOnError
  >({ url: '/{mcp_server_name}/mcp', ...options });

/**
 * Dynamic Mcp Route
 *
 * Handle dynamic MCP server routes like /github_mcp/mcp
 */
export const dynamicMcpRouteMcpServerNameMcpOptions6 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DynamicMcpRouteMcpServerNameMcpOptions6Data, ThrowOnError>,
) =>
  (options.client ?? client).post<
    DynamicMcpRouteMcpServerNameMcpOptions6Responses,
    DynamicMcpRouteMcpServerNameMcpOptions6Errors,
    ThrowOnError
  >({ url: '/{mcp_server_name}/mcp', ...options });

/**
 * Dynamic Mcp Route
 *
 * Handle dynamic MCP server routes like /github_mcp/mcp
 */
export const dynamicMcpRouteMcpServerNameMcpOptions7 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<DynamicMcpRouteMcpServerNameMcpOptions7Data, ThrowOnError>,
) =>
  (options.client ?? client).put<
    DynamicMcpRouteMcpServerNameMcpOptions7Responses,
    DynamicMcpRouteMcpServerNameMcpOptions7Errors,
    ThrowOnError
  >({ url: '/{mcp_server_name}/mcp', ...options });

/**
 * List Tool Rest Api
 *
 * List all available tools with information about the server they belong to.
 *
 * Example response:
 * {
 * "tools": [
 * {
 * "name": "create_zap",
 * "description": "Create a new zap",
 * "inputSchema": "tool_input_schema",
 * "mcp_info": {
 * "server_name": "zapier",
 * "logo_url": "https://www.zapier.com/logo.png",
 * }
 * }
 * ],
 * "error": null,
 * "message": "Successfully retrieved tools"
 * }
 */
export const listToolRestApiMcpRestToolsListGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<ListToolRestApiMcpRestToolsListGetData, ThrowOnError>,
) =>
  (options?.client ?? client).get<
    ListToolRestApiMcpRestToolsListGetResponses,
    ListToolRestApiMcpRestToolsListGetErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/mcp-rest/tools/list',
    ...options,
  });

/**
 * Call Tool Rest Api
 *
 * REST API to call a specific MCP tool with the provided arguments
 */
export const callToolRestApiMcpRestToolsCallPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<CallToolRestApiMcpRestToolsCallPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    CallToolRestApiMcpRestToolsCallPostResponses,
    unknown,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/mcp-rest/tools/call',
    ...options,
  });

/**
 * Test Connection
 *
 * Test if we can connect to the provided MCP server before adding it
 */
export const testConnectionMcpRestTestConnectionPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<TestConnectionMcpRestTestConnectionPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TestConnectionMcpRestTestConnectionPostResponses,
    TestConnectionMcpRestTestConnectionPostErrors,
    ThrowOnError
  >({
    url: '/mcp-rest/test/connection',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Test Tools List
 *
 * Preview tools available from MCP server before adding it
 */
export const testToolsListMcpRestTestToolsListPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<TestToolsListMcpRestTestToolsListPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TestToolsListMcpRestTestToolsListPostResponses,
    TestToolsListMcpRestTestToolsListPostErrors,
    ThrowOnError
  >({
    security: [{ name: 'x-litellm-api-key', type: 'apiKey' }],
    url: '/mcp-rest/test/tools/list',
    ...options,
    headers: {
      'Content-Type': 'application/json',
      ...options.headers,
    },
  });

/**
 * Authorize
 */
export const authorizeAuthorizeGet = <ThrowOnError extends boolean = false>(
  options: Options<AuthorizeAuthorizeGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    AuthorizeAuthorizeGetResponses,
    AuthorizeAuthorizeGetErrors,
    ThrowOnError
  >({ url: '/authorize', ...options });

/**
 * Authorize
 */
export const authorizeMcpServerNameAuthorizeGet = <
  ThrowOnError extends boolean = false,
>(
  options: Options<AuthorizeMcpServerNameAuthorizeGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    AuthorizeMcpServerNameAuthorizeGetResponses,
    AuthorizeMcpServerNameAuthorizeGetErrors,
    ThrowOnError
  >({ url: '/{mcp_server_name}/authorize', ...options });

/**
 * Token Endpoint
 *
 * Accept the authorization code from client and exchange it for OAuth token.
 * Supports PKCE flow by forwarding code_verifier to upstream provider.
 *
 * 1. Call the token endpoint with PKCE parameters
 * 2. Store the user's token in the db - and generate a LiteLLM virtual key
 * 3. Return the token
 * 4. Return a virtual key in this response
 */
export const tokenEndpointTokenPost = <ThrowOnError extends boolean = false>(
  options: Options<TokenEndpointTokenPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TokenEndpointTokenPostResponses,
    TokenEndpointTokenPostErrors,
    ThrowOnError
  >({
    ...urlSearchParamsBodySerializer,
    url: '/token',
    ...options,
    headers: {
      'Content-Type': 'application/x-www-form-urlencoded',
      ...options.headers,
    },
  });

/**
 * Token Endpoint
 *
 * Accept the authorization code from client and exchange it for OAuth token.
 * Supports PKCE flow by forwarding code_verifier to upstream provider.
 *
 * 1. Call the token endpoint with PKCE parameters
 * 2. Store the user's token in the db - and generate a LiteLLM virtual key
 * 3. Return the token
 * 4. Return a virtual key in this response
 */
export const tokenEndpointMcpServerNameTokenPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<TokenEndpointMcpServerNameTokenPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    TokenEndpointMcpServerNameTokenPostResponses,
    TokenEndpointMcpServerNameTokenPostErrors,
    ThrowOnError
  >({
    ...urlSearchParamsBodySerializer,
    url: '/{mcp_server_name}/token',
    ...options,
    headers: {
      'Content-Type': 'application/x-www-form-urlencoded',
      ...options.headers,
    },
  });

/**
 * Callback
 */
export const callbackCallbackGet = <ThrowOnError extends boolean = false>(
  options: Options<CallbackCallbackGetData, ThrowOnError>,
) =>
  (options.client ?? client).get<
    CallbackCallbackGetResponses,
    CallbackCallbackGetErrors,
    ThrowOnError
  >({ url: '/callback', ...options });

/**
 * Oauth Protected Resource Mcp
 */
export const oauthProtectedResourceMcpWellKnownOauthProtectedResourceGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetResponses,
    OauthProtectedResourceMcpWellKnownOauthProtectedResourceGetErrors,
    ThrowOnError
  >({ url: '/.well-known/oauth-protected-resource', ...options });

/**
 * Oauth Protected Resource Mcp
 */
export const oauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGet =
  <ThrowOnError extends boolean = false>(
    options: Options<
      OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetData,
      ThrowOnError
    >,
  ) =>
    (options.client ?? client).get<
      OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetResponses,
      OauthProtectedResourceMcpWellKnownOauthProtectedResourceMcpServerNameMcpGetErrors,
      ThrowOnError
    >({
      url: '/.well-known/oauth-protected-resource/{mcp_server_name}/mcp',
      ...options,
    });

/**
 * Oauth Authorization Server Root
 */
export const oauthAuthorizationServerRootWellKnownOauthAuthorizationServerGet =
  <ThrowOnError extends boolean = false>(
    options?: Options<
      OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetData,
      ThrowOnError
    >,
  ) =>
    (options?.client ?? client).get<
      OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetResponses,
      OauthAuthorizationServerRootWellKnownOauthAuthorizationServerGetErrors,
      ThrowOnError
    >({ url: '/.well-known/oauth-authorization-server', ...options });

/**
 * Oauth Authorization Server Mcp
 */
export const oauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGet =
  <ThrowOnError extends boolean = false>(
    options: Options<
      OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetData,
      ThrowOnError
    >,
  ) =>
    (options.client ?? client).get<
      OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetResponses,
      OauthAuthorizationServerMcpWellKnownOauthAuthorizationServerMcpServerNameGetErrors,
      ThrowOnError
    >({
      url: '/.well-known/oauth-authorization-server/{mcp_server_name}',
      ...options,
    });

/**
 * Openid Configuration
 */
export const openidConfigurationWellKnownOpenidConfigurationGet = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<
    OpenidConfigurationWellKnownOpenidConfigurationGetData,
    ThrowOnError
  >,
) =>
  (options?.client ?? client).get<
    OpenidConfigurationWellKnownOpenidConfigurationGetResponses,
    unknown,
    ThrowOnError
  >({ url: '/.well-known/openid-configuration', ...options });

/**
 * Oauth Authorization Server Root
 */
export const oauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGet =
  <ThrowOnError extends boolean = false>(
    options: Options<
      OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetData,
      ThrowOnError
    >,
  ) =>
    (options.client ?? client).get<
      OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetResponses,
      OauthAuthorizationServerRootWellKnownOauthAuthorizationServerMcpServerNameMcpGetErrors,
      ThrowOnError
    >({
      url: '/.well-known/oauth-authorization-server/{mcp_server_name}/mcp',
      ...options,
    });

/**
 * Register Client
 */
export const registerClientRegisterPost = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<RegisterClientRegisterPostData, ThrowOnError>,
) =>
  (options?.client ?? client).post<
    RegisterClientRegisterPostResponses,
    RegisterClientRegisterPostErrors,
    ThrowOnError
  >({ url: '/register', ...options });

/**
 * Register Client
 */
export const registerClientMcpServerNameRegisterPost = <
  ThrowOnError extends boolean = false,
>(
  options: Options<RegisterClientMcpServerNameRegisterPostData, ThrowOnError>,
) =>
  (options.client ?? client).post<
    RegisterClientMcpServerNameRegisterPostResponses,
    RegisterClientMcpServerNameRegisterPostErrors,
    ThrowOnError
  >({ url: '/{mcp_server_name}/register', ...options });

/**
 * WebSocket: vertex_ai_live_passthrough_endpoint
 *
 * WebSocket connection endpoint
 */
export const websocketVertexAiLivePassthroughEndpoint = <
  ThrowOnError extends boolean = false,
>(
  options?: Options<WebsocketVertexAiLivePassthroughEndpointData, ThrowOnError>,
) =>
  (options?.client ?? client).get<unknown, unknown, ThrowOnError>({
    url: '/vertex_ai/live',
    ...options,
  });

/**
 * WebSocket: realtime_websocket_endpoint
 *
 * WebSocket connection endpoint
 */
export const websocketRealtimeWebsocketEndpoint = <
  ThrowOnError extends boolean = false,
>(
  options: Options<WebsocketRealtimeWebsocketEndpointData, ThrowOnError>,
) =>
  (options.client ?? client).get<unknown, unknown, ThrowOnError>({
    url: '/realtime',
    ...options,
  });

/**
 * WebSocket: realtime_websocket_endpoint
 *
 * WebSocket connection endpoint
 */
export const websocketRealtimeWebsocketEndpoint2 = <
  ThrowOnError extends boolean = false,
>(
  options: Options<WebsocketRealtimeWebsocketEndpoint2Data, ThrowOnError>,
) =>
  (options.client ?? client).get<unknown, unknown, ThrowOnError>({
    url: '/v1/realtime',
    ...options,
  });
